{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for this multilayer perceptron can be found in `mnist.py`. The module `utils.py` contains helper functions to load the dataset, display progress bar, plot graphs, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from mnist_v2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build an MLP and choose the values of $h^1$ and $h^2$ such that the total number of parameters (including biases) falls within the range of $I = [0.5M, 1.0M]$. This can be achieved by choosing $h^1 = h^2 = 512$. Since MNIST samples are $28 \\times 28 = 784$ pixels, the total number of parameters is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668672\n"
     ]
    }
   ],
   "source": [
    "num_params = (28*28)*512 + 512*512 + 512*10\n",
    "print(num_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is within range. We thus build the MLP with the parameters below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "layers = [784, 512, 512, 10]\n",
    "learning_rate = 1e-2\n",
    "batch_size = 64\n",
    "data_filename = \"../data/mnist/mnist.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load the tensors via Torch data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader = get_data_loaders(data_filename, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hardcoded parameters used for all three initilization schemes are:\n",
    "* **Activation functions:** Rectified linear unit (ReLU)\n",
    "* **Loss function:** Cross entropy\n",
    "* **Optimizer:** Stochastic gradient descent (SGD) with learning rate `learning_rate`\n",
    "\n",
    "For each initialization scheme, we compile the model and train by keeping track of the average loss. After training, we plot the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Avg loss: 2.3019 -- Train acc: 0.1135  \n",
      "Epoch 2/10\n",
      "Avg loss: 2.3012 -- Train acc: 0.1135  \n",
      "Epoch 3/10\n",
      "Avg loss: 2.3011 -- Train acc: 0.1135  \n",
      "Epoch 4/10\n",
      "Avg loss: 2.3011 -- Train acc: 0.1135  \n",
      "Epoch 5/10\n",
      "Avg loss: 2.3011 -- Train acc: 0.1135  \n",
      "Epoch 6/10\n",
      "Avg loss: 2.3011 -- Train acc: 0.1135  \n",
      "Epoch 7/10\n",
      "Avg loss: 2.3011 -- Train acc: 0.1135  \n",
      "Epoch 8/10\n",
      "Avg loss: 2.3011 -- Train acc: 0.1135  \n",
      "Epoch 9/10\n",
      "Avg loss: 2.3011 -- Train acc: 0.1135  \n",
      "Epoch 10/10\n",
      "Avg loss: 2.3011 -- Train acc: 0.1135  \n",
      "Training done! Elapsed time: 0:00:19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile and train model\n",
    "mlp_z = MNIST(layers, learning_rate, \"zeros\")\n",
    "zeros_losses = mlp_z.train(10, train_loader, [], [], len(train_loader.dataset))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2be86fcf10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot avg loss / epoch\n",
    "%matplotlib inline\n",
    "plot_per_epoch(zeros_losses, \"Avg Loss\", \"Training with zeros initialization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Avg loss: 102.9132 -- Train acc: 0.9077  \n",
      "Epoch 2/10\n",
      "Avg loss: 13.5959 -- Train acc: 0.9570  \n",
      "Epoch 3/10\n",
      "Avg loss: 6.8289 -- Train acc: 0.9709  \n",
      "Epoch 4/10\n",
      "Avg loss: 3.8098 -- Train acc: 0.9771  \n",
      "Epoch 5/10\n",
      "Avg loss: 2.1536 -- Train acc: 0.9794  \n",
      "Epoch 6/10\n",
      "Avg loss: 1.2922 -- Train acc: 0.9828  \n",
      "Epoch 7/10\n",
      "Avg loss: 0.7900 -- Train acc: 0.9794  \n",
      "Epoch 8/10\n",
      "Avg loss: 0.4948 -- Train acc: 0.9936  \n",
      "Epoch 9/10\n",
      "Avg loss: 0.3095 -- Train acc: 0.9947  \n",
      "Epoch 10/10\n",
      "Avg loss: 0.1884 -- Train acc: 0.9932  \n",
      "Training done! Elapsed time: 0:00:19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile and train model\n",
    "mlp_n = MNIST(layers, learning_rate, \"normal\")\n",
    "normal_losses = mlp_n.train(10, train_loader, [], [], len(train_loader.dataset))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2be86e0090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot avg loss / epoch\n",
    "%matplotlib inline\n",
    "plot_per_epoch(normal_losses, \"Avg Loss\", \"Training with Normal(0,1) initialization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glorot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Avg loss: 0.8635 -- Train acc: 0.8856  \n",
      "Epoch 2/10\n",
      "Avg loss: 0.3712 -- Train acc: 0.9063  \n",
      "Epoch 3/10\n",
      "Avg loss: 0.3073 -- Train acc: 0.9191  \n",
      "Epoch 4/10\n",
      "Avg loss: 0.2729 -- Train acc: 0.9252  \n",
      "Epoch 5/10\n",
      "Avg loss: 0.2475 -- Train acc: 0.9309  \n",
      "Epoch 6/10\n",
      "Avg loss: 0.2269 -- Train acc: 0.9380  \n",
      "Epoch 7/10\n",
      "Avg loss: 0.2099 -- Train acc: 0.9430  \n",
      "Epoch 8/10\n",
      "Avg loss: 0.1944 -- Train acc: 0.9466  \n",
      "Epoch 9/10\n",
      "Avg loss: 0.1814 -- Train acc: 0.9495  \n",
      "Epoch 10/10\n",
      "Avg loss: 0.1702 -- Train acc: 0.9516  \n",
      "Training done! Elapsed time: 0:00:19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile and train model\n",
    "mlp_g = MNIST(layers, learning_rate, \"glorot\")\n",
    "glorot_losses = mlp_g.train(10, train_loader, [], [], len(train_loader.dataset))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0974872f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot avg loss / epoch\n",
    "%matplotlib inline\n",
    "plot_per_epoch(glorot_losses, \"Avg Loss\", \"Training with Glorot initialization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Discuss results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Avg loss: 0.8695 -- Train acc: 0.8834 -- Val acc: 0.8924\n",
      "Epoch 2/100\n",
      "Avg loss: 0.3749 -- Train acc: 0.9031 -- Val acc: 0.9110\n",
      "Epoch 3/100\n",
      "Avg loss: 0.3128 -- Train acc: 0.9174 -- Val acc: 0.9200\n",
      "Epoch 4/100\n",
      "Avg loss: 0.2786 -- Train acc: 0.9258 -- Val acc: 0.9271\n",
      "Epoch 5/100\n",
      "Avg loss: 0.2530 -- Train acc: 0.9303 -- Val acc: 0.9309\n",
      "Epoch 6/100\n",
      "Avg loss: 0.2324 -- Train acc: 0.9365 -- Val acc: 0.9359\n",
      "Epoch 7/100\n",
      "Avg loss: 0.2153 -- Train acc: 0.9406 -- Val acc: 0.9401\n",
      "Epoch 8/100\n",
      "Avg loss: 0.2004 -- Train acc: 0.9453 -- Val acc: 0.9450\n",
      "Epoch 9/100\n",
      "Avg loss: 0.1870 -- Train acc: 0.9477 -- Val acc: 0.9469\n",
      "Epoch 10/100\n",
      "Avg loss: 0.1753 -- Train acc: 0.9508 -- Val acc: 0.9477\n",
      "Epoch 11/100\n",
      "Avg loss: 0.1652 -- Train acc: 0.9542 -- Val acc: 0.9511\n",
      "Epoch 12/100\n",
      "Avg loss: 0.1553 -- Train acc: 0.9570 -- Val acc: 0.9528\n",
      "Epoch 13/100\n",
      "Avg loss: 0.1471 -- Train acc: 0.9580 -- Val acc: 0.9542\n",
      "Epoch 14/100\n",
      "Avg loss: 0.1392 -- Train acc: 0.9603 -- Val acc: 0.9559\n",
      "Epoch 15/100\n",
      "Avg loss: 0.1325 -- Train acc: 0.9628 -- Val acc: 0.9579\n",
      "Epoch 16/100\n",
      "Avg loss: 0.1254 -- Train acc: 0.9656 -- Val acc: 0.9592\n",
      "Epoch 17/100\n",
      "Avg loss: 0.1193 -- Train acc: 0.9670 -- Val acc: 0.9609\n",
      "Epoch 18/100\n",
      "Avg loss: 0.1141 -- Train acc: 0.9682 -- Val acc: 0.9610\n",
      "Epoch 19/100\n",
      "Avg loss: 0.1090 -- Train acc: 0.9698 -- Val acc: 0.9628\n",
      "Epoch 20/100\n",
      "Avg loss: 0.1042 -- Train acc: 0.9715 -- Val acc: 0.9639\n",
      "Epoch 21/100\n",
      "Avg loss: 0.0999 -- Train acc: 0.9730 -- Val acc: 0.9639\n",
      "Epoch 22/100\n",
      "Avg loss: 0.0959 -- Train acc: 0.9730 -- Val acc: 0.9633\n",
      "Epoch 23/100\n",
      "Avg loss: 0.0917 -- Train acc: 0.9747 -- Val acc: 0.9649\n",
      "Epoch 24/100\n",
      "Avg loss: 0.0880 -- Train acc: 0.9761 -- Val acc: 0.9658\n",
      "Epoch 25/100\n",
      "Avg loss: 0.0847 -- Train acc: 0.9757 -- Val acc: 0.9667\n",
      "Epoch 26/100\n",
      "Avg loss: 0.0813 -- Train acc: 0.9784 -- Val acc: 0.9673\n",
      "Epoch 27/100\n",
      "Avg loss: 0.0782 -- Train acc: 0.9787 -- Val acc: 0.9675\n",
      "Epoch 28/100\n",
      "Avg loss: 0.0752 -- Train acc: 0.9802 -- Val acc: 0.9677\n",
      "Epoch 29/100\n",
      "Avg loss: 0.0727 -- Train acc: 0.9804 -- Val acc: 0.9680\n",
      "Epoch 30/100\n",
      "Avg loss: 0.0700 -- Train acc: 0.9809 -- Val acc: 0.9685\n",
      "Epoch 31/100\n",
      "Avg loss: 0.0673 -- Train acc: 0.9819 -- Val acc: 0.9683\n",
      "Epoch 32/100\n",
      "Avg loss: 0.0648 -- Train acc: 0.9826 -- Val acc: 0.9696\n",
      "Epoch 33/100\n",
      "Avg loss: 0.0626 -- Train acc: 0.9833 -- Val acc: 0.9692\n",
      "Epoch 34/100\n",
      "Avg loss: 0.0603 -- Train acc: 0.9844 -- Val acc: 0.9702\n",
      "Epoch 35/100\n",
      "Avg loss: 0.0583 -- Train acc: 0.9846 -- Val acc: 0.9703\n",
      "Epoch 36/100\n",
      "Avg loss: 0.0564 -- Train acc: 0.9851 -- Val acc: 0.9709\n",
      "Epoch 37/100\n",
      "Avg loss: 0.0544 -- Train acc: 0.9860 -- Val acc: 0.9710\n",
      "Epoch 38/100\n",
      "Avg loss: 0.0526 -- Train acc: 0.9860 -- Val acc: 0.9705\n",
      "Epoch 39/100\n",
      "Avg loss: 0.0510 -- Train acc: 0.9871 -- Val acc: 0.9712\n",
      "Epoch 40/100\n",
      "Avg loss: 0.0490 -- Train acc: 0.9877 -- Val acc: 0.9715\n",
      "Epoch 41/100\n",
      "Avg loss: 0.0477 -- Train acc: 0.9877 -- Val acc: 0.9717\n",
      "Epoch 42/100\n",
      "Avg loss: 0.0459 -- Train acc: 0.9883 -- Val acc: 0.9716\n",
      "Epoch 43/100\n",
      "Avg loss: 0.0444 -- Train acc: 0.9889 -- Val acc: 0.9723\n",
      "Epoch 44/100\n",
      "Avg loss: 0.0431 -- Train acc: 0.9886 -- Val acc: 0.9711\n",
      "Epoch 45/100\n",
      "Avg loss: 0.0418 -- Train acc: 0.9896 -- Val acc: 0.9721\n",
      "Epoch 46/100\n",
      "Avg loss: 0.0403 -- Train acc: 0.9907 -- Val acc: 0.9725\n",
      "Epoch 47/100\n",
      "Avg loss: 0.0391 -- Train acc: 0.9910 -- Val acc: 0.9726\n",
      "Epoch 48/100\n",
      "Avg loss: 0.0379 -- Train acc: 0.9909 -- Val acc: 0.9723\n",
      "Epoch 49/100\n",
      "Avg loss: 0.0366 -- Train acc: 0.9916 -- Val acc: 0.9726\n",
      "Epoch 50/100\n",
      "Avg loss: 0.0356 -- Train acc: 0.9894 -- Val acc: 0.9700\n",
      "Epoch 51/100\n",
      "Avg loss: 0.0345 -- Train acc: 0.9926 -- Val acc: 0.9726\n",
      "Epoch 52/100\n",
      "Avg loss: 0.0333 -- Train acc: 0.9921 -- Val acc: 0.9736\n",
      "Epoch 53/100\n",
      "Avg loss: 0.0323 -- Train acc: 0.9925 -- Val acc: 0.9732\n",
      "Epoch 54/100\n",
      "Avg loss: 0.0314 -- Train acc: 0.9934 -- Val acc: 0.9736\n",
      "Epoch 55/100\n",
      "Avg loss: 0.0304 -- Train acc: 0.9936 -- Val acc: 0.9737\n",
      "Epoch 56/100\n",
      "Avg loss: 0.0294 -- Train acc: 0.9940 -- Val acc: 0.9737\n",
      "Epoch 57/100\n",
      "Avg loss: 0.0286 -- Train acc: 0.9940 -- Val acc: 0.9739\n",
      "Epoch 58/100\n",
      "Avg loss: 0.0278 -- Train acc: 0.9944 -- Val acc: 0.9736\n",
      "Epoch 59/100\n",
      "Avg loss: 0.0269 -- Train acc: 0.9940 -- Val acc: 0.9736\n",
      "Epoch 60/100\n",
      "Avg loss: 0.0261 -- Train acc: 0.9944 -- Val acc: 0.9737\n",
      "Epoch 61/100\n",
      "Avg loss: 0.0254 -- Train acc: 0.9947 -- Val acc: 0.9738\n",
      "Epoch 62/100\n",
      "Avg loss: 0.0248 -- Train acc: 0.9950 -- Val acc: 0.9741\n",
      "Epoch 63/100\n",
      "Avg loss: 0.0239 -- Train acc: 0.9952 -- Val acc: 0.9741\n",
      "Epoch 64/100\n",
      "Avg loss: 0.0232 -- Train acc: 0.9954 -- Val acc: 0.9743\n",
      "Epoch 65/100\n",
      "Avg loss: 0.0226 -- Train acc: 0.9956 -- Val acc: 0.9749\n",
      "Epoch 66/100\n",
      "Avg loss: 0.0219 -- Train acc: 0.9961 -- Val acc: 0.9747\n",
      "Epoch 67/100\n",
      "Avg loss: 0.0213 -- Train acc: 0.9959 -- Val acc: 0.9751\n",
      "Epoch 68/100\n",
      "Avg loss: 0.0208 -- Train acc: 0.9962 -- Val acc: 0.9748\n",
      "Epoch 69/100\n",
      "Avg loss: 0.0201 -- Train acc: 0.9962 -- Val acc: 0.9753\n",
      "Epoch 70/100\n",
      "Avg loss: 0.0196 -- Train acc: 0.9965 -- Val acc: 0.9742\n",
      "Epoch 71/100\n",
      "Avg loss: 0.0191 -- Train acc: 0.9964 -- Val acc: 0.9751\n",
      "Epoch 72/100\n",
      "Avg loss: 0.0186 -- Train acc: 0.9967 -- Val acc: 0.9749\n",
      "Epoch 73/100\n",
      "Avg loss: 0.0181 -- Train acc: 0.9968 -- Val acc: 0.9744\n",
      "Epoch 74/100\n",
      "Avg loss: 0.0176 -- Train acc: 0.9968 -- Val acc: 0.9744\n",
      "Epoch 75/100\n",
      "Avg loss: 0.0171 -- Train acc: 0.9969 -- Val acc: 0.9747\n",
      "Epoch 76/100\n",
      "Avg loss: 0.0167 -- Train acc: 0.9971 -- Val acc: 0.9748\n",
      "Epoch 77/100\n",
      "Avg loss: 0.0162 -- Train acc: 0.9972 -- Val acc: 0.9745\n",
      "Epoch 78/100\n",
      "Avg loss: 0.0159 -- Train acc: 0.9971 -- Val acc: 0.9748\n",
      "Epoch 79/100\n",
      "Avg loss: 0.0154 -- Train acc: 0.9966 -- Val acc: 0.9737\n",
      "Epoch 80/100\n",
      "Avg loss: 0.0151 -- Train acc: 0.9974 -- Val acc: 0.9755\n",
      "Epoch 81/100\n",
      "Avg loss: 0.0146 -- Train acc: 0.9975 -- Val acc: 0.9745\n",
      "Epoch 82/100\n",
      "Avg loss: 0.0143 -- Train acc: 0.9976 -- Val acc: 0.9746\n",
      "Epoch 83/100\n",
      "Avg loss: 0.0139 -- Train acc: 0.9977 -- Val acc: 0.9749\n",
      "Epoch 84/100\n",
      "Avg loss: 0.0136 -- Train acc: 0.9976 -- Val acc: 0.9739\n",
      "Epoch 85/100\n",
      "Avg loss: 0.0132 -- Train acc: 0.9977 -- Val acc: 0.9755\n",
      "Epoch 86/100\n",
      "Avg loss: 0.0129 -- Train acc: 0.9978 -- Val acc: 0.9754\n",
      "Epoch 87/100\n",
      "Avg loss: 0.0126 -- Train acc: 0.9979 -- Val acc: 0.9755\n",
      "Epoch 88/100\n",
      "Avg loss: 0.0122 -- Train acc: 0.9979 -- Val acc: 0.9747\n",
      "Epoch 89/100\n",
      "Avg loss: 0.0120 -- Train acc: 0.9980 -- Val acc: 0.9750\n",
      "Epoch 90/100\n",
      "Avg loss: 0.0117 -- Train acc: 0.9981 -- Val acc: 0.9754\n",
      "Epoch 91/100\n",
      "Avg loss: 0.0114 -- Train acc: 0.9981 -- Val acc: 0.9749\n",
      "Epoch 92/100\n",
      "Avg loss: 0.0111 -- Train acc: 0.9981 -- Val acc: 0.9750\n",
      "Epoch 93/100\n",
      "Avg loss: 0.0109 -- Train acc: 0.9982 -- Val acc: 0.9749\n",
      "Epoch 94/100\n",
      "Avg loss: 0.0106 -- Train acc: 0.9982 -- Val acc: 0.9754\n",
      "Epoch 95/100\n",
      "Avg loss: 0.0103 -- Train acc: 0.9982 -- Val acc: 0.9753\n",
      "Epoch 96/100\n",
      "Avg loss: 0.0101 -- Train acc: 0.9982 -- Val acc: 0.9747\n",
      "Epoch 97/100\n",
      "Avg loss: 0.0100 -- Train acc: 0.9983 -- Val acc: 0.9754\n",
      "Epoch 98/100\n",
      "Avg loss: 0.0097 -- Train acc: 0.9983 -- Val acc: 0.9754\n",
      "Epoch 99/100\n",
      "Avg loss: 0.0095 -- Train acc: 0.9984 -- Val acc: 0.9754\n",
      "Epoch 100/100\n",
      "Avg loss: 0.0093 -- Train acc: 0.9984 -- Val acc: 0.9748\n",
      "Training done! Elapsed time: 0:03:21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MNIST(layers, learning_rate, \"glorot\")\n",
    "_, train_acc, valid_acc, _ = mlp.train(100, train_loader, valid_loader, [], len(train_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2bb4a485d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and test accuracy / epoch\n",
    "%matplotlib inline\n",
    "plots_per_epoch([train_acc, valid_acc], [\"Train\", \"Test\"], \"Accuracy\", \"Accuracy per epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train by doubling the model capacity. This is done by doubling the number of neurons at the first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1332224\n"
     ]
    }
   ],
   "source": [
    "num_params = (28*28)*2*512 + 2*512*512 + 512*10\n",
    "print(num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Avg loss: 0.8166 -- Train acc: 0.8914 -- Val acc: 0.8975\n",
      "Epoch 2/100\n",
      "Avg loss: 0.3595 -- Train acc: 0.9106 -- Val acc: 0.9152\n",
      "Epoch 3/100\n",
      "Avg loss: 0.2994 -- Train acc: 0.9216 -- Val acc: 0.9219\n",
      "Epoch 4/100\n",
      "Avg loss: 0.2651 -- Train acc: 0.9300 -- Val acc: 0.9298\n",
      "Epoch 5/100\n",
      "Avg loss: 0.2398 -- Train acc: 0.9346 -- Val acc: 0.9325\n",
      "Epoch 6/100\n",
      "Avg loss: 0.2190 -- Train acc: 0.9401 -- Val acc: 0.9396\n",
      "Epoch 7/100\n",
      "Avg loss: 0.2018 -- Train acc: 0.9457 -- Val acc: 0.9456\n",
      "Epoch 8/100\n",
      "Avg loss: 0.1872 -- Train acc: 0.9487 -- Val acc: 0.9487\n",
      "Epoch 9/100\n",
      "Avg loss: 0.1737 -- Train acc: 0.9536 -- Val acc: 0.9511\n",
      "Epoch 10/100\n",
      "Avg loss: 0.1623 -- Train acc: 0.9561 -- Val acc: 0.9541\n",
      "Epoch 11/100\n",
      "Avg loss: 0.1521 -- Train acc: 0.9592 -- Val acc: 0.9554\n",
      "Epoch 12/100\n",
      "Avg loss: 0.1431 -- Train acc: 0.9610 -- Val acc: 0.9572\n",
      "Epoch 13/100\n",
      "Avg loss: 0.1347 -- Train acc: 0.9635 -- Val acc: 0.9584\n",
      "Epoch 14/100\n",
      "Avg loss: 0.1274 -- Train acc: 0.9656 -- Val acc: 0.9604\n",
      "Epoch 15/100\n",
      "Avg loss: 0.1204 -- Train acc: 0.9680 -- Val acc: 0.9619\n",
      "Epoch 16/100\n",
      "Avg loss: 0.1143 -- Train acc: 0.9691 -- Val acc: 0.9625\n",
      "Epoch 17/100\n",
      "Avg loss: 0.1087 -- Train acc: 0.9701 -- Val acc: 0.9625\n",
      "Epoch 18/100\n",
      "Avg loss: 0.1035 -- Train acc: 0.9723 -- Val acc: 0.9636\n",
      "Epoch 19/100\n",
      "Avg loss: 0.0984 -- Train acc: 0.9742 -- Val acc: 0.9651\n",
      "Epoch 20/100\n",
      "Avg loss: 0.0936 -- Train acc: 0.9755 -- Val acc: 0.9661\n",
      "Epoch 21/100\n",
      "Avg loss: 0.0900 -- Train acc: 0.9771 -- Val acc: 0.9672\n",
      "Epoch 22/100\n",
      "Avg loss: 0.0855 -- Train acc: 0.9774 -- Val acc: 0.9673\n",
      "Epoch 23/100\n",
      "Avg loss: 0.0819 -- Train acc: 0.9792 -- Val acc: 0.9680\n",
      "Epoch 24/100\n",
      "Avg loss: 0.0783 -- Train acc: 0.9788 -- Val acc: 0.9673\n",
      "Epoch 25/100\n",
      "Avg loss: 0.0754 -- Train acc: 0.9808 -- Val acc: 0.9684\n",
      "Epoch 26/100\n",
      "Avg loss: 0.0719 -- Train acc: 0.9813 -- Val acc: 0.9687\n",
      "Epoch 27/100\n",
      "Avg loss: 0.0690 -- Train acc: 0.9817 -- Val acc: 0.9691\n",
      "Epoch 28/100\n",
      "Avg loss: 0.0663 -- Train acc: 0.9825 -- Val acc: 0.9698\n",
      "Epoch 29/100\n",
      "Avg loss: 0.0636 -- Train acc: 0.9838 -- Val acc: 0.9696\n",
      "Epoch 30/100\n",
      "Avg loss: 0.0611 -- Train acc: 0.9838 -- Val acc: 0.9702\n",
      "Epoch 31/100\n",
      "Avg loss: 0.0588 -- Train acc: 0.9849 -- Val acc: 0.9711\n",
      "Epoch 32/100\n",
      "Avg loss: 0.0564 -- Train acc: 0.9853 -- Val acc: 0.9697\n",
      "Epoch 33/100\n",
      "Avg loss: 0.0544 -- Train acc: 0.9863 -- Val acc: 0.9723\n",
      "Epoch 34/100\n",
      "Avg loss: 0.0524 -- Train acc: 0.9864 -- Val acc: 0.9717\n",
      "Epoch 35/100\n",
      "Avg loss: 0.0505 -- Train acc: 0.9874 -- Val acc: 0.9722\n",
      "Epoch 36/100\n",
      "Avg loss: 0.0484 -- Train acc: 0.9880 -- Val acc: 0.9733\n",
      "Epoch 37/100\n",
      "Avg loss: 0.0467 -- Train acc: 0.9883 -- Val acc: 0.9726\n",
      "Epoch 38/100\n",
      "Avg loss: 0.0450 -- Train acc: 0.9888 -- Val acc: 0.9722\n",
      "Epoch 39/100\n",
      "Avg loss: 0.0433 -- Train acc: 0.9896 -- Val acc: 0.9733\n",
      "Epoch 40/100\n",
      "Avg loss: 0.0418 -- Train acc: 0.9896 -- Val acc: 0.9729\n",
      "Epoch 41/100\n",
      "Avg loss: 0.0405 -- Train acc: 0.9906 -- Val acc: 0.9741\n",
      "Epoch 42/100\n",
      "Avg loss: 0.0390 -- Train acc: 0.9897 -- Val acc: 0.9726\n",
      "Epoch 43/100\n",
      "Avg loss: 0.0376 -- Train acc: 0.9912 -- Val acc: 0.9736\n",
      "Epoch 44/100\n",
      "Avg loss: 0.0363 -- Train acc: 0.9917 -- Val acc: 0.9741\n",
      "Epoch 45/100\n",
      "Avg loss: 0.0351 -- Train acc: 0.9916 -- Val acc: 0.9744\n",
      "Epoch 46/100\n",
      "Avg loss: 0.0339 -- Train acc: 0.9924 -- Val acc: 0.9741\n",
      "Epoch 47/100\n",
      "Avg loss: 0.0327 -- Train acc: 0.9926 -- Val acc: 0.9737\n",
      "Epoch 48/100\n",
      "Avg loss: 0.0314 -- Train acc: 0.9932 -- Val acc: 0.9737\n",
      "Epoch 49/100\n",
      "Avg loss: 0.0305 -- Train acc: 0.9930 -- Val acc: 0.9742\n",
      "Epoch 50/100\n",
      "Avg loss: 0.0296 -- Train acc: 0.9939 -- Val acc: 0.9745\n",
      "Epoch 51/100\n",
      "Avg loss: 0.0285 -- Train acc: 0.9941 -- Val acc: 0.9737\n",
      "Epoch 52/100\n",
      "Avg loss: 0.0276 -- Train acc: 0.9943 -- Val acc: 0.9744\n",
      "Epoch 53/100\n",
      "Avg loss: 0.0266 -- Train acc: 0.9941 -- Val acc: 0.9742\n",
      "Epoch 54/100\n",
      "Avg loss: 0.0261 -- Train acc: 0.9887 -- Val acc: 0.9689\n",
      "Epoch 55/100\n",
      "Avg loss: 0.0251 -- Train acc: 0.9951 -- Val acc: 0.9745\n",
      "Epoch 56/100\n",
      "Avg loss: 0.0241 -- Train acc: 0.9953 -- Val acc: 0.9753\n",
      "Epoch 57/100\n",
      "Avg loss: 0.0234 -- Train acc: 0.9957 -- Val acc: 0.9750\n",
      "Epoch 58/100\n",
      "Avg loss: 0.0226 -- Train acc: 0.9957 -- Val acc: 0.9750\n",
      "Epoch 59/100\n",
      "Avg loss: 0.0218 -- Train acc: 0.9959 -- Val acc: 0.9746\n",
      "Epoch 60/100\n",
      "Avg loss: 0.0212 -- Train acc: 0.9961 -- Val acc: 0.9755\n",
      "Epoch 61/100\n",
      "Avg loss: 0.0206 -- Train acc: 0.9963 -- Val acc: 0.9747\n",
      "Epoch 62/100\n",
      "Avg loss: 0.0199 -- Train acc: 0.9965 -- Val acc: 0.9757\n",
      "Epoch 63/100\n",
      "Avg loss: 0.0193 -- Train acc: 0.9964 -- Val acc: 0.9746\n",
      "Epoch 64/100\n",
      "Avg loss: 0.0187 -- Train acc: 0.9968 -- Val acc: 0.9753\n",
      "Epoch 65/100\n",
      "Avg loss: 0.0181 -- Train acc: 0.9968 -- Val acc: 0.9750\n",
      "Epoch 66/100\n",
      "Avg loss: 0.0176 -- Train acc: 0.9969 -- Val acc: 0.9754\n",
      "Epoch 67/100\n",
      "Avg loss: 0.0170 -- Train acc: 0.9970 -- Val acc: 0.9759\n",
      "Epoch 68/100\n",
      "Avg loss: 0.0166 -- Train acc: 0.9971 -- Val acc: 0.9754\n",
      "Epoch 69/100\n",
      "Avg loss: 0.0161 -- Train acc: 0.9975 -- Val acc: 0.9754\n",
      "Epoch 70/100\n",
      "Avg loss: 0.0156 -- Train acc: 0.9972 -- Val acc: 0.9755\n",
      "Epoch 71/100\n",
      "Avg loss: 0.0153 -- Train acc: 0.9973 -- Val acc: 0.9760\n",
      "Epoch 72/100\n",
      "Avg loss: 0.0148 -- Train acc: 0.9975 -- Val acc: 0.9757\n",
      "Epoch 73/100\n",
      "Avg loss: 0.0144 -- Train acc: 0.9976 -- Val acc: 0.9760\n",
      "Epoch 74/100\n",
      "Avg loss: 0.0139 -- Train acc: 0.9978 -- Val acc: 0.9751\n",
      "Epoch 75/100\n",
      "Avg loss: 0.0136 -- Train acc: 0.9977 -- Val acc: 0.9757\n",
      "Epoch 76/100\n",
      "Avg loss: 0.0131 -- Train acc: 0.9977 -- Val acc: 0.9755\n",
      "Epoch 77/100\n",
      "Avg loss: 0.0128 -- Train acc: 0.9979 -- Val acc: 0.9758\n",
      "Epoch 78/100\n",
      "Avg loss: 0.0125 -- Train acc: 0.9980 -- Val acc: 0.9760\n",
      "Epoch 79/100\n",
      "Avg loss: 0.0121 -- Train acc: 0.9981 -- Val acc: 0.9757\n",
      "Epoch 80/100\n",
      "Avg loss: 0.0118 -- Train acc: 0.9982 -- Val acc: 0.9755\n",
      "Epoch 81/100\n",
      "Avg loss: 0.0115 -- Train acc: 0.9981 -- Val acc: 0.9757\n",
      "Epoch 82/100\n",
      "Avg loss: 0.0113 -- Train acc: 0.9981 -- Val acc: 0.9753\n",
      "Epoch 83/100\n",
      "Avg loss: 0.0109 -- Train acc: 0.9982 -- Val acc: 0.9755\n",
      "Epoch 84/100\n",
      "Avg loss: 0.0107 -- Train acc: 0.9983 -- Val acc: 0.9757\n",
      "Epoch 85/100\n",
      "Avg loss: 0.0104 -- Train acc: 0.9983 -- Val acc: 0.9755\n",
      "Epoch 86/100\n",
      "Avg loss: 0.0101 -- Train acc: 0.9984 -- Val acc: 0.9753\n",
      "Epoch 87/100\n",
      "Avg loss: 0.0098 -- Train acc: 0.9985 -- Val acc: 0.9757\n",
      "Epoch 88/100\n",
      "Avg loss: 0.0096 -- Train acc: 0.9985 -- Val acc: 0.9759\n",
      "Epoch 89/100\n",
      "Avg loss: 0.0094 -- Train acc: 0.9985 -- Val acc: 0.9757\n",
      "Epoch 90/100\n",
      "Avg loss: 0.0091 -- Train acc: 0.9985 -- Val acc: 0.9760\n",
      "Epoch 91/100\n",
      "Avg loss: 0.0089 -- Train acc: 0.9986 -- Val acc: 0.9760\n",
      "Epoch 92/100\n",
      "Avg loss: 0.0087 -- Train acc: 0.9986 -- Val acc: 0.9755\n",
      "Epoch 93/100\n",
      "Avg loss: 0.0085 -- Train acc: 0.9987 -- Val acc: 0.9757\n",
      "Epoch 94/100\n",
      "Avg loss: 0.0083 -- Train acc: 0.9986 -- Val acc: 0.9756\n",
      "Epoch 95/100\n",
      "Avg loss: 0.0081 -- Train acc: 0.9987 -- Val acc: 0.9753\n",
      "Epoch 96/100\n",
      "Avg loss: 0.0080 -- Train acc: 0.9987 -- Val acc: 0.9757\n",
      "Epoch 97/100\n",
      "Avg loss: 0.0078 -- Train acc: 0.9987 -- Val acc: 0.9758\n",
      "Epoch 98/100\n",
      "Avg loss: 0.0076 -- Train acc: 0.9987 -- Val acc: 0.9759\n",
      "Epoch 99/100\n",
      "Avg loss: 0.0074 -- Train acc: 0.9987 -- Val acc: 0.9757\n",
      "Epoch 100/100\n",
      "Avg loss: 0.0073 -- Train acc: 0.9988 -- Val acc: 0.9754\n",
      "Training done! Elapsed time: 0:03:20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "layers_2 = [784, 2*512, 512, 10]\n",
    "mlp_2 = MNIST(layers_2, learning_rate, \"glorot\")\n",
    "_, train_acc_2, valid_acc_2, _ = mlp_2.train(100, train_loader, valid_loader, [], len(train_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f091c231350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and test accuracy / epoch\n",
    "%matplotlib inline\n",
    "plots_per_epoch([train_acc_2, valid_acc_2], [\"Train\", \"Test\"], \"Accuracy\", \"Accuracy per epoch (doubled capacity)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Compare single vs. double capacity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training Set Size, Generalization Gap, and Standard Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each ratio $a \\in \\{0.01, 0.02, 0.05, 0.1, 1.0\\}$, we reduce the training set to $N_a = aN$ samples, where $N= 50\\,000$. We then train using this new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "a = 0.01, Na = 500\n",
      "------------------------------\n",
      "Iter 1\n",
      "Epoch 1/100\n",
      "Avg loss: 2.3415 -- Train acc: 0.1523 -- Val acc: 0.1544 -- Test acc: 0.1625 -- Gen gap -0.0102\n",
      "Epoch 2/100\n",
      "Avg loss: 2.2622 -- Train acc: 0.2656 -- Val acc: 0.2472 -- Test acc: 0.2548 -- Gen gap 0.0108\n",
      "Epoch 3/100\n",
      "Avg loss: 2.1935 -- Train acc: 0.4004 -- Val acc: 0.3335 -- Test acc: 0.3392 -- Gen gap 0.0612\n",
      "Epoch 4/100\n",
      "Avg loss: 2.1291 -- Train acc: 0.4941 -- Val acc: 0.4179 -- Test acc: 0.4168 -- Gen gap 0.0773\n",
      "Epoch 5/100\n",
      "Avg loss: 2.0678 -- Train acc: 0.5664 -- Val acc: 0.4997 -- Test acc: 0.4950 -- Gen gap 0.0714\n",
      "Epoch 6/100\n",
      "Avg loss: 2.0076 -- Train acc: 0.6035 -- Val acc: 0.5491 -- Test acc: 0.5462 -- Gen gap 0.0573\n",
      "Epoch 7/100\n",
      "Avg loss: 1.9493 -- Train acc: 0.6465 -- Val acc: 0.5905 -- Test acc: 0.5818 -- Gen gap 0.0647\n",
      "Epoch 8/100\n",
      "Avg loss: 1.8891 -- Train acc: 0.6816 -- Val acc: 0.6197 -- Test acc: 0.6121 -- Gen gap 0.0696\n",
      "Epoch 9/100\n",
      "Avg loss: 1.8319 -- Train acc: 0.7109 -- Val acc: 0.6456 -- Test acc: 0.6358 -- Gen gap 0.0751\n",
      "Epoch 10/100\n",
      "Avg loss: 1.7704 -- Train acc: 0.7246 -- Val acc: 0.6607 -- Test acc: 0.6477 -- Gen gap 0.0769\n",
      "Epoch 11/100\n",
      "Avg loss: 1.7070 -- Train acc: 0.7383 -- Val acc: 0.6792 -- Test acc: 0.6676 -- Gen gap 0.0707\n",
      "Epoch 12/100\n",
      "Avg loss: 1.6484 -- Train acc: 0.7578 -- Val acc: 0.6930 -- Test acc: 0.6828 -- Gen gap 0.0750\n",
      "Epoch 13/100\n",
      "Avg loss: 1.5882 -- Train acc: 0.7598 -- Val acc: 0.7041 -- Test acc: 0.6938 -- Gen gap 0.0660\n",
      "Epoch 14/100\n",
      "Avg loss: 1.5267 -- Train acc: 0.7754 -- Val acc: 0.7165 -- Test acc: 0.7076 -- Gen gap 0.0678\n",
      "Epoch 15/100\n",
      "Avg loss: 1.4698 -- Train acc: 0.7891 -- Val acc: 0.7273 -- Test acc: 0.7162 -- Gen gap 0.0729\n",
      "Epoch 16/100\n",
      "Avg loss: 1.4101 -- Train acc: 0.7969 -- Val acc: 0.7388 -- Test acc: 0.7276 -- Gen gap 0.0693\n",
      "Epoch 17/100\n",
      "Avg loss: 1.3516 -- Train acc: 0.8008 -- Val acc: 0.7450 -- Test acc: 0.7333 -- Gen gap 0.0675\n",
      "Epoch 18/100\n",
      "Avg loss: 1.2963 -- Train acc: 0.8027 -- Val acc: 0.7519 -- Test acc: 0.7387 -- Gen gap 0.0641\n",
      "Epoch 19/100\n",
      "Avg loss: 1.2440 -- Train acc: 0.8047 -- Val acc: 0.7596 -- Test acc: 0.7473 -- Gen gap 0.0574\n",
      "Epoch 20/100\n",
      "Avg loss: 1.1960 -- Train acc: 0.8066 -- Val acc: 0.7669 -- Test acc: 0.7529 -- Gen gap 0.0538\n",
      "Epoch 21/100\n",
      "Avg loss: 1.1441 -- Train acc: 0.8242 -- Val acc: 0.7771 -- Test acc: 0.7626 -- Gen gap 0.0616\n",
      "Epoch 22/100\n",
      "Avg loss: 1.1015 -- Train acc: 0.8242 -- Val acc: 0.7789 -- Test acc: 0.7641 -- Gen gap 0.0601\n",
      "Epoch 23/100\n",
      "Avg loss: 1.0545 -- Train acc: 0.8320 -- Val acc: 0.7848 -- Test acc: 0.7713 -- Gen gap 0.0607\n",
      "Epoch 24/100\n",
      "Avg loss: 1.0139 -- Train acc: 0.8301 -- Val acc: 0.7847 -- Test acc: 0.7709 -- Gen gap 0.0592\n",
      "Epoch 25/100\n",
      "Avg loss: 0.9769 -- Train acc: 0.8359 -- Val acc: 0.7911 -- Test acc: 0.7791 -- Gen gap 0.0569\n",
      "Epoch 26/100\n",
      "Avg loss: 0.9386 -- Train acc: 0.8379 -- Val acc: 0.7940 -- Test acc: 0.7818 -- Gen gap 0.0560\n",
      "Epoch 27/100\n",
      "Avg loss: 0.9075 -- Train acc: 0.8477 -- Val acc: 0.7994 -- Test acc: 0.7860 -- Gen gap 0.0616\n",
      "Epoch 28/100\n",
      "Avg loss: 0.8745 -- Train acc: 0.8516 -- Val acc: 0.8033 -- Test acc: 0.7896 -- Gen gap 0.0620\n",
      "Epoch 29/100\n",
      "Avg loss: 0.8424 -- Train acc: 0.8555 -- Val acc: 0.8065 -- Test acc: 0.7925 -- Gen gap 0.0630\n",
      "Epoch 30/100\n",
      "Avg loss: 0.8147 -- Train acc: 0.8535 -- Val acc: 0.8057 -- Test acc: 0.7933 -- Gen gap 0.0602\n",
      "Epoch 31/100\n",
      "Avg loss: 0.7867 -- Train acc: 0.8613 -- Val acc: 0.8100 -- Test acc: 0.7977 -- Gen gap 0.0637\n",
      "Epoch 32/100\n",
      "Avg loss: 0.7656 -- Train acc: 0.8633 -- Val acc: 0.8112 -- Test acc: 0.7984 -- Gen gap 0.0649\n",
      "Epoch 33/100\n",
      "Avg loss: 0.7393 -- Train acc: 0.8672 -- Val acc: 0.8122 -- Test acc: 0.8006 -- Gen gap 0.0666\n",
      "Epoch 34/100\n",
      "Avg loss: 0.7223 -- Train acc: 0.8711 -- Val acc: 0.8134 -- Test acc: 0.8018 -- Gen gap 0.0693\n",
      "Epoch 35/100\n",
      "Avg loss: 0.6969 -- Train acc: 0.8730 -- Val acc: 0.8178 -- Test acc: 0.8053 -- Gen gap 0.0677\n",
      "Epoch 36/100\n",
      "Avg loss: 0.6769 -- Train acc: 0.8711 -- Val acc: 0.8180 -- Test acc: 0.8055 -- Gen gap 0.0656\n",
      "Epoch 37/100\n",
      "Avg loss: 0.6592 -- Train acc: 0.8750 -- Val acc: 0.8179 -- Test acc: 0.8070 -- Gen gap 0.0680\n",
      "Epoch 38/100\n",
      "Avg loss: 0.6423 -- Train acc: 0.8750 -- Val acc: 0.8199 -- Test acc: 0.8091 -- Gen gap 0.0659\n",
      "Epoch 39/100\n",
      "Avg loss: 0.6245 -- Train acc: 0.8789 -- Val acc: 0.8231 -- Test acc: 0.8118 -- Gen gap 0.0671\n",
      "Epoch 40/100\n",
      "Avg loss: 0.6103 -- Train acc: 0.8770 -- Val acc: 0.8265 -- Test acc: 0.8138 -- Gen gap 0.0632\n",
      "Epoch 41/100\n",
      "Avg loss: 0.5965 -- Train acc: 0.8789 -- Val acc: 0.8220 -- Test acc: 0.8110 -- Gen gap 0.0679\n",
      "Epoch 42/100\n",
      "Avg loss: 0.5841 -- Train acc: 0.8848 -- Val acc: 0.8277 -- Test acc: 0.8151 -- Gen gap 0.0697\n",
      "Epoch 43/100\n",
      "Avg loss: 0.5697 -- Train acc: 0.8828 -- Val acc: 0.8289 -- Test acc: 0.8175 -- Gen gap 0.0653\n",
      "Epoch 44/100\n",
      "Avg loss: 0.5539 -- Train acc: 0.8906 -- Val acc: 0.8298 -- Test acc: 0.8199 -- Gen gap 0.0708\n",
      "Epoch 45/100\n",
      "Avg loss: 0.5427 -- Train acc: 0.8887 -- Val acc: 0.8333 -- Test acc: 0.8224 -- Gen gap 0.0663\n",
      "Epoch 46/100\n",
      "Avg loss: 0.5297 -- Train acc: 0.8926 -- Val acc: 0.8318 -- Test acc: 0.8214 -- Gen gap 0.0712\n",
      "Epoch 47/100\n",
      "Avg loss: 0.5202 -- Train acc: 0.8926 -- Val acc: 0.8339 -- Test acc: 0.8235 -- Gen gap 0.0690\n",
      "Epoch 48/100\n",
      "Avg loss: 0.5117 -- Train acc: 0.8926 -- Val acc: 0.8340 -- Test acc: 0.8249 -- Gen gap 0.0676\n",
      "Epoch 49/100\n",
      "Avg loss: 0.4955 -- Train acc: 0.8906 -- Val acc: 0.8371 -- Test acc: 0.8273 -- Gen gap 0.0633\n",
      "Epoch 50/100\n",
      "Avg loss: 0.4906 -- Train acc: 0.8965 -- Val acc: 0.8346 -- Test acc: 0.8260 -- Gen gap 0.0704\n",
      "Epoch 51/100\n",
      "Avg loss: 0.4791 -- Train acc: 0.8926 -- Val acc: 0.8373 -- Test acc: 0.8290 -- Gen gap 0.0636\n",
      "Epoch 52/100\n",
      "Avg loss: 0.4718 -- Train acc: 0.8945 -- Val acc: 0.8386 -- Test acc: 0.8304 -- Gen gap 0.0641\n",
      "Epoch 53/100\n",
      "Avg loss: 0.4601 -- Train acc: 0.8945 -- Val acc: 0.8385 -- Test acc: 0.8308 -- Gen gap 0.0637\n",
      "Epoch 54/100\n",
      "Avg loss: 0.4537 -- Train acc: 0.8965 -- Val acc: 0.8413 -- Test acc: 0.8347 -- Gen gap 0.0618\n",
      "Epoch 55/100\n",
      "Avg loss: 0.4429 -- Train acc: 0.8965 -- Val acc: 0.8386 -- Test acc: 0.8319 -- Gen gap 0.0646\n",
      "Epoch 56/100\n",
      "Avg loss: 0.4354 -- Train acc: 0.8984 -- Val acc: 0.8392 -- Test acc: 0.8328 -- Gen gap 0.0656\n",
      "Epoch 57/100\n",
      "Avg loss: 0.4297 -- Train acc: 0.8945 -- Val acc: 0.8399 -- Test acc: 0.8330 -- Gen gap 0.0615\n",
      "Epoch 58/100\n",
      "Avg loss: 0.4196 -- Train acc: 0.9004 -- Val acc: 0.8438 -- Test acc: 0.8364 -- Gen gap 0.0640\n",
      "Epoch 59/100\n",
      "Avg loss: 0.4138 -- Train acc: 0.9023 -- Val acc: 0.8432 -- Test acc: 0.8368 -- Gen gap 0.0656\n",
      "Epoch 60/100\n",
      "Avg loss: 0.4078 -- Train acc: 0.9023 -- Val acc: 0.8439 -- Test acc: 0.8383 -- Gen gap 0.0641\n",
      "Epoch 61/100\n",
      "Avg loss: 0.3987 -- Train acc: 0.9023 -- Val acc: 0.8445 -- Test acc: 0.8389 -- Gen gap 0.0635\n",
      "Epoch 62/100\n",
      "Avg loss: 0.3955 -- Train acc: 0.9043 -- Val acc: 0.8448 -- Test acc: 0.8396 -- Gen gap 0.0647\n",
      "Epoch 63/100\n",
      "Avg loss: 0.3881 -- Train acc: 0.9043 -- Val acc: 0.8462 -- Test acc: 0.8401 -- Gen gap 0.0642\n",
      "Epoch 64/100\n",
      "Avg loss: 0.3829 -- Train acc: 0.9043 -- Val acc: 0.8491 -- Test acc: 0.8429 -- Gen gap 0.0614\n",
      "Epoch 65/100\n",
      "Avg loss: 0.3770 -- Train acc: 0.9043 -- Val acc: 0.8492 -- Test acc: 0.8435 -- Gen gap 0.0608\n",
      "Epoch 66/100\n",
      "Avg loss: 0.3682 -- Train acc: 0.9062 -- Val acc: 0.8497 -- Test acc: 0.8428 -- Gen gap 0.0635\n",
      "Epoch 67/100\n",
      "Avg loss: 0.3605 -- Train acc: 0.9062 -- Val acc: 0.8501 -- Test acc: 0.8437 -- Gen gap 0.0626\n",
      "Epoch 68/100\n",
      "Avg loss: 0.3586 -- Train acc: 0.9062 -- Val acc: 0.8519 -- Test acc: 0.8449 -- Gen gap 0.0613\n",
      "Epoch 69/100\n",
      "Avg loss: 0.3529 -- Train acc: 0.9082 -- Val acc: 0.8534 -- Test acc: 0.8458 -- Gen gap 0.0624\n",
      "Epoch 70/100\n",
      "Avg loss: 0.3465 -- Train acc: 0.9082 -- Val acc: 0.8532 -- Test acc: 0.8467 -- Gen gap 0.0615\n",
      "Epoch 71/100\n",
      "Avg loss: 0.3407 -- Train acc: 0.9082 -- Val acc: 0.8534 -- Test acc: 0.8469 -- Gen gap 0.0613\n",
      "Epoch 72/100\n",
      "Avg loss: 0.3373 -- Train acc: 0.9121 -- Val acc: 0.8549 -- Test acc: 0.8482 -- Gen gap 0.0639\n",
      "Epoch 73/100\n",
      "Avg loss: 0.3309 -- Train acc: 0.9121 -- Val acc: 0.8552 -- Test acc: 0.8474 -- Gen gap 0.0647\n",
      "Epoch 74/100\n",
      "Avg loss: 0.3275 -- Train acc: 0.9121 -- Val acc: 0.8537 -- Test acc: 0.8480 -- Gen gap 0.0641\n",
      "Epoch 75/100\n",
      "Avg loss: 0.3218 -- Train acc: 0.9121 -- Val acc: 0.8538 -- Test acc: 0.8490 -- Gen gap 0.0631\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.3196 -- Train acc: 0.9180 -- Val acc: 0.8564 -- Test acc: 0.8497 -- Gen gap 0.0682\n",
      "Epoch 77/100\n",
      "Avg loss: 0.3158 -- Train acc: 0.9180 -- Val acc: 0.8570 -- Test acc: 0.8510 -- Gen gap 0.0670\n",
      "Epoch 78/100\n",
      "Avg loss: 0.3083 -- Train acc: 0.9180 -- Val acc: 0.8566 -- Test acc: 0.8508 -- Gen gap 0.0672\n",
      "Epoch 79/100\n",
      "Avg loss: 0.3070 -- Train acc: 0.9180 -- Val acc: 0.8571 -- Test acc: 0.8513 -- Gen gap 0.0667\n",
      "Epoch 80/100\n",
      "Avg loss: 0.3038 -- Train acc: 0.9219 -- Val acc: 0.8585 -- Test acc: 0.8532 -- Gen gap 0.0687\n",
      "Epoch 81/100\n",
      "Avg loss: 0.2975 -- Train acc: 0.9219 -- Val acc: 0.8578 -- Test acc: 0.8525 -- Gen gap 0.0694\n",
      "Epoch 82/100\n",
      "Avg loss: 0.2948 -- Train acc: 0.9238 -- Val acc: 0.8567 -- Test acc: 0.8515 -- Gen gap 0.0723\n",
      "Epoch 83/100\n",
      "Avg loss: 0.2893 -- Train acc: 0.9238 -- Val acc: 0.8597 -- Test acc: 0.8543 -- Gen gap 0.0695\n",
      "Epoch 84/100\n",
      "Avg loss: 0.2859 -- Train acc: 0.9199 -- Val acc: 0.8595 -- Test acc: 0.8539 -- Gen gap 0.0660\n",
      "Epoch 85/100\n",
      "Avg loss: 0.2842 -- Train acc: 0.9219 -- Val acc: 0.8598 -- Test acc: 0.8534 -- Gen gap 0.0685\n",
      "Epoch 86/100\n",
      "Avg loss: 0.2770 -- Train acc: 0.9297 -- Val acc: 0.8594 -- Test acc: 0.8543 -- Gen gap 0.0754\n",
      "Epoch 87/100\n",
      "Avg loss: 0.2757 -- Train acc: 0.9277 -- Val acc: 0.8604 -- Test acc: 0.8553 -- Gen gap 0.0724\n",
      "Epoch 88/100\n",
      "Avg loss: 0.2694 -- Train acc: 0.9316 -- Val acc: 0.8608 -- Test acc: 0.8556 -- Gen gap 0.0760\n",
      "Epoch 89/100\n",
      "Avg loss: 0.2664 -- Train acc: 0.9277 -- Val acc: 0.8605 -- Test acc: 0.8548 -- Gen gap 0.0729\n",
      "Epoch 90/100\n",
      "Avg loss: 0.2625 -- Train acc: 0.9297 -- Val acc: 0.8603 -- Test acc: 0.8552 -- Gen gap 0.0745\n",
      "Epoch 91/100\n",
      "Avg loss: 0.2599 -- Train acc: 0.9316 -- Val acc: 0.8605 -- Test acc: 0.8554 -- Gen gap 0.0762\n",
      "Epoch 92/100\n",
      "Avg loss: 0.2571 -- Train acc: 0.9355 -- Val acc: 0.8609 -- Test acc: 0.8553 -- Gen gap 0.0803\n",
      "Epoch 93/100\n",
      "Avg loss: 0.2540 -- Train acc: 0.9316 -- Val acc: 0.8615 -- Test acc: 0.8556 -- Gen gap 0.0760\n",
      "Epoch 94/100\n",
      "Avg loss: 0.2527 -- Train acc: 0.9375 -- Val acc: 0.8612 -- Test acc: 0.8561 -- Gen gap 0.0814\n",
      "Epoch 95/100\n",
      "Avg loss: 0.2457 -- Train acc: 0.9375 -- Val acc: 0.8612 -- Test acc: 0.8555 -- Gen gap 0.0820\n",
      "Epoch 96/100\n",
      "Avg loss: 0.2451 -- Train acc: 0.9375 -- Val acc: 0.8620 -- Test acc: 0.8559 -- Gen gap 0.0816\n",
      "Epoch 97/100\n",
      "Avg loss: 0.2404 -- Train acc: 0.9375 -- Val acc: 0.8622 -- Test acc: 0.8570 -- Gen gap 0.0805\n",
      "Epoch 98/100\n",
      "Avg loss: 0.2396 -- Train acc: 0.9375 -- Val acc: 0.8631 -- Test acc: 0.8568 -- Gen gap 0.0807\n",
      "Epoch 99/100\n",
      "Avg loss: 0.2358 -- Train acc: 0.9395 -- Val acc: 0.8627 -- Test acc: 0.8570 -- Gen gap 0.0825\n",
      "Epoch 100/100\n",
      "Avg loss: 0.2336 -- Train acc: 0.9395 -- Val acc: 0.8627 -- Test acc: 0.8570 -- Gen gap 0.0825\n",
      "Training done! Elapsed time: 0:00:15\n",
      "\n",
      "Iter 2\n",
      "Epoch 1/100\n",
      "Avg loss: 0.4437 -- Train acc: 0.8535 -- Val acc: 0.8646 -- Test acc: 0.8615 -- Gen gap -0.0079\n",
      "Epoch 2/100\n",
      "Avg loss: 0.4312 -- Train acc: 0.8594 -- Val acc: 0.8660 -- Test acc: 0.8629 -- Gen gap -0.0035\n",
      "Epoch 3/100\n",
      "Avg loss: 0.4227 -- Train acc: 0.8711 -- Val acc: 0.8688 -- Test acc: 0.8640 -- Gen gap 0.0071\n",
      "Epoch 4/100\n",
      "Avg loss: 0.4095 -- Train acc: 0.8789 -- Val acc: 0.8695 -- Test acc: 0.8655 -- Gen gap 0.0134\n",
      "Epoch 5/100\n",
      "Avg loss: 0.3985 -- Train acc: 0.8789 -- Val acc: 0.8703 -- Test acc: 0.8673 -- Gen gap 0.0116\n",
      "Epoch 6/100\n",
      "Avg loss: 0.3920 -- Train acc: 0.8828 -- Val acc: 0.8705 -- Test acc: 0.8678 -- Gen gap 0.0150\n",
      "Epoch 7/100\n",
      "Avg loss: 0.3824 -- Train acc: 0.8867 -- Val acc: 0.8710 -- Test acc: 0.8686 -- Gen gap 0.0181\n",
      "Epoch 8/100\n",
      "Avg loss: 0.3717 -- Train acc: 0.8848 -- Val acc: 0.8742 -- Test acc: 0.8700 -- Gen gap 0.0147\n",
      "Epoch 9/100\n",
      "Avg loss: 0.3634 -- Train acc: 0.8887 -- Val acc: 0.8730 -- Test acc: 0.8687 -- Gen gap 0.0199\n",
      "Epoch 10/100\n",
      "Avg loss: 0.3556 -- Train acc: 0.8887 -- Val acc: 0.8747 -- Test acc: 0.8697 -- Gen gap 0.0189\n",
      "Epoch 11/100\n",
      "Avg loss: 0.3539 -- Train acc: 0.8926 -- Val acc: 0.8749 -- Test acc: 0.8699 -- Gen gap 0.0227\n",
      "Epoch 12/100\n",
      "Avg loss: 0.3441 -- Train acc: 0.8906 -- Val acc: 0.8767 -- Test acc: 0.8720 -- Gen gap 0.0186\n",
      "Epoch 13/100\n",
      "Avg loss: 0.3385 -- Train acc: 0.8984 -- Val acc: 0.8760 -- Test acc: 0.8703 -- Gen gap 0.0281\n",
      "Epoch 14/100\n",
      "Avg loss: 0.3339 -- Train acc: 0.9023 -- Val acc: 0.8768 -- Test acc: 0.8719 -- Gen gap 0.0304\n",
      "Epoch 15/100\n",
      "Avg loss: 0.3246 -- Train acc: 0.9043 -- Val acc: 0.8758 -- Test acc: 0.8709 -- Gen gap 0.0334\n",
      "Epoch 16/100\n",
      "Avg loss: 0.3183 -- Train acc: 0.9043 -- Val acc: 0.8778 -- Test acc: 0.8732 -- Gen gap 0.0311\n",
      "Epoch 17/100\n",
      "Avg loss: 0.3111 -- Train acc: 0.9043 -- Val acc: 0.8780 -- Test acc: 0.8742 -- Gen gap 0.0301\n",
      "Epoch 18/100\n",
      "Avg loss: 0.3092 -- Train acc: 0.9082 -- Val acc: 0.8775 -- Test acc: 0.8736 -- Gen gap 0.0346\n",
      "Epoch 19/100\n",
      "Avg loss: 0.3026 -- Train acc: 0.9141 -- Val acc: 0.8776 -- Test acc: 0.8711 -- Gen gap 0.0429\n",
      "Epoch 20/100\n",
      "Avg loss: 0.2991 -- Train acc: 0.9160 -- Val acc: 0.8773 -- Test acc: 0.8733 -- Gen gap 0.0427\n",
      "Epoch 21/100\n",
      "Avg loss: 0.2924 -- Train acc: 0.9160 -- Val acc: 0.8783 -- Test acc: 0.8755 -- Gen gap 0.0405\n",
      "Epoch 22/100\n",
      "Avg loss: 0.2883 -- Train acc: 0.9160 -- Val acc: 0.8772 -- Test acc: 0.8742 -- Gen gap 0.0418\n",
      "Epoch 23/100\n",
      "Avg loss: 0.2811 -- Train acc: 0.9199 -- Val acc: 0.8785 -- Test acc: 0.8741 -- Gen gap 0.0458\n",
      "Epoch 24/100\n",
      "Avg loss: 0.2784 -- Train acc: 0.9180 -- Val acc: 0.8789 -- Test acc: 0.8742 -- Gen gap 0.0438\n",
      "Epoch 25/100\n",
      "Avg loss: 0.2726 -- Train acc: 0.9238 -- Val acc: 0.8786 -- Test acc: 0.8754 -- Gen gap 0.0484\n",
      "Epoch 26/100\n",
      "Avg loss: 0.2676 -- Train acc: 0.9238 -- Val acc: 0.8786 -- Test acc: 0.8754 -- Gen gap 0.0484\n",
      "Epoch 27/100\n",
      "Avg loss: 0.2667 -- Train acc: 0.9258 -- Val acc: 0.8791 -- Test acc: 0.8743 -- Gen gap 0.0515\n",
      "Epoch 28/100\n",
      "Avg loss: 0.2596 -- Train acc: 0.9258 -- Val acc: 0.8792 -- Test acc: 0.8744 -- Gen gap 0.0514\n",
      "Epoch 29/100\n",
      "Avg loss: 0.2563 -- Train acc: 0.9297 -- Val acc: 0.8797 -- Test acc: 0.8754 -- Gen gap 0.0543\n",
      "Epoch 30/100\n",
      "Avg loss: 0.2528 -- Train acc: 0.9297 -- Val acc: 0.8789 -- Test acc: 0.8752 -- Gen gap 0.0545\n",
      "Epoch 31/100\n",
      "Avg loss: 0.2515 -- Train acc: 0.9297 -- Val acc: 0.8800 -- Test acc: 0.8762 -- Gen gap 0.0535\n",
      "Epoch 32/100\n",
      "Avg loss: 0.2444 -- Train acc: 0.9297 -- Val acc: 0.8799 -- Test acc: 0.8747 -- Gen gap 0.0550\n",
      "Epoch 33/100\n",
      "Avg loss: 0.2418 -- Train acc: 0.9316 -- Val acc: 0.8790 -- Test acc: 0.8747 -- Gen gap 0.0569\n",
      "Epoch 34/100\n",
      "Avg loss: 0.2368 -- Train acc: 0.9297 -- Val acc: 0.8800 -- Test acc: 0.8753 -- Gen gap 0.0544\n",
      "Epoch 35/100\n",
      "Avg loss: 0.2334 -- Train acc: 0.9336 -- Val acc: 0.8793 -- Test acc: 0.8750 -- Gen gap 0.0586\n",
      "Epoch 36/100\n",
      "Avg loss: 0.2320 -- Train acc: 0.9316 -- Val acc: 0.8798 -- Test acc: 0.8750 -- Gen gap 0.0566\n",
      "Epoch 37/100\n",
      "Avg loss: 0.2264 -- Train acc: 0.9316 -- Val acc: 0.8798 -- Test acc: 0.8754 -- Gen gap 0.0562\n",
      "Epoch 38/100\n",
      "Avg loss: 0.2242 -- Train acc: 0.9355 -- Val acc: 0.8811 -- Test acc: 0.8757 -- Gen gap 0.0599\n",
      "Epoch 39/100\n",
      "Avg loss: 0.2208 -- Train acc: 0.9395 -- Val acc: 0.8807 -- Test acc: 0.8755 -- Gen gap 0.0640\n",
      "Epoch 40/100\n",
      "Avg loss: 0.2175 -- Train acc: 0.9375 -- Val acc: 0.8799 -- Test acc: 0.8752 -- Gen gap 0.0623\n",
      "Epoch 41/100\n",
      "Avg loss: 0.2150 -- Train acc: 0.9395 -- Val acc: 0.8787 -- Test acc: 0.8746 -- Gen gap 0.0649\n",
      "Epoch 42/100\n",
      "Avg loss: 0.2130 -- Train acc: 0.9414 -- Val acc: 0.8799 -- Test acc: 0.8751 -- Gen gap 0.0663\n",
      "Epoch 43/100\n",
      "Avg loss: 0.2072 -- Train acc: 0.9414 -- Val acc: 0.8799 -- Test acc: 0.8752 -- Gen gap 0.0662\n",
      "Epoch 44/100\n",
      "Avg loss: 0.2055 -- Train acc: 0.9414 -- Val acc: 0.8792 -- Test acc: 0.8745 -- Gen gap 0.0669\n",
      "Epoch 45/100\n",
      "Avg loss: 0.2041 -- Train acc: 0.9414 -- Val acc: 0.8800 -- Test acc: 0.8751 -- Gen gap 0.0663\n",
      "Epoch 46/100\n",
      "Avg loss: 0.2008 -- Train acc: 0.9434 -- Val acc: 0.8798 -- Test acc: 0.8750 -- Gen gap 0.0684\n",
      "Epoch 47/100\n",
      "Avg loss: 0.1986 -- Train acc: 0.9414 -- Val acc: 0.8802 -- Test acc: 0.8759 -- Gen gap 0.0655\n",
      "Epoch 48/100\n",
      "Avg loss: 0.1941 -- Train acc: 0.9453 -- Val acc: 0.8796 -- Test acc: 0.8753 -- Gen gap 0.0700\n",
      "Epoch 49/100\n",
      "Avg loss: 0.1918 -- Train acc: 0.9492 -- Val acc: 0.8794 -- Test acc: 0.8748 -- Gen gap 0.0744\n",
      "Epoch 50/100\n",
      "Avg loss: 0.1895 -- Train acc: 0.9473 -- Val acc: 0.8802 -- Test acc: 0.8748 -- Gen gap 0.0725\n",
      "Epoch 51/100\n",
      "Avg loss: 0.1873 -- Train acc: 0.9473 -- Val acc: 0.8803 -- Test acc: 0.8749 -- Gen gap 0.0724\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.1843 -- Train acc: 0.9473 -- Val acc: 0.8810 -- Test acc: 0.8754 -- Gen gap 0.0719\n",
      "Epoch 53/100\n",
      "Avg loss: 0.1829 -- Train acc: 0.9512 -- Val acc: 0.8811 -- Test acc: 0.8755 -- Gen gap 0.0757\n",
      "Epoch 54/100\n",
      "Avg loss: 0.1801 -- Train acc: 0.9492 -- Val acc: 0.8797 -- Test acc: 0.8747 -- Gen gap 0.0745\n",
      "Epoch 55/100\n",
      "Avg loss: 0.1767 -- Train acc: 0.9551 -- Val acc: 0.8793 -- Test acc: 0.8747 -- Gen gap 0.0804\n",
      "Epoch 56/100\n",
      "Avg loss: 0.1758 -- Train acc: 0.9531 -- Val acc: 0.8792 -- Test acc: 0.8738 -- Gen gap 0.0793\n",
      "Epoch 57/100\n",
      "Avg loss: 0.1721 -- Train acc: 0.9570 -- Val acc: 0.8808 -- Test acc: 0.8756 -- Gen gap 0.0814\n",
      "Epoch 58/100\n",
      "Avg loss: 0.1704 -- Train acc: 0.9590 -- Val acc: 0.8796 -- Test acc: 0.8754 -- Gen gap 0.0836\n",
      "Epoch 59/100\n",
      "Avg loss: 0.1674 -- Train acc: 0.9590 -- Val acc: 0.8801 -- Test acc: 0.8760 -- Gen gap 0.0830\n",
      "Epoch 60/100\n",
      "Avg loss: 0.1657 -- Train acc: 0.9609 -- Val acc: 0.8814 -- Test acc: 0.8755 -- Gen gap 0.0854\n",
      "Epoch 61/100\n",
      "Avg loss: 0.1644 -- Train acc: 0.9609 -- Val acc: 0.8805 -- Test acc: 0.8752 -- Gen gap 0.0857\n",
      "Epoch 62/100\n",
      "Avg loss: 0.1614 -- Train acc: 0.9609 -- Val acc: 0.8809 -- Test acc: 0.8755 -- Gen gap 0.0854\n",
      "Epoch 63/100\n",
      "Avg loss: 0.1597 -- Train acc: 0.9629 -- Val acc: 0.8808 -- Test acc: 0.8756 -- Gen gap 0.0873\n",
      "Epoch 64/100\n",
      "Avg loss: 0.1610 -- Train acc: 0.9609 -- Val acc: 0.8794 -- Test acc: 0.8753 -- Gen gap 0.0856\n",
      "Epoch 65/100\n",
      "Avg loss: 0.1557 -- Train acc: 0.9629 -- Val acc: 0.8799 -- Test acc: 0.8757 -- Gen gap 0.0872\n",
      "Epoch 66/100\n",
      "Avg loss: 0.1535 -- Train acc: 0.9609 -- Val acc: 0.8800 -- Test acc: 0.8757 -- Gen gap 0.0852\n",
      "Epoch 67/100\n",
      "Avg loss: 0.1505 -- Train acc: 0.9609 -- Val acc: 0.8790 -- Test acc: 0.8754 -- Gen gap 0.0855\n",
      "Epoch 68/100\n",
      "Avg loss: 0.1515 -- Train acc: 0.9648 -- Val acc: 0.8809 -- Test acc: 0.8764 -- Gen gap 0.0885\n",
      "Epoch 69/100\n",
      "Avg loss: 0.1471 -- Train acc: 0.9648 -- Val acc: 0.8808 -- Test acc: 0.8766 -- Gen gap 0.0883\n",
      "Epoch 70/100\n",
      "Avg loss: 0.1481 -- Train acc: 0.9668 -- Val acc: 0.8806 -- Test acc: 0.8753 -- Gen gap 0.0915\n",
      "Epoch 71/100\n",
      "Avg loss: 0.1442 -- Train acc: 0.9648 -- Val acc: 0.8797 -- Test acc: 0.8755 -- Gen gap 0.0893\n",
      "Epoch 72/100\n",
      "Avg loss: 0.1437 -- Train acc: 0.9668 -- Val acc: 0.8784 -- Test acc: 0.8754 -- Gen gap 0.0914\n",
      "Epoch 73/100\n",
      "Avg loss: 0.1414 -- Train acc: 0.9668 -- Val acc: 0.8799 -- Test acc: 0.8755 -- Gen gap 0.0913\n",
      "Epoch 74/100\n",
      "Avg loss: 0.1397 -- Train acc: 0.9668 -- Val acc: 0.8799 -- Test acc: 0.8757 -- Gen gap 0.0911\n",
      "Epoch 75/100\n",
      "Avg loss: 0.1377 -- Train acc: 0.9668 -- Val acc: 0.8793 -- Test acc: 0.8751 -- Gen gap 0.0917\n",
      "Epoch 76/100\n",
      "Avg loss: 0.1360 -- Train acc: 0.9668 -- Val acc: 0.8791 -- Test acc: 0.8753 -- Gen gap 0.0915\n",
      "Epoch 77/100\n",
      "Avg loss: 0.1347 -- Train acc: 0.9668 -- Val acc: 0.8793 -- Test acc: 0.8755 -- Gen gap 0.0913\n",
      "Epoch 78/100\n",
      "Avg loss: 0.1323 -- Train acc: 0.9668 -- Val acc: 0.8795 -- Test acc: 0.8754 -- Gen gap 0.0914\n",
      "Epoch 79/100\n",
      "Avg loss: 0.1315 -- Train acc: 0.9668 -- Val acc: 0.8792 -- Test acc: 0.8749 -- Gen gap 0.0919\n",
      "Epoch 80/100\n",
      "Avg loss: 0.1298 -- Train acc: 0.9668 -- Val acc: 0.8798 -- Test acc: 0.8750 -- Gen gap 0.0918\n",
      "Epoch 81/100\n",
      "Avg loss: 0.1286 -- Train acc: 0.9668 -- Val acc: 0.8790 -- Test acc: 0.8743 -- Gen gap 0.0925\n",
      "Epoch 82/100\n",
      "Avg loss: 0.1267 -- Train acc: 0.9668 -- Val acc: 0.8793 -- Test acc: 0.8748 -- Gen gap 0.0920\n",
      "Epoch 83/100\n",
      "Avg loss: 0.1244 -- Train acc: 0.9668 -- Val acc: 0.8805 -- Test acc: 0.8746 -- Gen gap 0.0922\n",
      "Epoch 84/100\n",
      "Avg loss: 0.1244 -- Train acc: 0.9688 -- Val acc: 0.8798 -- Test acc: 0.8746 -- Gen gap 0.0941\n",
      "Epoch 85/100\n",
      "Avg loss: 0.1217 -- Train acc: 0.9688 -- Val acc: 0.8797 -- Test acc: 0.8743 -- Gen gap 0.0944\n",
      "Epoch 86/100\n",
      "Avg loss: 0.1209 -- Train acc: 0.9688 -- Val acc: 0.8804 -- Test acc: 0.8739 -- Gen gap 0.0948\n",
      "Epoch 87/100\n",
      "Avg loss: 0.1196 -- Train acc: 0.9688 -- Val acc: 0.8805 -- Test acc: 0.8741 -- Gen gap 0.0946\n",
      "Epoch 88/100\n",
      "Avg loss: 0.1176 -- Train acc: 0.9688 -- Val acc: 0.8810 -- Test acc: 0.8746 -- Gen gap 0.0941\n",
      "Epoch 89/100\n",
      "Avg loss: 0.1181 -- Train acc: 0.9688 -- Val acc: 0.8799 -- Test acc: 0.8740 -- Gen gap 0.0947\n",
      "Epoch 90/100\n",
      "Avg loss: 0.1157 -- Train acc: 0.9688 -- Val acc: 0.8797 -- Test acc: 0.8743 -- Gen gap 0.0944\n",
      "Epoch 91/100\n",
      "Avg loss: 0.1137 -- Train acc: 0.9688 -- Val acc: 0.8801 -- Test acc: 0.8738 -- Gen gap 0.0949\n",
      "Epoch 92/100\n",
      "Avg loss: 0.1119 -- Train acc: 0.9688 -- Val acc: 0.8807 -- Test acc: 0.8739 -- Gen gap 0.0948\n",
      "Epoch 93/100\n",
      "Avg loss: 0.1128 -- Train acc: 0.9688 -- Val acc: 0.8800 -- Test acc: 0.8741 -- Gen gap 0.0946\n",
      "Epoch 94/100\n",
      "Avg loss: 0.1103 -- Train acc: 0.9688 -- Val acc: 0.8802 -- Test acc: 0.8746 -- Gen gap 0.0941\n",
      "Epoch 95/100\n",
      "Avg loss: 0.1096 -- Train acc: 0.9688 -- Val acc: 0.8804 -- Test acc: 0.8739 -- Gen gap 0.0948\n",
      "Epoch 96/100\n",
      "Avg loss: 0.1091 -- Train acc: 0.9688 -- Val acc: 0.8803 -- Test acc: 0.8737 -- Gen gap 0.0950\n",
      "Epoch 97/100\n",
      "Avg loss: 0.1079 -- Train acc: 0.9688 -- Val acc: 0.8800 -- Test acc: 0.8747 -- Gen gap 0.0940\n",
      "Epoch 98/100\n",
      "Avg loss: 0.1057 -- Train acc: 0.9688 -- Val acc: 0.8796 -- Test acc: 0.8743 -- Gen gap 0.0944\n",
      "Epoch 99/100\n",
      "Avg loss: 0.1068 -- Train acc: 0.9688 -- Val acc: 0.8796 -- Test acc: 0.8747 -- Gen gap 0.0940\n",
      "Epoch 100/100\n",
      "Avg loss: 0.1032 -- Train acc: 0.9707 -- Val acc: 0.8798 -- Test acc: 0.8741 -- Gen gap 0.0966\n",
      "Training done! Elapsed time: 0:00:16\n",
      "\n",
      "Iter 3\n",
      "Epoch 1/100\n",
      "Avg loss: 0.4227 -- Train acc: 0.8750 -- Val acc: 0.8833 -- Test acc: 0.8788 -- Gen gap -0.0038\n",
      "Epoch 2/100\n",
      "Avg loss: 0.4049 -- Train acc: 0.8770 -- Val acc: 0.8835 -- Test acc: 0.8775 -- Gen gap -0.0005\n",
      "Epoch 3/100\n",
      "Avg loss: 0.3916 -- Train acc: 0.8789 -- Val acc: 0.8807 -- Test acc: 0.8753 -- Gen gap 0.0036\n",
      "Epoch 4/100\n",
      "Avg loss: 0.3781 -- Train acc: 0.8848 -- Val acc: 0.8833 -- Test acc: 0.8778 -- Gen gap 0.0070\n",
      "Epoch 5/100\n",
      "Avg loss: 0.3622 -- Train acc: 0.8887 -- Val acc: 0.8840 -- Test acc: 0.8789 -- Gen gap 0.0098\n",
      "Epoch 6/100\n",
      "Avg loss: 0.3480 -- Train acc: 0.8945 -- Val acc: 0.8840 -- Test acc: 0.8796 -- Gen gap 0.0150\n",
      "Epoch 7/100\n",
      "Avg loss: 0.3398 -- Train acc: 0.8926 -- Val acc: 0.8859 -- Test acc: 0.8806 -- Gen gap 0.0120\n",
      "Epoch 8/100\n",
      "Avg loss: 0.3379 -- Train acc: 0.8965 -- Val acc: 0.8854 -- Test acc: 0.8825 -- Gen gap 0.0140\n",
      "Epoch 9/100\n",
      "Avg loss: 0.3231 -- Train acc: 0.8965 -- Val acc: 0.8841 -- Test acc: 0.8823 -- Gen gap 0.0142\n",
      "Epoch 10/100\n",
      "Avg loss: 0.3132 -- Train acc: 0.8984 -- Val acc: 0.8861 -- Test acc: 0.8841 -- Gen gap 0.0144\n",
      "Epoch 11/100\n",
      "Avg loss: 0.3065 -- Train acc: 0.8984 -- Val acc: 0.8855 -- Test acc: 0.8828 -- Gen gap 0.0157\n",
      "Epoch 12/100\n",
      "Avg loss: 0.3008 -- Train acc: 0.8984 -- Val acc: 0.8846 -- Test acc: 0.8835 -- Gen gap 0.0150\n",
      "Epoch 13/100\n",
      "Avg loss: 0.2917 -- Train acc: 0.8984 -- Val acc: 0.8857 -- Test acc: 0.8840 -- Gen gap 0.0145\n",
      "Epoch 14/100\n",
      "Avg loss: 0.2856 -- Train acc: 0.9004 -- Val acc: 0.8855 -- Test acc: 0.8842 -- Gen gap 0.0162\n",
      "Epoch 15/100\n",
      "Avg loss: 0.2773 -- Train acc: 0.9023 -- Val acc: 0.8866 -- Test acc: 0.8834 -- Gen gap 0.0190\n",
      "Epoch 16/100\n",
      "Avg loss: 0.2751 -- Train acc: 0.9043 -- Val acc: 0.8860 -- Test acc: 0.8838 -- Gen gap 0.0205\n",
      "Epoch 17/100\n",
      "Avg loss: 0.2679 -- Train acc: 0.9023 -- Val acc: 0.8847 -- Test acc: 0.8839 -- Gen gap 0.0185\n",
      "Epoch 18/100\n",
      "Avg loss: 0.2665 -- Train acc: 0.9062 -- Val acc: 0.8866 -- Test acc: 0.8839 -- Gen gap 0.0224\n",
      "Epoch 19/100\n",
      "Avg loss: 0.2582 -- Train acc: 0.9082 -- Val acc: 0.8865 -- Test acc: 0.8849 -- Gen gap 0.0234\n",
      "Epoch 20/100\n",
      "Avg loss: 0.2552 -- Train acc: 0.9082 -- Val acc: 0.8849 -- Test acc: 0.8838 -- Gen gap 0.0244\n",
      "Epoch 21/100\n",
      "Avg loss: 0.2476 -- Train acc: 0.9102 -- Val acc: 0.8861 -- Test acc: 0.8847 -- Gen gap 0.0255\n",
      "Epoch 22/100\n",
      "Avg loss: 0.2438 -- Train acc: 0.9121 -- Val acc: 0.8854 -- Test acc: 0.8846 -- Gen gap 0.0276\n",
      "Epoch 23/100\n",
      "Avg loss: 0.2440 -- Train acc: 0.9160 -- Val acc: 0.8864 -- Test acc: 0.8860 -- Gen gap 0.0300\n",
      "Epoch 24/100\n",
      "Avg loss: 0.2343 -- Train acc: 0.9160 -- Val acc: 0.8859 -- Test acc: 0.8861 -- Gen gap 0.0299\n",
      "Epoch 25/100\n",
      "Avg loss: 0.2302 -- Train acc: 0.9141 -- Val acc: 0.8857 -- Test acc: 0.8850 -- Gen gap 0.0291\n",
      "Epoch 26/100\n",
      "Avg loss: 0.2248 -- Train acc: 0.9238 -- Val acc: 0.8869 -- Test acc: 0.8851 -- Gen gap 0.0388\n",
      "Epoch 27/100\n",
      "Avg loss: 0.2195 -- Train acc: 0.9238 -- Val acc: 0.8871 -- Test acc: 0.8849 -- Gen gap 0.0390\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.2143 -- Train acc: 0.9258 -- Val acc: 0.8856 -- Test acc: 0.8850 -- Gen gap 0.0408\n",
      "Epoch 29/100\n",
      "Avg loss: 0.2168 -- Train acc: 0.9238 -- Val acc: 0.8866 -- Test acc: 0.8855 -- Gen gap 0.0383\n",
      "Epoch 30/100\n",
      "Avg loss: 0.2125 -- Train acc: 0.9355 -- Val acc: 0.8876 -- Test acc: 0.8860 -- Gen gap 0.0495\n",
      "Epoch 31/100\n",
      "Avg loss: 0.2078 -- Train acc: 0.9336 -- Val acc: 0.8882 -- Test acc: 0.8858 -- Gen gap 0.0477\n",
      "Epoch 32/100\n",
      "Avg loss: 0.2077 -- Train acc: 0.9375 -- Val acc: 0.8880 -- Test acc: 0.8867 -- Gen gap 0.0508\n",
      "Epoch 33/100\n",
      "Avg loss: 0.1993 -- Train acc: 0.9375 -- Val acc: 0.8876 -- Test acc: 0.8861 -- Gen gap 0.0514\n",
      "Epoch 34/100\n",
      "Avg loss: 0.1976 -- Train acc: 0.9395 -- Val acc: 0.8879 -- Test acc: 0.8857 -- Gen gap 0.0537\n",
      "Epoch 35/100\n",
      "Avg loss: 0.1928 -- Train acc: 0.9395 -- Val acc: 0.8872 -- Test acc: 0.8859 -- Gen gap 0.0535\n",
      "Epoch 36/100\n",
      "Avg loss: 0.1918 -- Train acc: 0.9395 -- Val acc: 0.8874 -- Test acc: 0.8864 -- Gen gap 0.0530\n",
      "Epoch 37/100\n",
      "Avg loss: 0.1892 -- Train acc: 0.9414 -- Val acc: 0.8869 -- Test acc: 0.8855 -- Gen gap 0.0559\n",
      "Epoch 38/100\n",
      "Avg loss: 0.1844 -- Train acc: 0.9453 -- Val acc: 0.8879 -- Test acc: 0.8860 -- Gen gap 0.0593\n",
      "Epoch 39/100\n",
      "Avg loss: 0.1822 -- Train acc: 0.9434 -- Val acc: 0.8891 -- Test acc: 0.8861 -- Gen gap 0.0572\n",
      "Epoch 40/100\n",
      "Avg loss: 0.1805 -- Train acc: 0.9453 -- Val acc: 0.8877 -- Test acc: 0.8865 -- Gen gap 0.0588\n",
      "Epoch 41/100\n",
      "Avg loss: 0.1761 -- Train acc: 0.9512 -- Val acc: 0.8879 -- Test acc: 0.8868 -- Gen gap 0.0643\n",
      "Epoch 42/100\n",
      "Avg loss: 0.1739 -- Train acc: 0.9512 -- Val acc: 0.8875 -- Test acc: 0.8865 -- Gen gap 0.0646\n",
      "Epoch 43/100\n",
      "Avg loss: 0.1708 -- Train acc: 0.9512 -- Val acc: 0.8879 -- Test acc: 0.8857 -- Gen gap 0.0654\n",
      "Epoch 44/100\n",
      "Avg loss: 0.1705 -- Train acc: 0.9531 -- Val acc: 0.8884 -- Test acc: 0.8876 -- Gen gap 0.0655\n",
      "Epoch 45/100\n",
      "Avg loss: 0.1663 -- Train acc: 0.9531 -- Val acc: 0.8886 -- Test acc: 0.8880 -- Gen gap 0.0651\n",
      "Epoch 46/100\n",
      "Avg loss: 0.1632 -- Train acc: 0.9531 -- Val acc: 0.8887 -- Test acc: 0.8870 -- Gen gap 0.0661\n",
      "Epoch 47/100\n",
      "Avg loss: 0.1614 -- Train acc: 0.9551 -- Val acc: 0.8882 -- Test acc: 0.8870 -- Gen gap 0.0680\n",
      "Epoch 48/100\n",
      "Avg loss: 0.1593 -- Train acc: 0.9570 -- Val acc: 0.8884 -- Test acc: 0.8876 -- Gen gap 0.0694\n",
      "Epoch 49/100\n",
      "Avg loss: 0.1562 -- Train acc: 0.9551 -- Val acc: 0.8878 -- Test acc: 0.8865 -- Gen gap 0.0685\n",
      "Epoch 50/100\n",
      "Avg loss: 0.1550 -- Train acc: 0.9551 -- Val acc: 0.8880 -- Test acc: 0.8870 -- Gen gap 0.0680\n",
      "Epoch 51/100\n",
      "Avg loss: 0.1513 -- Train acc: 0.9570 -- Val acc: 0.8880 -- Test acc: 0.8875 -- Gen gap 0.0695\n",
      "Epoch 52/100\n",
      "Avg loss: 0.1499 -- Train acc: 0.9570 -- Val acc: 0.8881 -- Test acc: 0.8874 -- Gen gap 0.0696\n",
      "Epoch 53/100\n",
      "Avg loss: 0.1482 -- Train acc: 0.9570 -- Val acc: 0.8879 -- Test acc: 0.8865 -- Gen gap 0.0705\n",
      "Epoch 54/100\n",
      "Avg loss: 0.1459 -- Train acc: 0.9590 -- Val acc: 0.8874 -- Test acc: 0.8868 -- Gen gap 0.0721\n",
      "Epoch 55/100\n",
      "Avg loss: 0.1444 -- Train acc: 0.9570 -- Val acc: 0.8876 -- Test acc: 0.8867 -- Gen gap 0.0703\n",
      "Epoch 56/100\n",
      "Avg loss: 0.1424 -- Train acc: 0.9590 -- Val acc: 0.8879 -- Test acc: 0.8871 -- Gen gap 0.0718\n",
      "Epoch 57/100\n",
      "Avg loss: 0.1403 -- Train acc: 0.9590 -- Val acc: 0.8874 -- Test acc: 0.8873 -- Gen gap 0.0716\n",
      "Epoch 58/100\n",
      "Avg loss: 0.1411 -- Train acc: 0.9590 -- Val acc: 0.8873 -- Test acc: 0.8867 -- Gen gap 0.0722\n",
      "Epoch 59/100\n",
      "Avg loss: 0.1370 -- Train acc: 0.9590 -- Val acc: 0.8878 -- Test acc: 0.8872 -- Gen gap 0.0717\n",
      "Epoch 60/100\n",
      "Avg loss: 0.1357 -- Train acc: 0.9590 -- Val acc: 0.8880 -- Test acc: 0.8866 -- Gen gap 0.0723\n",
      "Epoch 61/100\n",
      "Avg loss: 0.1333 -- Train acc: 0.9609 -- Val acc: 0.8875 -- Test acc: 0.8874 -- Gen gap 0.0735\n",
      "Epoch 62/100\n",
      "Avg loss: 0.1307 -- Train acc: 0.9609 -- Val acc: 0.8881 -- Test acc: 0.8868 -- Gen gap 0.0741\n",
      "Epoch 63/100\n",
      "Avg loss: 0.1295 -- Train acc: 0.9590 -- Val acc: 0.8875 -- Test acc: 0.8867 -- Gen gap 0.0722\n",
      "Epoch 64/100\n",
      "Avg loss: 0.1299 -- Train acc: 0.9609 -- Val acc: 0.8880 -- Test acc: 0.8863 -- Gen gap 0.0746\n",
      "Epoch 65/100\n",
      "Avg loss: 0.1272 -- Train acc: 0.9629 -- Val acc: 0.8874 -- Test acc: 0.8864 -- Gen gap 0.0764\n",
      "Epoch 66/100\n",
      "Avg loss: 0.1273 -- Train acc: 0.9629 -- Val acc: 0.8882 -- Test acc: 0.8864 -- Gen gap 0.0764\n",
      "Epoch 67/100\n",
      "Avg loss: 0.1222 -- Train acc: 0.9629 -- Val acc: 0.8880 -- Test acc: 0.8858 -- Gen gap 0.0770\n",
      "Epoch 68/100\n",
      "Avg loss: 0.1228 -- Train acc: 0.9629 -- Val acc: 0.8875 -- Test acc: 0.8867 -- Gen gap 0.0761\n",
      "Epoch 69/100\n",
      "Avg loss: 0.1204 -- Train acc: 0.9648 -- Val acc: 0.8872 -- Test acc: 0.8860 -- Gen gap 0.0788\n",
      "Epoch 70/100\n",
      "Avg loss: 0.1201 -- Train acc: 0.9668 -- Val acc: 0.8884 -- Test acc: 0.8866 -- Gen gap 0.0802\n",
      "Epoch 71/100\n",
      "Avg loss: 0.1186 -- Train acc: 0.9648 -- Val acc: 0.8876 -- Test acc: 0.8864 -- Gen gap 0.0784\n",
      "Epoch 72/100\n",
      "Avg loss: 0.1164 -- Train acc: 0.9668 -- Val acc: 0.8878 -- Test acc: 0.8863 -- Gen gap 0.0805\n",
      "Epoch 73/100\n",
      "Avg loss: 0.1141 -- Train acc: 0.9668 -- Val acc: 0.8890 -- Test acc: 0.8862 -- Gen gap 0.0806\n",
      "Epoch 74/100\n",
      "Avg loss: 0.1144 -- Train acc: 0.9668 -- Val acc: 0.8876 -- Test acc: 0.8858 -- Gen gap 0.0809\n",
      "Epoch 75/100\n",
      "Avg loss: 0.1135 -- Train acc: 0.9688 -- Val acc: 0.8882 -- Test acc: 0.8864 -- Gen gap 0.0823\n",
      "Epoch 76/100\n",
      "Avg loss: 0.1109 -- Train acc: 0.9688 -- Val acc: 0.8883 -- Test acc: 0.8868 -- Gen gap 0.0819\n",
      "Epoch 77/100\n",
      "Avg loss: 0.1101 -- Train acc: 0.9688 -- Val acc: 0.8885 -- Test acc: 0.8863 -- Gen gap 0.0824\n",
      "Epoch 78/100\n",
      "Avg loss: 0.1076 -- Train acc: 0.9707 -- Val acc: 0.8877 -- Test acc: 0.8866 -- Gen gap 0.0841\n",
      "Epoch 79/100\n",
      "Avg loss: 0.1062 -- Train acc: 0.9707 -- Val acc: 0.8872 -- Test acc: 0.8866 -- Gen gap 0.0841\n",
      "Epoch 80/100\n",
      "Avg loss: 0.1058 -- Train acc: 0.9688 -- Val acc: 0.8882 -- Test acc: 0.8866 -- Gen gap 0.0821\n",
      "Epoch 81/100\n",
      "Avg loss: 0.1047 -- Train acc: 0.9707 -- Val acc: 0.8878 -- Test acc: 0.8861 -- Gen gap 0.0846\n",
      "Epoch 82/100\n",
      "Avg loss: 0.1036 -- Train acc: 0.9707 -- Val acc: 0.8881 -- Test acc: 0.8862 -- Gen gap 0.0845\n",
      "Epoch 83/100\n",
      "Avg loss: 0.1012 -- Train acc: 0.9707 -- Val acc: 0.8878 -- Test acc: 0.8859 -- Gen gap 0.0848\n",
      "Epoch 84/100\n",
      "Avg loss: 0.1024 -- Train acc: 0.9707 -- Val acc: 0.8882 -- Test acc: 0.8861 -- Gen gap 0.0846\n",
      "Epoch 85/100\n",
      "Avg loss: 0.0996 -- Train acc: 0.9707 -- Val acc: 0.8879 -- Test acc: 0.8854 -- Gen gap 0.0854\n",
      "Epoch 86/100\n",
      "Avg loss: 0.0990 -- Train acc: 0.9707 -- Val acc: 0.8888 -- Test acc: 0.8863 -- Gen gap 0.0844\n",
      "Epoch 87/100\n",
      "Avg loss: 0.0969 -- Train acc: 0.9707 -- Val acc: 0.8881 -- Test acc: 0.8870 -- Gen gap 0.0837\n",
      "Epoch 88/100\n",
      "Avg loss: 0.0964 -- Train acc: 0.9707 -- Val acc: 0.8887 -- Test acc: 0.8868 -- Gen gap 0.0839\n",
      "Epoch 89/100\n",
      "Avg loss: 0.0976 -- Train acc: 0.9707 -- Val acc: 0.8885 -- Test acc: 0.8864 -- Gen gap 0.0843\n",
      "Epoch 90/100\n",
      "Avg loss: 0.0949 -- Train acc: 0.9707 -- Val acc: 0.8885 -- Test acc: 0.8866 -- Gen gap 0.0841\n",
      "Epoch 91/100\n",
      "Avg loss: 0.0944 -- Train acc: 0.9707 -- Val acc: 0.8880 -- Test acc: 0.8858 -- Gen gap 0.0849\n",
      "Epoch 92/100\n",
      "Avg loss: 0.0923 -- Train acc: 0.9707 -- Val acc: 0.8884 -- Test acc: 0.8866 -- Gen gap 0.0841\n",
      "Epoch 93/100\n",
      "Avg loss: 0.0909 -- Train acc: 0.9707 -- Val acc: 0.8885 -- Test acc: 0.8864 -- Gen gap 0.0843\n",
      "Epoch 94/100\n",
      "Avg loss: 0.0917 -- Train acc: 0.9707 -- Val acc: 0.8877 -- Test acc: 0.8857 -- Gen gap 0.0850\n",
      "Epoch 95/100\n",
      "Avg loss: 0.0897 -- Train acc: 0.9707 -- Val acc: 0.8874 -- Test acc: 0.8854 -- Gen gap 0.0854\n",
      "Epoch 96/100\n",
      "Avg loss: 0.0883 -- Train acc: 0.9707 -- Val acc: 0.8879 -- Test acc: 0.8855 -- Gen gap 0.0852\n",
      "Epoch 97/100\n",
      "Avg loss: 0.0877 -- Train acc: 0.9707 -- Val acc: 0.8882 -- Test acc: 0.8845 -- Gen gap 0.0862\n",
      "Epoch 98/100\n",
      "Avg loss: 0.0878 -- Train acc: 0.9707 -- Val acc: 0.8881 -- Test acc: 0.8853 -- Gen gap 0.0855\n",
      "Epoch 99/100\n",
      "Avg loss: 0.0854 -- Train acc: 0.9707 -- Val acc: 0.8880 -- Test acc: 0.8851 -- Gen gap 0.0857\n",
      "Epoch 100/100\n",
      "Avg loss: 0.0853 -- Train acc: 0.9707 -- Val acc: 0.8892 -- Test acc: 0.8854 -- Gen gap 0.0853\n",
      "Training done! Elapsed time: 0:00:14\n",
      "\n",
      "==============================\n",
      "a = 0.02, Na = 1000\n",
      "------------------------------\n",
      "Iter 1\n",
      "Epoch 1/100\n",
      "Avg loss: 0.3878 -- Train acc: 0.8760 -- Val acc: 0.8900 -- Test acc: 0.8888 -- Gen gap -0.0129\n",
      "Epoch 2/100\n",
      "Avg loss: 0.3659 -- Train acc: 0.8828 -- Val acc: 0.8948 -- Test acc: 0.8923 -- Gen gap -0.0095\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.3424 -- Train acc: 0.8848 -- Val acc: 0.8954 -- Test acc: 0.8925 -- Gen gap -0.0078\n",
      "Epoch 4/100\n",
      "Avg loss: 0.3295 -- Train acc: 0.8838 -- Val acc: 0.8956 -- Test acc: 0.8939 -- Gen gap -0.0101\n",
      "Epoch 5/100\n",
      "Avg loss: 0.3200 -- Train acc: 0.8906 -- Val acc: 0.8985 -- Test acc: 0.8947 -- Gen gap -0.0041\n",
      "Epoch 6/100\n",
      "Avg loss: 0.3012 -- Train acc: 0.8955 -- Val acc: 0.8986 -- Test acc: 0.8953 -- Gen gap 0.0002\n",
      "Epoch 7/100\n",
      "Avg loss: 0.3041 -- Train acc: 0.8936 -- Val acc: 0.8974 -- Test acc: 0.8950 -- Gen gap -0.0014\n",
      "Epoch 8/100\n",
      "Avg loss: 0.2852 -- Train acc: 0.8984 -- Val acc: 0.9008 -- Test acc: 0.8983 -- Gen gap 0.0001\n",
      "Epoch 9/100\n",
      "Avg loss: 0.2808 -- Train acc: 0.9043 -- Val acc: 0.9006 -- Test acc: 0.8976 -- Gen gap 0.0067\n",
      "Epoch 10/100\n",
      "Avg loss: 0.2709 -- Train acc: 0.9082 -- Val acc: 0.9014 -- Test acc: 0.8960 -- Gen gap 0.0122\n",
      "Epoch 11/100\n",
      "Avg loss: 0.2639 -- Train acc: 0.9082 -- Val acc: 0.9022 -- Test acc: 0.8987 -- Gen gap 0.0095\n",
      "Epoch 12/100\n",
      "Avg loss: 0.2644 -- Train acc: 0.9092 -- Val acc: 0.9006 -- Test acc: 0.8973 -- Gen gap 0.0119\n",
      "Epoch 13/100\n",
      "Avg loss: 0.2516 -- Train acc: 0.9111 -- Val acc: 0.9024 -- Test acc: 0.8994 -- Gen gap 0.0117\n",
      "Epoch 14/100\n",
      "Avg loss: 0.2509 -- Train acc: 0.9150 -- Val acc: 0.9026 -- Test acc: 0.9004 -- Gen gap 0.0147\n",
      "Epoch 15/100\n",
      "Avg loss: 0.2380 -- Train acc: 0.9199 -- Val acc: 0.9038 -- Test acc: 0.8994 -- Gen gap 0.0205\n",
      "Epoch 16/100\n",
      "Avg loss: 0.2347 -- Train acc: 0.9199 -- Val acc: 0.9033 -- Test acc: 0.9009 -- Gen gap 0.0190\n",
      "Epoch 17/100\n",
      "Avg loss: 0.2316 -- Train acc: 0.9189 -- Val acc: 0.9043 -- Test acc: 0.9010 -- Gen gap 0.0180\n",
      "Epoch 18/100\n",
      "Avg loss: 0.2244 -- Train acc: 0.9199 -- Val acc: 0.9038 -- Test acc: 0.9006 -- Gen gap 0.0193\n",
      "Epoch 19/100\n",
      "Avg loss: 0.2189 -- Train acc: 0.9258 -- Val acc: 0.9049 -- Test acc: 0.8998 -- Gen gap 0.0260\n",
      "Epoch 20/100\n",
      "Avg loss: 0.2171 -- Train acc: 0.9268 -- Val acc: 0.9044 -- Test acc: 0.9004 -- Gen gap 0.0264\n",
      "Epoch 21/100\n",
      "Avg loss: 0.2124 -- Train acc: 0.9297 -- Val acc: 0.9042 -- Test acc: 0.9000 -- Gen gap 0.0297\n",
      "Epoch 22/100\n",
      "Avg loss: 0.2089 -- Train acc: 0.9297 -- Val acc: 0.9043 -- Test acc: 0.8998 -- Gen gap 0.0299\n",
      "Epoch 23/100\n",
      "Avg loss: 0.2062 -- Train acc: 0.9336 -- Val acc: 0.9037 -- Test acc: 0.9010 -- Gen gap 0.0326\n",
      "Epoch 24/100\n",
      "Avg loss: 0.1977 -- Train acc: 0.9346 -- Val acc: 0.9041 -- Test acc: 0.8998 -- Gen gap 0.0348\n",
      "Epoch 25/100\n",
      "Avg loss: 0.1968 -- Train acc: 0.9346 -- Val acc: 0.9032 -- Test acc: 0.9001 -- Gen gap 0.0345\n",
      "Epoch 26/100\n",
      "Avg loss: 0.1938 -- Train acc: 0.9414 -- Val acc: 0.9045 -- Test acc: 0.9000 -- Gen gap 0.0414\n",
      "Epoch 27/100\n",
      "Avg loss: 0.1895 -- Train acc: 0.9424 -- Val acc: 0.9049 -- Test acc: 0.9007 -- Gen gap 0.0417\n",
      "Epoch 28/100\n",
      "Avg loss: 0.1865 -- Train acc: 0.9424 -- Val acc: 0.9051 -- Test acc: 0.9006 -- Gen gap 0.0418\n",
      "Epoch 29/100\n",
      "Avg loss: 0.1799 -- Train acc: 0.9453 -- Val acc: 0.9053 -- Test acc: 0.9013 -- Gen gap 0.0440\n",
      "Epoch 30/100\n",
      "Avg loss: 0.1808 -- Train acc: 0.9473 -- Val acc: 0.9041 -- Test acc: 0.8994 -- Gen gap 0.0479\n",
      "Epoch 31/100\n",
      "Avg loss: 0.1779 -- Train acc: 0.9453 -- Val acc: 0.9047 -- Test acc: 0.9008 -- Gen gap 0.0445\n",
      "Epoch 32/100\n",
      "Avg loss: 0.1725 -- Train acc: 0.9502 -- Val acc: 0.9041 -- Test acc: 0.9001 -- Gen gap 0.0501\n",
      "Epoch 33/100\n",
      "Avg loss: 0.1667 -- Train acc: 0.9512 -- Val acc: 0.9034 -- Test acc: 0.9005 -- Gen gap 0.0507\n",
      "Epoch 34/100\n",
      "Avg loss: 0.1667 -- Train acc: 0.9512 -- Val acc: 0.9053 -- Test acc: 0.9001 -- Gen gap 0.0511\n",
      "Epoch 35/100\n",
      "Avg loss: 0.1666 -- Train acc: 0.9531 -- Val acc: 0.9034 -- Test acc: 0.9006 -- Gen gap 0.0525\n",
      "Epoch 36/100\n",
      "Avg loss: 0.1641 -- Train acc: 0.9521 -- Val acc: 0.9039 -- Test acc: 0.9008 -- Gen gap 0.0514\n",
      "Epoch 37/100\n",
      "Avg loss: 0.1566 -- Train acc: 0.9531 -- Val acc: 0.9045 -- Test acc: 0.9008 -- Gen gap 0.0523\n",
      "Epoch 38/100\n",
      "Avg loss: 0.1577 -- Train acc: 0.9541 -- Val acc: 0.9057 -- Test acc: 0.9003 -- Gen gap 0.0538\n",
      "Epoch 39/100\n",
      "Avg loss: 0.1531 -- Train acc: 0.9561 -- Val acc: 0.9063 -- Test acc: 0.9012 -- Gen gap 0.0549\n",
      "Epoch 40/100\n",
      "Avg loss: 0.1495 -- Train acc: 0.9531 -- Val acc: 0.9055 -- Test acc: 0.9002 -- Gen gap 0.0529\n",
      "Epoch 41/100\n",
      "Avg loss: 0.1483 -- Train acc: 0.9561 -- Val acc: 0.9061 -- Test acc: 0.9011 -- Gen gap 0.0550\n",
      "Epoch 42/100\n",
      "Avg loss: 0.1486 -- Train acc: 0.9551 -- Val acc: 0.9051 -- Test acc: 0.9012 -- Gen gap 0.0539\n",
      "Epoch 43/100\n",
      "Avg loss: 0.1432 -- Train acc: 0.9580 -- Val acc: 0.9056 -- Test acc: 0.9010 -- Gen gap 0.0570\n",
      "Epoch 44/100\n",
      "Avg loss: 0.1426 -- Train acc: 0.9570 -- Val acc: 0.9065 -- Test acc: 0.9013 -- Gen gap 0.0558\n",
      "Epoch 45/100\n",
      "Avg loss: 0.1394 -- Train acc: 0.9580 -- Val acc: 0.9059 -- Test acc: 0.9012 -- Gen gap 0.0568\n",
      "Epoch 46/100\n",
      "Avg loss: 0.1398 -- Train acc: 0.9580 -- Val acc: 0.9058 -- Test acc: 0.9012 -- Gen gap 0.0568\n",
      "Epoch 47/100\n",
      "Avg loss: 0.1344 -- Train acc: 0.9580 -- Val acc: 0.9062 -- Test acc: 0.9020 -- Gen gap 0.0560\n",
      "Epoch 48/100\n",
      "Avg loss: 0.1340 -- Train acc: 0.9570 -- Val acc: 0.9058 -- Test acc: 0.9016 -- Gen gap 0.0555\n",
      "Epoch 49/100\n",
      "Avg loss: 0.1304 -- Train acc: 0.9570 -- Val acc: 0.9071 -- Test acc: 0.9007 -- Gen gap 0.0564\n",
      "Epoch 50/100\n",
      "Avg loss: 0.1284 -- Train acc: 0.9580 -- Val acc: 0.9062 -- Test acc: 0.9014 -- Gen gap 0.0566\n",
      "Epoch 51/100\n",
      "Avg loss: 0.1292 -- Train acc: 0.9580 -- Val acc: 0.9070 -- Test acc: 0.9020 -- Gen gap 0.0560\n",
      "Epoch 52/100\n",
      "Avg loss: 0.1268 -- Train acc: 0.9580 -- Val acc: 0.9060 -- Test acc: 0.9021 -- Gen gap 0.0559\n",
      "Epoch 53/100\n",
      "Avg loss: 0.1226 -- Train acc: 0.9600 -- Val acc: 0.9062 -- Test acc: 0.9018 -- Gen gap 0.0582\n",
      "Epoch 54/100\n",
      "Avg loss: 0.1216 -- Train acc: 0.9600 -- Val acc: 0.9067 -- Test acc: 0.9010 -- Gen gap 0.0590\n",
      "Epoch 55/100\n",
      "Avg loss: 0.1190 -- Train acc: 0.9600 -- Val acc: 0.9064 -- Test acc: 0.9015 -- Gen gap 0.0585\n",
      "Epoch 56/100\n",
      "Avg loss: 0.1173 -- Train acc: 0.9609 -- Val acc: 0.9063 -- Test acc: 0.9014 -- Gen gap 0.0596\n",
      "Epoch 57/100\n",
      "Avg loss: 0.1161 -- Train acc: 0.9629 -- Val acc: 0.9076 -- Test acc: 0.9023 -- Gen gap 0.0606\n",
      "Epoch 58/100\n",
      "Avg loss: 0.1139 -- Train acc: 0.9619 -- Val acc: 0.9062 -- Test acc: 0.9012 -- Gen gap 0.0607\n",
      "Epoch 59/100\n",
      "Avg loss: 0.1157 -- Train acc: 0.9619 -- Val acc: 0.9062 -- Test acc: 0.9017 -- Gen gap 0.0602\n",
      "Epoch 60/100\n",
      "Avg loss: 0.1101 -- Train acc: 0.9619 -- Val acc: 0.9070 -- Test acc: 0.9020 -- Gen gap 0.0599\n",
      "Epoch 61/100\n",
      "Avg loss: 0.1095 -- Train acc: 0.9639 -- Val acc: 0.9079 -- Test acc: 0.9013 -- Gen gap 0.0626\n",
      "Epoch 62/100\n",
      "Avg loss: 0.1067 -- Train acc: 0.9639 -- Val acc: 0.9074 -- Test acc: 0.9015 -- Gen gap 0.0624\n",
      "Epoch 63/100\n",
      "Avg loss: 0.1050 -- Train acc: 0.9639 -- Val acc: 0.9073 -- Test acc: 0.9024 -- Gen gap 0.0615\n",
      "Epoch 64/100\n",
      "Avg loss: 0.1055 -- Train acc: 0.9629 -- Val acc: 0.9069 -- Test acc: 0.9017 -- Gen gap 0.0612\n",
      "Epoch 65/100\n",
      "Avg loss: 0.1045 -- Train acc: 0.9639 -- Val acc: 0.9076 -- Test acc: 0.9009 -- Gen gap 0.0630\n",
      "Epoch 66/100\n",
      "Avg loss: 0.1024 -- Train acc: 0.9639 -- Val acc: 0.9089 -- Test acc: 0.9010 -- Gen gap 0.0629\n",
      "Epoch 67/100\n",
      "Avg loss: 0.1008 -- Train acc: 0.9658 -- Val acc: 0.9069 -- Test acc: 0.9019 -- Gen gap 0.0639\n",
      "Epoch 68/100\n",
      "Avg loss: 0.0984 -- Train acc: 0.9648 -- Val acc: 0.9080 -- Test acc: 0.9026 -- Gen gap 0.0623\n",
      "Epoch 69/100\n",
      "Avg loss: 0.0978 -- Train acc: 0.9658 -- Val acc: 0.9072 -- Test acc: 0.9018 -- Gen gap 0.0640\n",
      "Epoch 70/100\n",
      "Avg loss: 0.0966 -- Train acc: 0.9648 -- Val acc: 0.9077 -- Test acc: 0.9024 -- Gen gap 0.0625\n",
      "Epoch 71/100\n",
      "Avg loss: 0.0940 -- Train acc: 0.9648 -- Val acc: 0.9071 -- Test acc: 0.9014 -- Gen gap 0.0635\n",
      "Epoch 72/100\n",
      "Avg loss: 0.0933 -- Train acc: 0.9648 -- Val acc: 0.9085 -- Test acc: 0.9013 -- Gen gap 0.0636\n",
      "Epoch 73/100\n",
      "Avg loss: 0.0927 -- Train acc: 0.9658 -- Val acc: 0.9076 -- Test acc: 0.9017 -- Gen gap 0.0641\n",
      "Epoch 74/100\n",
      "Avg loss: 0.0905 -- Train acc: 0.9658 -- Val acc: 0.9077 -- Test acc: 0.9010 -- Gen gap 0.0648\n",
      "Epoch 75/100\n",
      "Avg loss: 0.0901 -- Train acc: 0.9678 -- Val acc: 0.9071 -- Test acc: 0.9022 -- Gen gap 0.0656\n",
      "Epoch 76/100\n",
      "Avg loss: 0.0911 -- Train acc: 0.9678 -- Val acc: 0.9067 -- Test acc: 0.9005 -- Gen gap 0.0673\n",
      "Epoch 77/100\n",
      "Avg loss: 0.0871 -- Train acc: 0.9658 -- Val acc: 0.9072 -- Test acc: 0.9013 -- Gen gap 0.0645\n",
      "Epoch 78/100\n",
      "Avg loss: 0.0854 -- Train acc: 0.9688 -- Val acc: 0.9076 -- Test acc: 0.9016 -- Gen gap 0.0672\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.0871 -- Train acc: 0.9668 -- Val acc: 0.9065 -- Test acc: 0.9012 -- Gen gap 0.0656\n",
      "Epoch 80/100\n",
      "Avg loss: 0.0830 -- Train acc: 0.9697 -- Val acc: 0.9078 -- Test acc: 0.9023 -- Gen gap 0.0675\n",
      "Epoch 81/100\n",
      "Avg loss: 0.0827 -- Train acc: 0.9697 -- Val acc: 0.9077 -- Test acc: 0.9021 -- Gen gap 0.0677\n",
      "Epoch 82/100\n",
      "Avg loss: 0.0818 -- Train acc: 0.9697 -- Val acc: 0.9084 -- Test acc: 0.9025 -- Gen gap 0.0673\n",
      "Epoch 83/100\n",
      "Avg loss: 0.0812 -- Train acc: 0.9697 -- Val acc: 0.9085 -- Test acc: 0.9019 -- Gen gap 0.0679\n",
      "Epoch 84/100\n",
      "Avg loss: 0.0800 -- Train acc: 0.9697 -- Val acc: 0.9088 -- Test acc: 0.9014 -- Gen gap 0.0684\n",
      "Epoch 85/100\n",
      "Avg loss: 0.0786 -- Train acc: 0.9697 -- Val acc: 0.9074 -- Test acc: 0.9011 -- Gen gap 0.0687\n",
      "Epoch 86/100\n",
      "Avg loss: 0.0777 -- Train acc: 0.9697 -- Val acc: 0.9080 -- Test acc: 0.9018 -- Gen gap 0.0680\n",
      "Epoch 87/100\n",
      "Avg loss: 0.0762 -- Train acc: 0.9697 -- Val acc: 0.9074 -- Test acc: 0.9024 -- Gen gap 0.0674\n",
      "Epoch 88/100\n",
      "Avg loss: 0.0752 -- Train acc: 0.9697 -- Val acc: 0.9078 -- Test acc: 0.9014 -- Gen gap 0.0684\n",
      "Epoch 89/100\n",
      "Avg loss: 0.0750 -- Train acc: 0.9697 -- Val acc: 0.9082 -- Test acc: 0.9013 -- Gen gap 0.0685\n",
      "Epoch 90/100\n",
      "Avg loss: 0.0732 -- Train acc: 0.9697 -- Val acc: 0.9082 -- Test acc: 0.9013 -- Gen gap 0.0685\n",
      "Epoch 91/100\n",
      "Avg loss: 0.0721 -- Train acc: 0.9717 -- Val acc: 0.9077 -- Test acc: 0.9008 -- Gen gap 0.0709\n",
      "Epoch 92/100\n",
      "Avg loss: 0.0724 -- Train acc: 0.9697 -- Val acc: 0.9086 -- Test acc: 0.9013 -- Gen gap 0.0685\n",
      "Epoch 93/100\n",
      "Avg loss: 0.0713 -- Train acc: 0.9717 -- Val acc: 0.9085 -- Test acc: 0.9014 -- Gen gap 0.0703\n",
      "Epoch 94/100\n",
      "Avg loss: 0.0709 -- Train acc: 0.9727 -- Val acc: 0.9074 -- Test acc: 0.9010 -- Gen gap 0.0717\n",
      "Epoch 95/100\n",
      "Avg loss: 0.0691 -- Train acc: 0.9727 -- Val acc: 0.9080 -- Test acc: 0.9016 -- Gen gap 0.0711\n",
      "Epoch 96/100\n",
      "Avg loss: 0.0686 -- Train acc: 0.9736 -- Val acc: 0.9080 -- Test acc: 0.9008 -- Gen gap 0.0729\n",
      "Epoch 97/100\n",
      "Avg loss: 0.0678 -- Train acc: 0.9736 -- Val acc: 0.9076 -- Test acc: 0.9006 -- Gen gap 0.0731\n",
      "Epoch 98/100\n",
      "Avg loss: 0.0665 -- Train acc: 0.9736 -- Val acc: 0.9086 -- Test acc: 0.9015 -- Gen gap 0.0722\n",
      "Epoch 99/100\n",
      "Avg loss: 0.0668 -- Train acc: 0.9736 -- Val acc: 0.9082 -- Test acc: 0.9013 -- Gen gap 0.0724\n",
      "Epoch 100/100\n",
      "Avg loss: 0.0654 -- Train acc: 0.9736 -- Val acc: 0.9087 -- Test acc: 0.9016 -- Gen gap 0.0721\n",
      "Training done! Elapsed time: 0:00:17\n",
      "\n",
      "Iter 2\n",
      "Epoch 1/100\n",
      "Avg loss: 0.3153 -- Train acc: 0.8896 -- Val acc: 0.9083 -- Test acc: 0.9012 -- Gen gap -0.0115\n",
      "Epoch 2/100\n",
      "Avg loss: 0.2972 -- Train acc: 0.8955 -- Val acc: 0.9085 -- Test acc: 0.9044 -- Gen gap -0.0089\n",
      "Epoch 3/100\n",
      "Avg loss: 0.2889 -- Train acc: 0.8955 -- Val acc: 0.9086 -- Test acc: 0.9025 -- Gen gap -0.0070\n",
      "Epoch 4/100\n",
      "Avg loss: 0.2712 -- Train acc: 0.8975 -- Val acc: 0.9111 -- Test acc: 0.9062 -- Gen gap -0.0088\n",
      "Epoch 5/100\n",
      "Avg loss: 0.2650 -- Train acc: 0.9072 -- Val acc: 0.9097 -- Test acc: 0.9048 -- Gen gap 0.0025\n",
      "Epoch 6/100\n",
      "Avg loss: 0.2572 -- Train acc: 0.9062 -- Val acc: 0.9109 -- Test acc: 0.9078 -- Gen gap -0.0016\n",
      "Epoch 7/100\n",
      "Avg loss: 0.2445 -- Train acc: 0.9121 -- Val acc: 0.9120 -- Test acc: 0.9086 -- Gen gap 0.0035\n",
      "Epoch 8/100\n",
      "Avg loss: 0.2354 -- Train acc: 0.9150 -- Val acc: 0.9099 -- Test acc: 0.9062 -- Gen gap 0.0089\n",
      "Epoch 9/100\n",
      "Avg loss: 0.2317 -- Train acc: 0.9150 -- Val acc: 0.9098 -- Test acc: 0.9072 -- Gen gap 0.0078\n",
      "Epoch 10/100\n",
      "Avg loss: 0.2245 -- Train acc: 0.9170 -- Val acc: 0.9098 -- Test acc: 0.9076 -- Gen gap 0.0093\n",
      "Epoch 11/100\n",
      "Avg loss: 0.2163 -- Train acc: 0.9219 -- Val acc: 0.9113 -- Test acc: 0.9084 -- Gen gap 0.0134\n",
      "Epoch 12/100\n",
      "Avg loss: 0.2187 -- Train acc: 0.9248 -- Val acc: 0.9119 -- Test acc: 0.9092 -- Gen gap 0.0156\n",
      "Epoch 13/100\n",
      "Avg loss: 0.2096 -- Train acc: 0.9238 -- Val acc: 0.9099 -- Test acc: 0.9081 -- Gen gap 0.0157\n",
      "Epoch 14/100\n",
      "Avg loss: 0.2001 -- Train acc: 0.9248 -- Val acc: 0.9108 -- Test acc: 0.9072 -- Gen gap 0.0176\n",
      "Epoch 15/100\n",
      "Avg loss: 0.1966 -- Train acc: 0.9248 -- Val acc: 0.9096 -- Test acc: 0.9071 -- Gen gap 0.0177\n",
      "Epoch 16/100\n",
      "Avg loss: 0.1872 -- Train acc: 0.9277 -- Val acc: 0.9106 -- Test acc: 0.9081 -- Gen gap 0.0196\n",
      "Epoch 17/100\n",
      "Avg loss: 0.1874 -- Train acc: 0.9287 -- Val acc: 0.9111 -- Test acc: 0.9081 -- Gen gap 0.0206\n",
      "Epoch 18/100\n",
      "Avg loss: 0.1796 -- Train acc: 0.9297 -- Val acc: 0.9112 -- Test acc: 0.9085 -- Gen gap 0.0211\n",
      "Epoch 19/100\n",
      "Avg loss: 0.1751 -- Train acc: 0.9316 -- Val acc: 0.9106 -- Test acc: 0.9077 -- Gen gap 0.0239\n",
      "Epoch 20/100\n",
      "Avg loss: 0.1739 -- Train acc: 0.9297 -- Val acc: 0.9100 -- Test acc: 0.9086 -- Gen gap 0.0210\n",
      "Epoch 21/100\n",
      "Avg loss: 0.1696 -- Train acc: 0.9326 -- Val acc: 0.9107 -- Test acc: 0.9084 -- Gen gap 0.0242\n",
      "Epoch 22/100\n",
      "Avg loss: 0.1641 -- Train acc: 0.9336 -- Val acc: 0.9115 -- Test acc: 0.9093 -- Gen gap 0.0243\n",
      "Epoch 23/100\n",
      "Avg loss: 0.1622 -- Train acc: 0.9355 -- Val acc: 0.9114 -- Test acc: 0.9095 -- Gen gap 0.0260\n",
      "Epoch 24/100\n",
      "Avg loss: 0.1565 -- Train acc: 0.9375 -- Val acc: 0.9119 -- Test acc: 0.9094 -- Gen gap 0.0281\n",
      "Epoch 25/100\n",
      "Avg loss: 0.1541 -- Train acc: 0.9414 -- Val acc: 0.9100 -- Test acc: 0.9090 -- Gen gap 0.0324\n",
      "Epoch 26/100\n",
      "Avg loss: 0.1531 -- Train acc: 0.9443 -- Val acc: 0.9108 -- Test acc: 0.9087 -- Gen gap 0.0356\n",
      "Epoch 27/100\n",
      "Avg loss: 0.1500 -- Train acc: 0.9443 -- Val acc: 0.9109 -- Test acc: 0.9086 -- Gen gap 0.0357\n",
      "Epoch 28/100\n",
      "Avg loss: 0.1426 -- Train acc: 0.9473 -- Val acc: 0.9121 -- Test acc: 0.9087 -- Gen gap 0.0385\n",
      "Epoch 29/100\n",
      "Avg loss: 0.1420 -- Train acc: 0.9482 -- Val acc: 0.9114 -- Test acc: 0.9092 -- Gen gap 0.0390\n",
      "Epoch 30/100\n",
      "Avg loss: 0.1360 -- Train acc: 0.9492 -- Val acc: 0.9115 -- Test acc: 0.9100 -- Gen gap 0.0392\n",
      "Epoch 31/100\n",
      "Avg loss: 0.1353 -- Train acc: 0.9521 -- Val acc: 0.9111 -- Test acc: 0.9094 -- Gen gap 0.0427\n",
      "Epoch 32/100\n",
      "Avg loss: 0.1334 -- Train acc: 0.9521 -- Val acc: 0.9115 -- Test acc: 0.9097 -- Gen gap 0.0424\n",
      "Epoch 33/100\n",
      "Avg loss: 0.1305 -- Train acc: 0.9502 -- Val acc: 0.9123 -- Test acc: 0.9097 -- Gen gap 0.0405\n",
      "Epoch 34/100\n",
      "Avg loss: 0.1296 -- Train acc: 0.9521 -- Val acc: 0.9106 -- Test acc: 0.9086 -- Gen gap 0.0435\n",
      "Epoch 35/100\n",
      "Avg loss: 0.1248 -- Train acc: 0.9570 -- Val acc: 0.9115 -- Test acc: 0.9096 -- Gen gap 0.0474\n",
      "Epoch 36/100\n",
      "Avg loss: 0.1228 -- Train acc: 0.9580 -- Val acc: 0.9115 -- Test acc: 0.9097 -- Gen gap 0.0483\n",
      "Epoch 37/100\n",
      "Avg loss: 0.1203 -- Train acc: 0.9561 -- Val acc: 0.9115 -- Test acc: 0.9099 -- Gen gap 0.0461\n",
      "Epoch 38/100\n",
      "Avg loss: 0.1194 -- Train acc: 0.9551 -- Val acc: 0.9114 -- Test acc: 0.9110 -- Gen gap 0.0441\n",
      "Epoch 39/100\n",
      "Avg loss: 0.1166 -- Train acc: 0.9580 -- Val acc: 0.9114 -- Test acc: 0.9103 -- Gen gap 0.0477\n",
      "Epoch 40/100\n",
      "Avg loss: 0.1144 -- Train acc: 0.9590 -- Val acc: 0.9109 -- Test acc: 0.9096 -- Gen gap 0.0494\n",
      "Epoch 41/100\n",
      "Avg loss: 0.1112 -- Train acc: 0.9590 -- Val acc: 0.9108 -- Test acc: 0.9090 -- Gen gap 0.0499\n",
      "Epoch 42/100\n",
      "Avg loss: 0.1110 -- Train acc: 0.9600 -- Val acc: 0.9109 -- Test acc: 0.9108 -- Gen gap 0.0491\n",
      "Epoch 43/100\n",
      "Avg loss: 0.1081 -- Train acc: 0.9600 -- Val acc: 0.9104 -- Test acc: 0.9096 -- Gen gap 0.0503\n",
      "Epoch 44/100\n",
      "Avg loss: 0.1060 -- Train acc: 0.9600 -- Val acc: 0.9116 -- Test acc: 0.9105 -- Gen gap 0.0494\n",
      "Epoch 45/100\n",
      "Avg loss: 0.1064 -- Train acc: 0.9600 -- Val acc: 0.9101 -- Test acc: 0.9093 -- Gen gap 0.0506\n",
      "Epoch 46/100\n",
      "Avg loss: 0.1049 -- Train acc: 0.9619 -- Val acc: 0.9097 -- Test acc: 0.9090 -- Gen gap 0.0529\n",
      "Epoch 47/100\n",
      "Avg loss: 0.1020 -- Train acc: 0.9609 -- Val acc: 0.9114 -- Test acc: 0.9098 -- Gen gap 0.0511\n",
      "Epoch 48/100\n",
      "Avg loss: 0.0992 -- Train acc: 0.9619 -- Val acc: 0.9110 -- Test acc: 0.9098 -- Gen gap 0.0521\n",
      "Epoch 49/100\n",
      "Avg loss: 0.0976 -- Train acc: 0.9619 -- Val acc: 0.9117 -- Test acc: 0.9102 -- Gen gap 0.0517\n",
      "Epoch 50/100\n",
      "Avg loss: 0.0962 -- Train acc: 0.9619 -- Val acc: 0.9116 -- Test acc: 0.9111 -- Gen gap 0.0508\n",
      "Epoch 51/100\n",
      "Avg loss: 0.0965 -- Train acc: 0.9619 -- Val acc: 0.9111 -- Test acc: 0.9105 -- Gen gap 0.0514\n",
      "Epoch 52/100\n",
      "Avg loss: 0.0945 -- Train acc: 0.9629 -- Val acc: 0.9111 -- Test acc: 0.9111 -- Gen gap 0.0518\n",
      "Epoch 53/100\n",
      "Avg loss: 0.0912 -- Train acc: 0.9609 -- Val acc: 0.9104 -- Test acc: 0.9099 -- Gen gap 0.0510\n",
      "Epoch 54/100\n",
      "Avg loss: 0.0918 -- Train acc: 0.9619 -- Val acc: 0.9117 -- Test acc: 0.9095 -- Gen gap 0.0524\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.0890 -- Train acc: 0.9629 -- Val acc: 0.9116 -- Test acc: 0.9102 -- Gen gap 0.0527\n",
      "Epoch 56/100\n",
      "Avg loss: 0.0892 -- Train acc: 0.9658 -- Val acc: 0.9114 -- Test acc: 0.9094 -- Gen gap 0.0564\n",
      "Epoch 57/100\n",
      "Avg loss: 0.0870 -- Train acc: 0.9639 -- Val acc: 0.9109 -- Test acc: 0.9093 -- Gen gap 0.0545\n",
      "Epoch 58/100\n",
      "Avg loss: 0.0858 -- Train acc: 0.9648 -- Val acc: 0.9103 -- Test acc: 0.9097 -- Gen gap 0.0551\n",
      "Epoch 59/100\n",
      "Avg loss: 0.0835 -- Train acc: 0.9658 -- Val acc: 0.9109 -- Test acc: 0.9100 -- Gen gap 0.0558\n",
      "Epoch 60/100\n",
      "Avg loss: 0.0820 -- Train acc: 0.9658 -- Val acc: 0.9107 -- Test acc: 0.9095 -- Gen gap 0.0563\n",
      "Epoch 61/100\n",
      "Avg loss: 0.0811 -- Train acc: 0.9658 -- Val acc: 0.9102 -- Test acc: 0.9097 -- Gen gap 0.0561\n",
      "Epoch 62/100\n",
      "Avg loss: 0.0798 -- Train acc: 0.9688 -- Val acc: 0.9094 -- Test acc: 0.9096 -- Gen gap 0.0591\n",
      "Epoch 63/100\n",
      "Avg loss: 0.0777 -- Train acc: 0.9688 -- Val acc: 0.9100 -- Test acc: 0.9092 -- Gen gap 0.0595\n",
      "Epoch 64/100\n",
      "Avg loss: 0.0791 -- Train acc: 0.9668 -- Val acc: 0.9097 -- Test acc: 0.9105 -- Gen gap 0.0563\n",
      "Epoch 65/100\n",
      "Avg loss: 0.0767 -- Train acc: 0.9688 -- Val acc: 0.9095 -- Test acc: 0.9100 -- Gen gap 0.0587\n",
      "Epoch 66/100\n",
      "Avg loss: 0.0759 -- Train acc: 0.9688 -- Val acc: 0.9106 -- Test acc: 0.9097 -- Gen gap 0.0590\n",
      "Epoch 67/100\n",
      "Avg loss: 0.0739 -- Train acc: 0.9688 -- Val acc: 0.9113 -- Test acc: 0.9104 -- Gen gap 0.0583\n",
      "Epoch 68/100\n",
      "Avg loss: 0.0738 -- Train acc: 0.9688 -- Val acc: 0.9111 -- Test acc: 0.9106 -- Gen gap 0.0581\n",
      "Epoch 69/100\n",
      "Avg loss: 0.0726 -- Train acc: 0.9697 -- Val acc: 0.9113 -- Test acc: 0.9106 -- Gen gap 0.0591\n",
      "Epoch 70/100\n",
      "Avg loss: 0.0707 -- Train acc: 0.9707 -- Val acc: 0.9100 -- Test acc: 0.9106 -- Gen gap 0.0601\n",
      "Epoch 71/100\n",
      "Avg loss: 0.0710 -- Train acc: 0.9697 -- Val acc: 0.9108 -- Test acc: 0.9108 -- Gen gap 0.0589\n",
      "Epoch 72/100\n",
      "Avg loss: 0.0692 -- Train acc: 0.9707 -- Val acc: 0.9102 -- Test acc: 0.9101 -- Gen gap 0.0606\n",
      "Epoch 73/100\n",
      "Avg loss: 0.0679 -- Train acc: 0.9717 -- Val acc: 0.9101 -- Test acc: 0.9100 -- Gen gap 0.0616\n",
      "Epoch 74/100\n",
      "Avg loss: 0.0672 -- Train acc: 0.9717 -- Val acc: 0.9102 -- Test acc: 0.9102 -- Gen gap 0.0614\n",
      "Epoch 75/100\n",
      "Avg loss: 0.0666 -- Train acc: 0.9717 -- Val acc: 0.9096 -- Test acc: 0.9099 -- Gen gap 0.0617\n",
      "Epoch 76/100\n",
      "Avg loss: 0.0668 -- Train acc: 0.9717 -- Val acc: 0.9095 -- Test acc: 0.9092 -- Gen gap 0.0624\n",
      "Epoch 77/100\n",
      "Avg loss: 0.0644 -- Train acc: 0.9736 -- Val acc: 0.9090 -- Test acc: 0.9097 -- Gen gap 0.0639\n",
      "Epoch 78/100\n",
      "Avg loss: 0.0642 -- Train acc: 0.9727 -- Val acc: 0.9111 -- Test acc: 0.9109 -- Gen gap 0.0617\n",
      "Epoch 79/100\n",
      "Avg loss: 0.0623 -- Train acc: 0.9736 -- Val acc: 0.9109 -- Test acc: 0.9110 -- Gen gap 0.0626\n",
      "Epoch 80/100\n",
      "Avg loss: 0.0629 -- Train acc: 0.9746 -- Val acc: 0.9106 -- Test acc: 0.9101 -- Gen gap 0.0645\n",
      "Epoch 81/100\n",
      "Avg loss: 0.0621 -- Train acc: 0.9756 -- Val acc: 0.9096 -- Test acc: 0.9099 -- Gen gap 0.0657\n",
      "Epoch 82/100\n",
      "Avg loss: 0.0618 -- Train acc: 0.9756 -- Val acc: 0.9098 -- Test acc: 0.9098 -- Gen gap 0.0658\n",
      "Epoch 83/100\n",
      "Avg loss: 0.0608 -- Train acc: 0.9756 -- Val acc: 0.9097 -- Test acc: 0.9097 -- Gen gap 0.0659\n",
      "Epoch 84/100\n",
      "Avg loss: 0.0599 -- Train acc: 0.9756 -- Val acc: 0.9099 -- Test acc: 0.9098 -- Gen gap 0.0658\n",
      "Epoch 85/100\n",
      "Avg loss: 0.0580 -- Train acc: 0.9756 -- Val acc: 0.9104 -- Test acc: 0.9105 -- Gen gap 0.0651\n",
      "Epoch 86/100\n",
      "Avg loss: 0.0589 -- Train acc: 0.9756 -- Val acc: 0.9093 -- Test acc: 0.9102 -- Gen gap 0.0654\n",
      "Epoch 87/100\n",
      "Avg loss: 0.0565 -- Train acc: 0.9756 -- Val acc: 0.9097 -- Test acc: 0.9099 -- Gen gap 0.0657\n",
      "Epoch 88/100\n",
      "Avg loss: 0.0566 -- Train acc: 0.9756 -- Val acc: 0.9097 -- Test acc: 0.9098 -- Gen gap 0.0658\n",
      "Epoch 89/100\n",
      "Avg loss: 0.0557 -- Train acc: 0.9756 -- Val acc: 0.9100 -- Test acc: 0.9098 -- Gen gap 0.0658\n",
      "Epoch 90/100\n",
      "Avg loss: 0.0553 -- Train acc: 0.9756 -- Val acc: 0.9097 -- Test acc: 0.9093 -- Gen gap 0.0663\n",
      "Epoch 91/100\n",
      "Avg loss: 0.0539 -- Train acc: 0.9756 -- Val acc: 0.9100 -- Test acc: 0.9090 -- Gen gap 0.0665\n",
      "Epoch 92/100\n",
      "Avg loss: 0.0535 -- Train acc: 0.9756 -- Val acc: 0.9094 -- Test acc: 0.9092 -- Gen gap 0.0664\n",
      "Epoch 93/100\n",
      "Avg loss: 0.0531 -- Train acc: 0.9756 -- Val acc: 0.9093 -- Test acc: 0.9094 -- Gen gap 0.0662\n",
      "Epoch 94/100\n",
      "Avg loss: 0.0536 -- Train acc: 0.9756 -- Val acc: 0.9081 -- Test acc: 0.9085 -- Gen gap 0.0670\n",
      "Epoch 95/100\n",
      "Avg loss: 0.0521 -- Train acc: 0.9756 -- Val acc: 0.9098 -- Test acc: 0.9097 -- Gen gap 0.0659\n",
      "Epoch 96/100\n",
      "Avg loss: 0.0511 -- Train acc: 0.9756 -- Val acc: 0.9097 -- Test acc: 0.9106 -- Gen gap 0.0650\n",
      "Epoch 97/100\n",
      "Avg loss: 0.0505 -- Train acc: 0.9756 -- Val acc: 0.9098 -- Test acc: 0.9103 -- Gen gap 0.0653\n",
      "Epoch 98/100\n",
      "Avg loss: 0.0500 -- Train acc: 0.9756 -- Val acc: 0.9091 -- Test acc: 0.9100 -- Gen gap 0.0656\n",
      "Epoch 99/100\n",
      "Avg loss: 0.0491 -- Train acc: 0.9756 -- Val acc: 0.9097 -- Test acc: 0.9099 -- Gen gap 0.0657\n",
      "Epoch 100/100\n",
      "Avg loss: 0.0490 -- Train acc: 0.9756 -- Val acc: 0.9106 -- Test acc: 0.9103 -- Gen gap 0.0653\n",
      "Training done! Elapsed time: 0:00:17\n",
      "\n",
      "Iter 3\n",
      "Epoch 1/100\n",
      "Avg loss: 0.2884 -- Train acc: 0.9141 -- Val acc: 0.9105 -- Test acc: 0.9108 -- Gen gap 0.0032\n",
      "Epoch 2/100\n",
      "Avg loss: 0.2659 -- Train acc: 0.9199 -- Val acc: 0.9125 -- Test acc: 0.9108 -- Gen gap 0.0091\n",
      "Epoch 3/100\n",
      "Avg loss: 0.2580 -- Train acc: 0.9189 -- Val acc: 0.9147 -- Test acc: 0.9121 -- Gen gap 0.0068\n",
      "Epoch 4/100\n",
      "Avg loss: 0.2450 -- Train acc: 0.9209 -- Val acc: 0.9153 -- Test acc: 0.9118 -- Gen gap 0.0091\n",
      "Epoch 5/100\n",
      "Avg loss: 0.2346 -- Train acc: 0.9229 -- Val acc: 0.9166 -- Test acc: 0.9134 -- Gen gap 0.0094\n",
      "Epoch 6/100\n",
      "Avg loss: 0.2195 -- Train acc: 0.9258 -- Val acc: 0.9166 -- Test acc: 0.9137 -- Gen gap 0.0121\n",
      "Epoch 7/100\n",
      "Avg loss: 0.2151 -- Train acc: 0.9277 -- Val acc: 0.9164 -- Test acc: 0.9132 -- Gen gap 0.0145\n",
      "Epoch 8/100\n",
      "Avg loss: 0.2027 -- Train acc: 0.9297 -- Val acc: 0.9172 -- Test acc: 0.9150 -- Gen gap 0.0147\n",
      "Epoch 9/100\n",
      "Avg loss: 0.2011 -- Train acc: 0.9336 -- Val acc: 0.9163 -- Test acc: 0.9142 -- Gen gap 0.0194\n",
      "Epoch 10/100\n",
      "Avg loss: 0.1871 -- Train acc: 0.9326 -- Val acc: 0.9178 -- Test acc: 0.9153 -- Gen gap 0.0173\n",
      "Epoch 11/100\n",
      "Avg loss: 0.1885 -- Train acc: 0.9375 -- Val acc: 0.9170 -- Test acc: 0.9152 -- Gen gap 0.0223\n",
      "Epoch 12/100\n",
      "Avg loss: 0.1799 -- Train acc: 0.9395 -- Val acc: 0.9156 -- Test acc: 0.9133 -- Gen gap 0.0261\n",
      "Epoch 13/100\n",
      "Avg loss: 0.1733 -- Train acc: 0.9463 -- Val acc: 0.9176 -- Test acc: 0.9150 -- Gen gap 0.0313\n",
      "Epoch 14/100\n",
      "Avg loss: 0.1713 -- Train acc: 0.9424 -- Val acc: 0.9186 -- Test acc: 0.9153 -- Gen gap 0.0271\n",
      "Epoch 15/100\n",
      "Avg loss: 0.1629 -- Train acc: 0.9434 -- Val acc: 0.9177 -- Test acc: 0.9155 -- Gen gap 0.0279\n",
      "Epoch 16/100\n",
      "Avg loss: 0.1642 -- Train acc: 0.9492 -- Val acc: 0.9179 -- Test acc: 0.9154 -- Gen gap 0.0338\n",
      "Epoch 17/100\n",
      "Avg loss: 0.1552 -- Train acc: 0.9512 -- Val acc: 0.9175 -- Test acc: 0.9156 -- Gen gap 0.0356\n",
      "Epoch 18/100\n",
      "Avg loss: 0.1495 -- Train acc: 0.9541 -- Val acc: 0.9182 -- Test acc: 0.9150 -- Gen gap 0.0391\n",
      "Epoch 19/100\n",
      "Avg loss: 0.1485 -- Train acc: 0.9531 -- Val acc: 0.9175 -- Test acc: 0.9143 -- Gen gap 0.0388\n",
      "Epoch 20/100\n",
      "Avg loss: 0.1430 -- Train acc: 0.9570 -- Val acc: 0.9190 -- Test acc: 0.9148 -- Gen gap 0.0422\n",
      "Epoch 21/100\n",
      "Avg loss: 0.1418 -- Train acc: 0.9561 -- Val acc: 0.9194 -- Test acc: 0.9155 -- Gen gap 0.0405\n",
      "Epoch 22/100\n",
      "Avg loss: 0.1367 -- Train acc: 0.9551 -- Val acc: 0.9174 -- Test acc: 0.9147 -- Gen gap 0.0404\n",
      "Epoch 23/100\n",
      "Avg loss: 0.1344 -- Train acc: 0.9541 -- Val acc: 0.9194 -- Test acc: 0.9148 -- Gen gap 0.0393\n",
      "Epoch 24/100\n",
      "Avg loss: 0.1331 -- Train acc: 0.9561 -- Val acc: 0.9173 -- Test acc: 0.9150 -- Gen gap 0.0410\n",
      "Epoch 25/100\n",
      "Avg loss: 0.1285 -- Train acc: 0.9580 -- Val acc: 0.9193 -- Test acc: 0.9152 -- Gen gap 0.0428\n",
      "Epoch 26/100\n",
      "Avg loss: 0.1257 -- Train acc: 0.9570 -- Val acc: 0.9180 -- Test acc: 0.9150 -- Gen gap 0.0420\n",
      "Epoch 27/100\n",
      "Avg loss: 0.1239 -- Train acc: 0.9580 -- Val acc: 0.9184 -- Test acc: 0.9149 -- Gen gap 0.0431\n",
      "Epoch 28/100\n",
      "Avg loss: 0.1186 -- Train acc: 0.9580 -- Val acc: 0.9189 -- Test acc: 0.9147 -- Gen gap 0.0433\n",
      "Epoch 29/100\n",
      "Avg loss: 0.1192 -- Train acc: 0.9600 -- Val acc: 0.9180 -- Test acc: 0.9141 -- Gen gap 0.0458\n",
      "Epoch 30/100\n",
      "Avg loss: 0.1188 -- Train acc: 0.9600 -- Val acc: 0.9184 -- Test acc: 0.9141 -- Gen gap 0.0458\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.1121 -- Train acc: 0.9590 -- Val acc: 0.9188 -- Test acc: 0.9154 -- Gen gap 0.0436\n",
      "Epoch 32/100\n",
      "Avg loss: 0.1102 -- Train acc: 0.9609 -- Val acc: 0.9187 -- Test acc: 0.9154 -- Gen gap 0.0455\n",
      "Epoch 33/100\n",
      "Avg loss: 0.1107 -- Train acc: 0.9619 -- Val acc: 0.9188 -- Test acc: 0.9145 -- Gen gap 0.0474\n",
      "Epoch 34/100\n",
      "Avg loss: 0.1058 -- Train acc: 0.9639 -- Val acc: 0.9188 -- Test acc: 0.9148 -- Gen gap 0.0491\n",
      "Epoch 35/100\n",
      "Avg loss: 0.1034 -- Train acc: 0.9629 -- Val acc: 0.9187 -- Test acc: 0.9144 -- Gen gap 0.0485\n",
      "Epoch 36/100\n",
      "Avg loss: 0.1041 -- Train acc: 0.9639 -- Val acc: 0.9167 -- Test acc: 0.9145 -- Gen gap 0.0494\n",
      "Epoch 37/100\n",
      "Avg loss: 0.0989 -- Train acc: 0.9648 -- Val acc: 0.9191 -- Test acc: 0.9156 -- Gen gap 0.0492\n",
      "Epoch 38/100\n",
      "Avg loss: 0.0987 -- Train acc: 0.9639 -- Val acc: 0.9184 -- Test acc: 0.9157 -- Gen gap 0.0482\n",
      "Epoch 39/100\n",
      "Avg loss: 0.0958 -- Train acc: 0.9648 -- Val acc: 0.9185 -- Test acc: 0.9155 -- Gen gap 0.0493\n",
      "Epoch 40/100\n",
      "Avg loss: 0.0935 -- Train acc: 0.9639 -- Val acc: 0.9187 -- Test acc: 0.9141 -- Gen gap 0.0498\n",
      "Epoch 41/100\n",
      "Avg loss: 0.0915 -- Train acc: 0.9648 -- Val acc: 0.9199 -- Test acc: 0.9144 -- Gen gap 0.0504\n",
      "Epoch 42/100\n",
      "Avg loss: 0.0905 -- Train acc: 0.9648 -- Val acc: 0.9191 -- Test acc: 0.9151 -- Gen gap 0.0497\n",
      "Epoch 43/100\n",
      "Avg loss: 0.0885 -- Train acc: 0.9648 -- Val acc: 0.9185 -- Test acc: 0.9150 -- Gen gap 0.0498\n",
      "Epoch 44/100\n",
      "Avg loss: 0.0865 -- Train acc: 0.9648 -- Val acc: 0.9188 -- Test acc: 0.9151 -- Gen gap 0.0497\n",
      "Epoch 45/100\n",
      "Avg loss: 0.0854 -- Train acc: 0.9648 -- Val acc: 0.9185 -- Test acc: 0.9141 -- Gen gap 0.0507\n",
      "Epoch 46/100\n",
      "Avg loss: 0.0837 -- Train acc: 0.9648 -- Val acc: 0.9192 -- Test acc: 0.9145 -- Gen gap 0.0503\n",
      "Epoch 47/100\n",
      "Avg loss: 0.0822 -- Train acc: 0.9658 -- Val acc: 0.9188 -- Test acc: 0.9147 -- Gen gap 0.0511\n",
      "Epoch 48/100\n",
      "Avg loss: 0.0802 -- Train acc: 0.9658 -- Val acc: 0.9189 -- Test acc: 0.9150 -- Gen gap 0.0508\n",
      "Epoch 49/100\n",
      "Avg loss: 0.0782 -- Train acc: 0.9668 -- Val acc: 0.9199 -- Test acc: 0.9144 -- Gen gap 0.0524\n",
      "Epoch 50/100\n",
      "Avg loss: 0.0770 -- Train acc: 0.9668 -- Val acc: 0.9198 -- Test acc: 0.9143 -- Gen gap 0.0525\n",
      "Epoch 51/100\n",
      "Avg loss: 0.0764 -- Train acc: 0.9668 -- Val acc: 0.9182 -- Test acc: 0.9150 -- Gen gap 0.0518\n",
      "Epoch 52/100\n",
      "Avg loss: 0.0747 -- Train acc: 0.9668 -- Val acc: 0.9198 -- Test acc: 0.9144 -- Gen gap 0.0524\n",
      "Epoch 53/100\n",
      "Avg loss: 0.0738 -- Train acc: 0.9678 -- Val acc: 0.9190 -- Test acc: 0.9139 -- Gen gap 0.0539\n",
      "Epoch 54/100\n",
      "Avg loss: 0.0718 -- Train acc: 0.9678 -- Val acc: 0.9193 -- Test acc: 0.9146 -- Gen gap 0.0532\n",
      "Epoch 55/100\n",
      "Avg loss: 0.0717 -- Train acc: 0.9688 -- Val acc: 0.9186 -- Test acc: 0.9139 -- Gen gap 0.0548\n",
      "Epoch 56/100\n",
      "Avg loss: 0.0700 -- Train acc: 0.9688 -- Val acc: 0.9199 -- Test acc: 0.9141 -- Gen gap 0.0546\n",
      "Epoch 57/100\n",
      "Avg loss: 0.0688 -- Train acc: 0.9697 -- Val acc: 0.9189 -- Test acc: 0.9141 -- Gen gap 0.0556\n",
      "Epoch 58/100\n",
      "Avg loss: 0.0674 -- Train acc: 0.9688 -- Val acc: 0.9183 -- Test acc: 0.9136 -- Gen gap 0.0551\n",
      "Epoch 59/100\n",
      "Avg loss: 0.0667 -- Train acc: 0.9688 -- Val acc: 0.9192 -- Test acc: 0.9139 -- Gen gap 0.0548\n",
      "Epoch 60/100\n",
      "Avg loss: 0.0657 -- Train acc: 0.9688 -- Val acc: 0.9185 -- Test acc: 0.9143 -- Gen gap 0.0544\n",
      "Epoch 61/100\n",
      "Avg loss: 0.0640 -- Train acc: 0.9697 -- Val acc: 0.9192 -- Test acc: 0.9139 -- Gen gap 0.0558\n",
      "Epoch 62/100\n",
      "Avg loss: 0.0622 -- Train acc: 0.9697 -- Val acc: 0.9191 -- Test acc: 0.9138 -- Gen gap 0.0559\n",
      "Epoch 63/100\n",
      "Avg loss: 0.0626 -- Train acc: 0.9697 -- Val acc: 0.9183 -- Test acc: 0.9138 -- Gen gap 0.0559\n",
      "Epoch 64/100\n",
      "Avg loss: 0.0605 -- Train acc: 0.9707 -- Val acc: 0.9181 -- Test acc: 0.9136 -- Gen gap 0.0571\n",
      "Epoch 65/100\n",
      "Avg loss: 0.0602 -- Train acc: 0.9707 -- Val acc: 0.9179 -- Test acc: 0.9138 -- Gen gap 0.0569\n",
      "Epoch 66/100\n",
      "Avg loss: 0.0584 -- Train acc: 0.9707 -- Val acc: 0.9189 -- Test acc: 0.9139 -- Gen gap 0.0568\n",
      "Epoch 67/100\n",
      "Avg loss: 0.0585 -- Train acc: 0.9717 -- Val acc: 0.9191 -- Test acc: 0.9134 -- Gen gap 0.0583\n",
      "Epoch 68/100\n",
      "Avg loss: 0.0577 -- Train acc: 0.9707 -- Val acc: 0.9186 -- Test acc: 0.9140 -- Gen gap 0.0567\n",
      "Epoch 69/100\n",
      "Avg loss: 0.0556 -- Train acc: 0.9707 -- Val acc: 0.9193 -- Test acc: 0.9135 -- Gen gap 0.0572\n",
      "Epoch 70/100\n",
      "Avg loss: 0.0564 -- Train acc: 0.9707 -- Val acc: 0.9180 -- Test acc: 0.9137 -- Gen gap 0.0570\n",
      "Epoch 71/100\n",
      "Avg loss: 0.0538 -- Train acc: 0.9707 -- Val acc: 0.9188 -- Test acc: 0.9142 -- Gen gap 0.0565\n",
      "Epoch 72/100\n",
      "Avg loss: 0.0544 -- Train acc: 0.9717 -- Val acc: 0.9185 -- Test acc: 0.9136 -- Gen gap 0.0581\n",
      "Epoch 73/100\n",
      "Avg loss: 0.0529 -- Train acc: 0.9717 -- Val acc: 0.9175 -- Test acc: 0.9134 -- Gen gap 0.0583\n",
      "Epoch 74/100\n",
      "Avg loss: 0.0528 -- Train acc: 0.9736 -- Val acc: 0.9173 -- Test acc: 0.9131 -- Gen gap 0.0605\n",
      "Epoch 75/100\n",
      "Avg loss: 0.0507 -- Train acc: 0.9727 -- Val acc: 0.9190 -- Test acc: 0.9138 -- Gen gap 0.0588\n",
      "Epoch 76/100\n",
      "Avg loss: 0.0508 -- Train acc: 0.9736 -- Val acc: 0.9180 -- Test acc: 0.9136 -- Gen gap 0.0600\n",
      "Epoch 77/100\n",
      "Avg loss: 0.0494 -- Train acc: 0.9736 -- Val acc: 0.9187 -- Test acc: 0.9135 -- Gen gap 0.0601\n",
      "Epoch 78/100\n",
      "Avg loss: 0.0494 -- Train acc: 0.9736 -- Val acc: 0.9193 -- Test acc: 0.9133 -- Gen gap 0.0603\n",
      "Epoch 79/100\n",
      "Avg loss: 0.0481 -- Train acc: 0.9736 -- Val acc: 0.9186 -- Test acc: 0.9130 -- Gen gap 0.0606\n",
      "Epoch 80/100\n",
      "Avg loss: 0.0475 -- Train acc: 0.9727 -- Val acc: 0.9196 -- Test acc: 0.9138 -- Gen gap 0.0588\n",
      "Epoch 81/100\n",
      "Avg loss: 0.0486 -- Train acc: 0.9746 -- Val acc: 0.9184 -- Test acc: 0.9135 -- Gen gap 0.0611\n",
      "Epoch 82/100\n",
      "Avg loss: 0.0469 -- Train acc: 0.9746 -- Val acc: 0.9180 -- Test acc: 0.9127 -- Gen gap 0.0619\n",
      "Epoch 83/100\n",
      "Avg loss: 0.0453 -- Train acc: 0.9746 -- Val acc: 0.9189 -- Test acc: 0.9129 -- Gen gap 0.0617\n",
      "Epoch 84/100\n",
      "Avg loss: 0.0453 -- Train acc: 0.9746 -- Val acc: 0.9195 -- Test acc: 0.9135 -- Gen gap 0.0611\n",
      "Epoch 85/100\n",
      "Avg loss: 0.0440 -- Train acc: 0.9746 -- Val acc: 0.9190 -- Test acc: 0.9134 -- Gen gap 0.0612\n",
      "Epoch 86/100\n",
      "Avg loss: 0.0443 -- Train acc: 0.9746 -- Val acc: 0.9176 -- Test acc: 0.9136 -- Gen gap 0.0610\n",
      "Epoch 87/100\n",
      "Avg loss: 0.0435 -- Train acc: 0.9746 -- Val acc: 0.9197 -- Test acc: 0.9136 -- Gen gap 0.0610\n",
      "Epoch 88/100\n",
      "Avg loss: 0.0429 -- Train acc: 0.9746 -- Val acc: 0.9201 -- Test acc: 0.9143 -- Gen gap 0.0603\n",
      "Epoch 89/100\n",
      "Avg loss: 0.0419 -- Train acc: 0.9746 -- Val acc: 0.9196 -- Test acc: 0.9143 -- Gen gap 0.0603\n",
      "Epoch 90/100\n",
      "Avg loss: 0.0422 -- Train acc: 0.9746 -- Val acc: 0.9193 -- Test acc: 0.9138 -- Gen gap 0.0608\n",
      "Epoch 91/100\n",
      "Avg loss: 0.0407 -- Train acc: 0.9746 -- Val acc: 0.9190 -- Test acc: 0.9136 -- Gen gap 0.0610\n",
      "Epoch 92/100\n",
      "Avg loss: 0.0404 -- Train acc: 0.9756 -- Val acc: 0.9196 -- Test acc: 0.9137 -- Gen gap 0.0619\n",
      "Epoch 93/100\n",
      "Avg loss: 0.0397 -- Train acc: 0.9756 -- Val acc: 0.9196 -- Test acc: 0.9138 -- Gen gap 0.0618\n",
      "Epoch 94/100\n",
      "Avg loss: 0.0393 -- Train acc: 0.9756 -- Val acc: 0.9190 -- Test acc: 0.9133 -- Gen gap 0.0623\n",
      "Epoch 95/100\n",
      "Avg loss: 0.0393 -- Train acc: 0.9756 -- Val acc: 0.9200 -- Test acc: 0.9143 -- Gen gap 0.0613\n",
      "Epoch 96/100\n",
      "Avg loss: 0.0386 -- Train acc: 0.9756 -- Val acc: 0.9195 -- Test acc: 0.9137 -- Gen gap 0.0619\n",
      "Epoch 97/100\n",
      "Avg loss: 0.0379 -- Train acc: 0.9756 -- Val acc: 0.9189 -- Test acc: 0.9132 -- Gen gap 0.0624\n",
      "Epoch 98/100\n",
      "Avg loss: 0.0380 -- Train acc: 0.9756 -- Val acc: 0.9192 -- Test acc: 0.9132 -- Gen gap 0.0624\n",
      "Epoch 99/100\n",
      "Avg loss: 0.0375 -- Train acc: 0.9766 -- Val acc: 0.9191 -- Test acc: 0.9134 -- Gen gap 0.0631\n",
      "Epoch 100/100\n",
      "Avg loss: 0.0374 -- Train acc: 0.9756 -- Val acc: 0.9192 -- Test acc: 0.9145 -- Gen gap 0.0611\n",
      "Training done! Elapsed time: 0:00:17\n",
      "\n",
      "==============================\n",
      "a = 0.05, Na = 2500\n",
      "------------------------------\n",
      "Iter 1\n",
      "Epoch 1/100\n",
      "Avg loss: 0.2710 -- Train acc: 0.9051 -- Val acc: 0.9215 -- Test acc: 0.9165 -- Gen gap -0.0114\n",
      "Epoch 2/100\n",
      "Avg loss: 0.2569 -- Train acc: 0.9102 -- Val acc: 0.9259 -- Test acc: 0.9201 -- Gen gap -0.0099\n",
      "Epoch 3/100\n",
      "Avg loss: 0.2315 -- Train acc: 0.9141 -- Val acc: 0.9285 -- Test acc: 0.9232 -- Gen gap -0.0091\n",
      "Epoch 4/100\n",
      "Avg loss: 0.2220 -- Train acc: 0.9047 -- Val acc: 0.9162 -- Test acc: 0.9098 -- Gen gap -0.0051\n",
      "Epoch 5/100\n",
      "Avg loss: 0.2127 -- Train acc: 0.9203 -- Val acc: 0.9288 -- Test acc: 0.9235 -- Gen gap -0.0032\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.1943 -- Train acc: 0.9211 -- Val acc: 0.9271 -- Test acc: 0.9213 -- Gen gap -0.0002\n",
      "Epoch 7/100\n",
      "Avg loss: 0.1843 -- Train acc: 0.9273 -- Val acc: 0.9306 -- Test acc: 0.9264 -- Gen gap 0.0010\n",
      "Epoch 8/100\n",
      "Avg loss: 0.1767 -- Train acc: 0.9309 -- Val acc: 0.9318 -- Test acc: 0.9259 -- Gen gap 0.0050\n",
      "Epoch 9/100\n",
      "Avg loss: 0.1704 -- Train acc: 0.9320 -- Val acc: 0.9303 -- Test acc: 0.9259 -- Gen gap 0.0062\n",
      "Epoch 10/100\n",
      "Avg loss: 0.1646 -- Train acc: 0.9355 -- Val acc: 0.9326 -- Test acc: 0.9271 -- Gen gap 0.0084\n",
      "Epoch 11/100\n",
      "Avg loss: 0.1625 -- Train acc: 0.9352 -- Val acc: 0.9315 -- Test acc: 0.9274 -- Gen gap 0.0077\n",
      "Epoch 12/100\n",
      "Avg loss: 0.1532 -- Train acc: 0.9402 -- Val acc: 0.9332 -- Test acc: 0.9279 -- Gen gap 0.0123\n",
      "Epoch 13/100\n",
      "Avg loss: 0.1472 -- Train acc: 0.9414 -- Val acc: 0.9318 -- Test acc: 0.9280 -- Gen gap 0.0134\n",
      "Epoch 14/100\n",
      "Avg loss: 0.1430 -- Train acc: 0.9410 -- Val acc: 0.9322 -- Test acc: 0.9278 -- Gen gap 0.0132\n",
      "Epoch 15/100\n",
      "Avg loss: 0.1457 -- Train acc: 0.9332 -- Val acc: 0.9256 -- Test acc: 0.9218 -- Gen gap 0.0114\n",
      "Epoch 16/100\n",
      "Avg loss: 0.1359 -- Train acc: 0.9465 -- Val acc: 0.9340 -- Test acc: 0.9296 -- Gen gap 0.0168\n",
      "Epoch 17/100\n",
      "Avg loss: 0.1308 -- Train acc: 0.9453 -- Val acc: 0.9332 -- Test acc: 0.9292 -- Gen gap 0.0161\n",
      "Epoch 18/100\n",
      "Avg loss: 0.1272 -- Train acc: 0.9477 -- Val acc: 0.9341 -- Test acc: 0.9296 -- Gen gap 0.0180\n",
      "Epoch 19/100\n",
      "Avg loss: 0.1272 -- Train acc: 0.9484 -- Val acc: 0.9314 -- Test acc: 0.9291 -- Gen gap 0.0193\n",
      "Epoch 20/100\n",
      "Avg loss: 0.1220 -- Train acc: 0.9469 -- Val acc: 0.9322 -- Test acc: 0.9283 -- Gen gap 0.0185\n",
      "Epoch 21/100\n",
      "Avg loss: 0.1217 -- Train acc: 0.9473 -- Val acc: 0.9316 -- Test acc: 0.9279 -- Gen gap 0.0193\n",
      "Epoch 22/100\n",
      "Avg loss: 0.1201 -- Train acc: 0.9414 -- Val acc: 0.9314 -- Test acc: 0.9278 -- Gen gap 0.0136\n",
      "Epoch 23/100\n",
      "Avg loss: 0.1166 -- Train acc: 0.9527 -- Val acc: 0.9349 -- Test acc: 0.9313 -- Gen gap 0.0214\n",
      "Epoch 24/100\n",
      "Avg loss: 0.1110 -- Train acc: 0.9523 -- Val acc: 0.9335 -- Test acc: 0.9315 -- Gen gap 0.0208\n",
      "Epoch 25/100\n",
      "Avg loss: 0.1063 -- Train acc: 0.9539 -- Val acc: 0.9340 -- Test acc: 0.9310 -- Gen gap 0.0229\n",
      "Epoch 26/100\n",
      "Avg loss: 0.1040 -- Train acc: 0.9543 -- Val acc: 0.9344 -- Test acc: 0.9318 -- Gen gap 0.0225\n",
      "Epoch 27/100\n",
      "Avg loss: 0.1055 -- Train acc: 0.9531 -- Val acc: 0.9326 -- Test acc: 0.9268 -- Gen gap 0.0264\n",
      "Epoch 28/100\n",
      "Avg loss: 0.1015 -- Train acc: 0.9539 -- Val acc: 0.9327 -- Test acc: 0.9294 -- Gen gap 0.0245\n",
      "Epoch 29/100\n",
      "Avg loss: 0.0973 -- Train acc: 0.9570 -- Val acc: 0.9347 -- Test acc: 0.9313 -- Gen gap 0.0257\n",
      "Epoch 30/100\n",
      "Avg loss: 0.0948 -- Train acc: 0.9578 -- Val acc: 0.9341 -- Test acc: 0.9306 -- Gen gap 0.0272\n",
      "Epoch 31/100\n",
      "Avg loss: 0.0923 -- Train acc: 0.9582 -- Val acc: 0.9352 -- Test acc: 0.9304 -- Gen gap 0.0278\n",
      "Epoch 32/100\n",
      "Avg loss: 0.0901 -- Train acc: 0.9586 -- Val acc: 0.9336 -- Test acc: 0.9309 -- Gen gap 0.0277\n",
      "Epoch 33/100\n",
      "Avg loss: 0.0888 -- Train acc: 0.9586 -- Val acc: 0.9336 -- Test acc: 0.9309 -- Gen gap 0.0277\n",
      "Epoch 34/100\n",
      "Avg loss: 0.0871 -- Train acc: 0.9605 -- Val acc: 0.9340 -- Test acc: 0.9315 -- Gen gap 0.0290\n",
      "Epoch 35/100\n",
      "Avg loss: 0.0860 -- Train acc: 0.9605 -- Val acc: 0.9346 -- Test acc: 0.9311 -- Gen gap 0.0294\n",
      "Epoch 36/100\n",
      "Avg loss: 0.0836 -- Train acc: 0.9617 -- Val acc: 0.9346 -- Test acc: 0.9309 -- Gen gap 0.0308\n",
      "Epoch 37/100\n",
      "Avg loss: 0.0818 -- Train acc: 0.9617 -- Val acc: 0.9333 -- Test acc: 0.9319 -- Gen gap 0.0298\n",
      "Epoch 38/100\n",
      "Avg loss: 0.0810 -- Train acc: 0.9625 -- Val acc: 0.9353 -- Test acc: 0.9316 -- Gen gap 0.0309\n",
      "Epoch 39/100\n",
      "Avg loss: 0.0794 -- Train acc: 0.9625 -- Val acc: 0.9354 -- Test acc: 0.9317 -- Gen gap 0.0308\n",
      "Epoch 40/100\n",
      "Avg loss: 0.0795 -- Train acc: 0.9609 -- Val acc: 0.9328 -- Test acc: 0.9292 -- Gen gap 0.0317\n",
      "Epoch 41/100\n",
      "Avg loss: 0.0783 -- Train acc: 0.9645 -- Val acc: 0.9356 -- Test acc: 0.9310 -- Gen gap 0.0334\n",
      "Epoch 42/100\n",
      "Avg loss: 0.0754 -- Train acc: 0.9652 -- Val acc: 0.9357 -- Test acc: 0.9319 -- Gen gap 0.0333\n",
      "Epoch 43/100\n",
      "Avg loss: 0.0738 -- Train acc: 0.9652 -- Val acc: 0.9352 -- Test acc: 0.9320 -- Gen gap 0.0332\n",
      "Epoch 44/100\n",
      "Avg loss: 0.0717 -- Train acc: 0.9660 -- Val acc: 0.9344 -- Test acc: 0.9319 -- Gen gap 0.0341\n",
      "Epoch 45/100\n",
      "Avg loss: 0.0701 -- Train acc: 0.9668 -- Val acc: 0.9354 -- Test acc: 0.9307 -- Gen gap 0.0361\n",
      "Epoch 46/100\n",
      "Avg loss: 0.0695 -- Train acc: 0.9680 -- Val acc: 0.9357 -- Test acc: 0.9312 -- Gen gap 0.0367\n",
      "Epoch 47/100\n",
      "Avg loss: 0.0681 -- Train acc: 0.9684 -- Val acc: 0.9347 -- Test acc: 0.9307 -- Gen gap 0.0376\n",
      "Epoch 48/100\n",
      "Avg loss: 0.0669 -- Train acc: 0.9684 -- Val acc: 0.9360 -- Test acc: 0.9315 -- Gen gap 0.0368\n",
      "Epoch 49/100\n",
      "Avg loss: 0.0654 -- Train acc: 0.9684 -- Val acc: 0.9352 -- Test acc: 0.9319 -- Gen gap 0.0364\n",
      "Epoch 50/100\n",
      "Avg loss: 0.0669 -- Train acc: 0.9668 -- Val acc: 0.9343 -- Test acc: 0.9316 -- Gen gap 0.0352\n",
      "Epoch 51/100\n",
      "Avg loss: 0.0632 -- Train acc: 0.9680 -- Val acc: 0.9357 -- Test acc: 0.9314 -- Gen gap 0.0365\n",
      "Epoch 52/100\n",
      "Avg loss: 0.0628 -- Train acc: 0.9699 -- Val acc: 0.9354 -- Test acc: 0.9309 -- Gen gap 0.0390\n",
      "Epoch 53/100\n",
      "Avg loss: 0.0611 -- Train acc: 0.9691 -- Val acc: 0.9351 -- Test acc: 0.9325 -- Gen gap 0.0366\n",
      "Epoch 54/100\n",
      "Avg loss: 0.0609 -- Train acc: 0.9695 -- Val acc: 0.9331 -- Test acc: 0.9322 -- Gen gap 0.0373\n",
      "Epoch 55/100\n",
      "Avg loss: 0.0607 -- Train acc: 0.9691 -- Val acc: 0.9351 -- Test acc: 0.9323 -- Gen gap 0.0368\n",
      "Epoch 56/100\n",
      "Avg loss: 0.0667 -- Train acc: 0.9602 -- Val acc: 0.9305 -- Test acc: 0.9271 -- Gen gap 0.0330\n",
      "Epoch 57/100\n",
      "Avg loss: 0.0622 -- Train acc: 0.9703 -- Val acc: 0.9341 -- Test acc: 0.9306 -- Gen gap 0.0397\n",
      "Epoch 58/100\n",
      "Avg loss: 0.0570 -- Train acc: 0.9707 -- Val acc: 0.9352 -- Test acc: 0.9306 -- Gen gap 0.0401\n",
      "Epoch 59/100\n",
      "Avg loss: 0.0555 -- Train acc: 0.9707 -- Val acc: 0.9348 -- Test acc: 0.9319 -- Gen gap 0.0388\n",
      "Epoch 60/100\n",
      "Avg loss: 0.0549 -- Train acc: 0.9707 -- Val acc: 0.9360 -- Test acc: 0.9315 -- Gen gap 0.0392\n",
      "Epoch 61/100\n",
      "Avg loss: 0.0538 -- Train acc: 0.9711 -- Val acc: 0.9350 -- Test acc: 0.9311 -- Gen gap 0.0400\n",
      "Epoch 62/100\n",
      "Avg loss: 0.0548 -- Train acc: 0.9711 -- Val acc: 0.9346 -- Test acc: 0.9303 -- Gen gap 0.0408\n",
      "Epoch 63/100\n",
      "Avg loss: 0.0534 -- Train acc: 0.9723 -- Val acc: 0.9349 -- Test acc: 0.9315 -- Gen gap 0.0407\n",
      "Epoch 64/100\n",
      "Avg loss: 0.0532 -- Train acc: 0.9691 -- Val acc: 0.9325 -- Test acc: 0.9302 -- Gen gap 0.0389\n",
      "Epoch 65/100\n",
      "Avg loss: 0.0513 -- Train acc: 0.9719 -- Val acc: 0.9361 -- Test acc: 0.9312 -- Gen gap 0.0406\n",
      "Epoch 66/100\n",
      "Avg loss: 0.0522 -- Train acc: 0.9691 -- Val acc: 0.9335 -- Test acc: 0.9312 -- Gen gap 0.0379\n",
      "Epoch 67/100\n",
      "Avg loss: 0.0501 -- Train acc: 0.9719 -- Val acc: 0.9359 -- Test acc: 0.9318 -- Gen gap 0.0400\n",
      "Epoch 68/100\n",
      "Avg loss: 0.0488 -- Train acc: 0.9719 -- Val acc: 0.9349 -- Test acc: 0.9317 -- Gen gap 0.0401\n",
      "Epoch 69/100\n",
      "Avg loss: 0.0487 -- Train acc: 0.9723 -- Val acc: 0.9354 -- Test acc: 0.9322 -- Gen gap 0.0400\n",
      "Epoch 70/100\n",
      "Avg loss: 0.0477 -- Train acc: 0.9734 -- Val acc: 0.9366 -- Test acc: 0.9315 -- Gen gap 0.0419\n",
      "Epoch 71/100\n",
      "Avg loss: 0.0472 -- Train acc: 0.9727 -- Val acc: 0.9364 -- Test acc: 0.9316 -- Gen gap 0.0410\n",
      "Epoch 72/100\n",
      "Avg loss: 0.0457 -- Train acc: 0.9730 -- Val acc: 0.9364 -- Test acc: 0.9322 -- Gen gap 0.0408\n",
      "Epoch 73/100\n",
      "Avg loss: 0.0472 -- Train acc: 0.9734 -- Val acc: 0.9361 -- Test acc: 0.9311 -- Gen gap 0.0423\n",
      "Epoch 74/100\n",
      "Avg loss: 0.0445 -- Train acc: 0.9730 -- Val acc: 0.9360 -- Test acc: 0.9313 -- Gen gap 0.0417\n",
      "Epoch 75/100\n",
      "Avg loss: 0.0436 -- Train acc: 0.9730 -- Val acc: 0.9357 -- Test acc: 0.9317 -- Gen gap 0.0413\n",
      "Epoch 76/100\n",
      "Avg loss: 0.0438 -- Train acc: 0.9738 -- Val acc: 0.9367 -- Test acc: 0.9314 -- Gen gap 0.0424\n",
      "Epoch 77/100\n",
      "Avg loss: 0.0426 -- Train acc: 0.9734 -- Val acc: 0.9368 -- Test acc: 0.9318 -- Gen gap 0.0416\n",
      "Epoch 78/100\n",
      "Avg loss: 0.0432 -- Train acc: 0.9734 -- Val acc: 0.9367 -- Test acc: 0.9324 -- Gen gap 0.0410\n",
      "Epoch 79/100\n",
      "Avg loss: 0.0418 -- Train acc: 0.9738 -- Val acc: 0.9351 -- Test acc: 0.9322 -- Gen gap 0.0416\n",
      "Epoch 80/100\n",
      "Avg loss: 0.0407 -- Train acc: 0.9738 -- Val acc: 0.9363 -- Test acc: 0.9314 -- Gen gap 0.0424\n",
      "Epoch 81/100\n",
      "Avg loss: 0.0408 -- Train acc: 0.9734 -- Val acc: 0.9360 -- Test acc: 0.9319 -- Gen gap 0.0415\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.0400 -- Train acc: 0.9734 -- Val acc: 0.9364 -- Test acc: 0.9318 -- Gen gap 0.0416\n",
      "Epoch 83/100\n",
      "Avg loss: 0.0398 -- Train acc: 0.9738 -- Val acc: 0.9359 -- Test acc: 0.9317 -- Gen gap 0.0421\n",
      "Epoch 84/100\n",
      "Avg loss: 0.0399 -- Train acc: 0.9738 -- Val acc: 0.9353 -- Test acc: 0.9321 -- Gen gap 0.0417\n",
      "Epoch 85/100\n",
      "Avg loss: 0.0388 -- Train acc: 0.9738 -- Val acc: 0.9365 -- Test acc: 0.9319 -- Gen gap 0.0419\n",
      "Epoch 86/100\n",
      "Avg loss: 0.0379 -- Train acc: 0.9738 -- Val acc: 0.9359 -- Test acc: 0.9322 -- Gen gap 0.0416\n",
      "Epoch 87/100\n",
      "Avg loss: 0.0373 -- Train acc: 0.9738 -- Val acc: 0.9367 -- Test acc: 0.9319 -- Gen gap 0.0419\n",
      "Epoch 88/100\n",
      "Avg loss: 0.0369 -- Train acc: 0.9738 -- Val acc: 0.9364 -- Test acc: 0.9313 -- Gen gap 0.0425\n",
      "Epoch 89/100\n",
      "Avg loss: 0.0367 -- Train acc: 0.9734 -- Val acc: 0.9353 -- Test acc: 0.9315 -- Gen gap 0.0419\n",
      "Epoch 90/100\n",
      "Avg loss: 0.0365 -- Train acc: 0.9730 -- Val acc: 0.9351 -- Test acc: 0.9310 -- Gen gap 0.0420\n",
      "Epoch 91/100\n",
      "Avg loss: 0.0357 -- Train acc: 0.9742 -- Val acc: 0.9365 -- Test acc: 0.9312 -- Gen gap 0.0430\n",
      "Epoch 92/100\n",
      "Avg loss: 0.0361 -- Train acc: 0.9734 -- Val acc: 0.9337 -- Test acc: 0.9299 -- Gen gap 0.0435\n",
      "Epoch 93/100\n",
      "Avg loss: 0.0349 -- Train acc: 0.9746 -- Val acc: 0.9363 -- Test acc: 0.9321 -- Gen gap 0.0425\n",
      "Epoch 94/100\n",
      "Avg loss: 0.0357 -- Train acc: 0.9742 -- Val acc: 0.9370 -- Test acc: 0.9317 -- Gen gap 0.0425\n",
      "Epoch 95/100\n",
      "Avg loss: 0.0340 -- Train acc: 0.9750 -- Val acc: 0.9362 -- Test acc: 0.9318 -- Gen gap 0.0432\n",
      "Epoch 96/100\n",
      "Avg loss: 0.0341 -- Train acc: 0.9750 -- Val acc: 0.9360 -- Test acc: 0.9310 -- Gen gap 0.0440\n",
      "Epoch 97/100\n",
      "Avg loss: 0.0328 -- Train acc: 0.9750 -- Val acc: 0.9369 -- Test acc: 0.9318 -- Gen gap 0.0432\n",
      "Epoch 98/100\n",
      "Avg loss: 0.0339 -- Train acc: 0.9746 -- Val acc: 0.9349 -- Test acc: 0.9318 -- Gen gap 0.0428\n",
      "Epoch 99/100\n",
      "Avg loss: 0.0322 -- Train acc: 0.9750 -- Val acc: 0.9368 -- Test acc: 0.9317 -- Gen gap 0.0433\n",
      "Epoch 100/100\n",
      "Avg loss: 0.0336 -- Train acc: 0.9750 -- Val acc: 0.9353 -- Test acc: 0.9305 -- Gen gap 0.0445\n",
      "Training done! Elapsed time: 0:00:22\n",
      "\n",
      "Iter 2\n",
      "Epoch 1/100\n",
      "Avg loss: 0.2040 -- Train acc: 0.9250 -- Val acc: 0.9367 -- Test acc: 0.9334 -- Gen gap -0.0084\n",
      "Epoch 2/100\n",
      "Avg loss: 0.2278 -- Train acc: 0.9059 -- Val acc: 0.9175 -- Test acc: 0.9148 -- Gen gap -0.0089\n",
      "Epoch 3/100\n",
      "Avg loss: 0.1770 -- Train acc: 0.9348 -- Val acc: 0.9372 -- Test acc: 0.9332 -- Gen gap 0.0015\n",
      "Epoch 4/100\n",
      "Avg loss: 0.1585 -- Train acc: 0.9359 -- Val acc: 0.9381 -- Test acc: 0.9351 -- Gen gap 0.0008\n",
      "Epoch 5/100\n",
      "Avg loss: 0.1496 -- Train acc: 0.9383 -- Val acc: 0.9365 -- Test acc: 0.9350 -- Gen gap 0.0033\n",
      "Epoch 6/100\n",
      "Avg loss: 0.1395 -- Train acc: 0.9410 -- Val acc: 0.9381 -- Test acc: 0.9372 -- Gen gap 0.0038\n",
      "Epoch 7/100\n",
      "Avg loss: 0.1318 -- Train acc: 0.9441 -- Val acc: 0.9378 -- Test acc: 0.9366 -- Gen gap 0.0075\n",
      "Epoch 8/100\n",
      "Avg loss: 0.1263 -- Train acc: 0.9469 -- Val acc: 0.9383 -- Test acc: 0.9361 -- Gen gap 0.0108\n",
      "Epoch 9/100\n",
      "Avg loss: 0.1196 -- Train acc: 0.9465 -- Val acc: 0.9374 -- Test acc: 0.9361 -- Gen gap 0.0104\n",
      "Epoch 10/100\n",
      "Avg loss: 0.1133 -- Train acc: 0.9516 -- Val acc: 0.9398 -- Test acc: 0.9374 -- Gen gap 0.0142\n",
      "Epoch 11/100\n",
      "Avg loss: 0.1104 -- Train acc: 0.9523 -- Val acc: 0.9387 -- Test acc: 0.9371 -- Gen gap 0.0152\n",
      "Epoch 12/100\n",
      "Avg loss: 0.1052 -- Train acc: 0.9547 -- Val acc: 0.9381 -- Test acc: 0.9361 -- Gen gap 0.0186\n",
      "Epoch 13/100\n",
      "Avg loss: 0.1047 -- Train acc: 0.9543 -- Val acc: 0.9375 -- Test acc: 0.9353 -- Gen gap 0.0190\n",
      "Epoch 14/100\n",
      "Avg loss: 0.0977 -- Train acc: 0.9570 -- Val acc: 0.9382 -- Test acc: 0.9368 -- Gen gap 0.0202\n",
      "Epoch 15/100\n",
      "Avg loss: 0.1040 -- Train acc: 0.9465 -- Val acc: 0.9361 -- Test acc: 0.9343 -- Gen gap 0.0122\n",
      "Epoch 16/100\n",
      "Avg loss: 0.0968 -- Train acc: 0.9535 -- Val acc: 0.9363 -- Test acc: 0.9348 -- Gen gap 0.0187\n",
      "Epoch 17/100\n",
      "Avg loss: 0.0889 -- Train acc: 0.9574 -- Val acc: 0.9387 -- Test acc: 0.9381 -- Gen gap 0.0193\n",
      "Epoch 18/100\n",
      "Avg loss: 0.0850 -- Train acc: 0.9570 -- Val acc: 0.9392 -- Test acc: 0.9353 -- Gen gap 0.0217\n",
      "Epoch 19/100\n",
      "Avg loss: 0.0823 -- Train acc: 0.9602 -- Val acc: 0.9380 -- Test acc: 0.9369 -- Gen gap 0.0233\n",
      "Epoch 20/100\n",
      "Avg loss: 0.0795 -- Train acc: 0.9613 -- Val acc: 0.9384 -- Test acc: 0.9374 -- Gen gap 0.0239\n",
      "Epoch 21/100\n",
      "Avg loss: 0.0813 -- Train acc: 0.9563 -- Val acc: 0.9363 -- Test acc: 0.9314 -- Gen gap 0.0248\n",
      "Epoch 22/100\n",
      "Avg loss: 0.0787 -- Train acc: 0.9621 -- Val acc: 0.9388 -- Test acc: 0.9375 -- Gen gap 0.0246\n",
      "Epoch 23/100\n",
      "Avg loss: 0.0734 -- Train acc: 0.9621 -- Val acc: 0.9394 -- Test acc: 0.9362 -- Gen gap 0.0259\n",
      "Epoch 24/100\n",
      "Avg loss: 0.0711 -- Train acc: 0.9641 -- Val acc: 0.9386 -- Test acc: 0.9369 -- Gen gap 0.0272\n",
      "Epoch 25/100\n",
      "Avg loss: 0.0692 -- Train acc: 0.9637 -- Val acc: 0.9386 -- Test acc: 0.9366 -- Gen gap 0.0271\n",
      "Epoch 26/100\n",
      "Avg loss: 0.0673 -- Train acc: 0.9648 -- Val acc: 0.9386 -- Test acc: 0.9366 -- Gen gap 0.0282\n",
      "Epoch 27/100\n",
      "Avg loss: 0.0642 -- Train acc: 0.9645 -- Val acc: 0.9393 -- Test acc: 0.9380 -- Gen gap 0.0265\n",
      "Epoch 28/100\n",
      "Avg loss: 0.0633 -- Train acc: 0.9656 -- Val acc: 0.9390 -- Test acc: 0.9365 -- Gen gap 0.0291\n",
      "Epoch 29/100\n",
      "Avg loss: 0.0622 -- Train acc: 0.9652 -- Val acc: 0.9383 -- Test acc: 0.9361 -- Gen gap 0.0291\n",
      "Epoch 30/100\n",
      "Avg loss: 0.0591 -- Train acc: 0.9656 -- Val acc: 0.9387 -- Test acc: 0.9378 -- Gen gap 0.0278\n",
      "Epoch 31/100\n",
      "Avg loss: 0.0578 -- Train acc: 0.9656 -- Val acc: 0.9390 -- Test acc: 0.9389 -- Gen gap 0.0267\n",
      "Epoch 32/100\n",
      "Avg loss: 0.0565 -- Train acc: 0.9660 -- Val acc: 0.9385 -- Test acc: 0.9384 -- Gen gap 0.0276\n",
      "Epoch 33/100\n",
      "Avg loss: 0.0549 -- Train acc: 0.9668 -- Val acc: 0.9390 -- Test acc: 0.9370 -- Gen gap 0.0298\n",
      "Epoch 34/100\n",
      "Avg loss: 0.0535 -- Train acc: 0.9664 -- Val acc: 0.9386 -- Test acc: 0.9372 -- Gen gap 0.0292\n",
      "Epoch 35/100\n",
      "Avg loss: 0.0517 -- Train acc: 0.9688 -- Val acc: 0.9391 -- Test acc: 0.9373 -- Gen gap 0.0314\n",
      "Epoch 36/100\n",
      "Avg loss: 0.0513 -- Train acc: 0.9672 -- Val acc: 0.9388 -- Test acc: 0.9386 -- Gen gap 0.0286\n",
      "Epoch 37/100\n",
      "Avg loss: 0.0498 -- Train acc: 0.9684 -- Val acc: 0.9385 -- Test acc: 0.9373 -- Gen gap 0.0311\n",
      "Epoch 38/100\n",
      "Avg loss: 0.0487 -- Train acc: 0.9688 -- Val acc: 0.9392 -- Test acc: 0.9371 -- Gen gap 0.0316\n",
      "Epoch 39/100\n",
      "Avg loss: 0.0480 -- Train acc: 0.9695 -- Val acc: 0.9398 -- Test acc: 0.9380 -- Gen gap 0.0315\n",
      "Epoch 40/100\n",
      "Avg loss: 0.0471 -- Train acc: 0.9688 -- Val acc: 0.9390 -- Test acc: 0.9364 -- Gen gap 0.0323\n",
      "Epoch 41/100\n",
      "Avg loss: 0.0459 -- Train acc: 0.9699 -- Val acc: 0.9394 -- Test acc: 0.9376 -- Gen gap 0.0323\n",
      "Epoch 42/100\n",
      "Avg loss: 0.0446 -- Train acc: 0.9707 -- Val acc: 0.9383 -- Test acc: 0.9374 -- Gen gap 0.0333\n",
      "Epoch 43/100\n",
      "Avg loss: 0.0448 -- Train acc: 0.9691 -- Val acc: 0.9391 -- Test acc: 0.9358 -- Gen gap 0.0333\n",
      "Epoch 44/100\n",
      "Avg loss: 0.0459 -- Train acc: 0.9691 -- Val acc: 0.9386 -- Test acc: 0.9367 -- Gen gap 0.0324\n",
      "Epoch 45/100\n",
      "Avg loss: 0.0456 -- Train acc: 0.9703 -- Val acc: 0.9380 -- Test acc: 0.9369 -- Gen gap 0.0334\n",
      "Epoch 46/100\n",
      "Avg loss: 0.0428 -- Train acc: 0.9707 -- Val acc: 0.9397 -- Test acc: 0.9384 -- Gen gap 0.0323\n",
      "Epoch 47/100\n",
      "Avg loss: 0.0415 -- Train acc: 0.9723 -- Val acc: 0.9400 -- Test acc: 0.9371 -- Gen gap 0.0352\n",
      "Epoch 48/100\n",
      "Avg loss: 0.0393 -- Train acc: 0.9723 -- Val acc: 0.9396 -- Test acc: 0.9378 -- Gen gap 0.0345\n",
      "Epoch 49/100\n",
      "Avg loss: 0.0390 -- Train acc: 0.9730 -- Val acc: 0.9392 -- Test acc: 0.9371 -- Gen gap 0.0359\n",
      "Epoch 50/100\n",
      "Avg loss: 0.0380 -- Train acc: 0.9727 -- Val acc: 0.9396 -- Test acc: 0.9388 -- Gen gap 0.0339\n",
      "Epoch 51/100\n",
      "Avg loss: 0.0371 -- Train acc: 0.9734 -- Val acc: 0.9392 -- Test acc: 0.9385 -- Gen gap 0.0349\n",
      "Epoch 52/100\n",
      "Avg loss: 0.0374 -- Train acc: 0.9727 -- Val acc: 0.9394 -- Test acc: 0.9383 -- Gen gap 0.0344\n",
      "Epoch 53/100\n",
      "Avg loss: 0.0396 -- Train acc: 0.9715 -- Val acc: 0.9376 -- Test acc: 0.9342 -- Gen gap 0.0373\n",
      "Epoch 54/100\n",
      "Avg loss: 0.0368 -- Train acc: 0.9734 -- Val acc: 0.9393 -- Test acc: 0.9383 -- Gen gap 0.0351\n",
      "Epoch 55/100\n",
      "Avg loss: 0.0343 -- Train acc: 0.9738 -- Val acc: 0.9400 -- Test acc: 0.9384 -- Gen gap 0.0354\n",
      "Epoch 56/100\n",
      "Avg loss: 0.0380 -- Train acc: 0.9742 -- Val acc: 0.9390 -- Test acc: 0.9369 -- Gen gap 0.0373\n",
      "Epoch 57/100\n",
      "Avg loss: 0.0338 -- Train acc: 0.9742 -- Val acc: 0.9393 -- Test acc: 0.9376 -- Gen gap 0.0366\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.0327 -- Train acc: 0.9738 -- Val acc: 0.9398 -- Test acc: 0.9375 -- Gen gap 0.0363\n",
      "Epoch 59/100\n",
      "Avg loss: 0.0318 -- Train acc: 0.9742 -- Val acc: 0.9397 -- Test acc: 0.9371 -- Gen gap 0.0371\n",
      "Epoch 60/100\n",
      "Avg loss: 0.0317 -- Train acc: 0.9742 -- Val acc: 0.9397 -- Test acc: 0.9379 -- Gen gap 0.0363\n",
      "Epoch 61/100\n",
      "Avg loss: 0.0307 -- Train acc: 0.9742 -- Val acc: 0.9400 -- Test acc: 0.9379 -- Gen gap 0.0363\n",
      "Epoch 62/100\n",
      "Avg loss: 0.0310 -- Train acc: 0.9742 -- Val acc: 0.9393 -- Test acc: 0.9360 -- Gen gap 0.0382\n",
      "Epoch 63/100\n",
      "Avg loss: 0.0298 -- Train acc: 0.9742 -- Val acc: 0.9400 -- Test acc: 0.9374 -- Gen gap 0.0368\n",
      "Epoch 64/100\n",
      "Avg loss: 0.0299 -- Train acc: 0.9742 -- Val acc: 0.9397 -- Test acc: 0.9367 -- Gen gap 0.0375\n",
      "Epoch 65/100\n",
      "Avg loss: 0.0294 -- Train acc: 0.9746 -- Val acc: 0.9398 -- Test acc: 0.9376 -- Gen gap 0.0370\n",
      "Epoch 66/100\n",
      "Avg loss: 0.0295 -- Train acc: 0.9750 -- Val acc: 0.9397 -- Test acc: 0.9375 -- Gen gap 0.0375\n",
      "Epoch 67/100\n",
      "Avg loss: 0.0285 -- Train acc: 0.9746 -- Val acc: 0.9396 -- Test acc: 0.9367 -- Gen gap 0.0379\n",
      "Epoch 68/100\n",
      "Avg loss: 0.0279 -- Train acc: 0.9750 -- Val acc: 0.9404 -- Test acc: 0.9371 -- Gen gap 0.0379\n",
      "Epoch 69/100\n",
      "Avg loss: 0.0274 -- Train acc: 0.9746 -- Val acc: 0.9392 -- Test acc: 0.9363 -- Gen gap 0.0383\n",
      "Epoch 70/100\n",
      "Avg loss: 0.0295 -- Train acc: 0.9680 -- Val acc: 0.9339 -- Test acc: 0.9352 -- Gen gap 0.0328\n",
      "Epoch 71/100\n",
      "Avg loss: 0.0298 -- Train acc: 0.9746 -- Val acc: 0.9401 -- Test acc: 0.9365 -- Gen gap 0.0381\n",
      "Epoch 72/100\n",
      "Avg loss: 0.0265 -- Train acc: 0.9746 -- Val acc: 0.9397 -- Test acc: 0.9370 -- Gen gap 0.0376\n",
      "Epoch 73/100\n",
      "Avg loss: 0.0255 -- Train acc: 0.9750 -- Val acc: 0.9397 -- Test acc: 0.9378 -- Gen gap 0.0372\n",
      "Epoch 74/100\n",
      "Avg loss: 0.0251 -- Train acc: 0.9750 -- Val acc: 0.9400 -- Test acc: 0.9370 -- Gen gap 0.0380\n",
      "Epoch 75/100\n",
      "Avg loss: 0.0260 -- Train acc: 0.9746 -- Val acc: 0.9396 -- Test acc: 0.9357 -- Gen gap 0.0389\n",
      "Epoch 76/100\n",
      "Avg loss: 0.0250 -- Train acc: 0.9750 -- Val acc: 0.9407 -- Test acc: 0.9373 -- Gen gap 0.0377\n",
      "Epoch 77/100\n",
      "Avg loss: 0.0243 -- Train acc: 0.9754 -- Val acc: 0.9396 -- Test acc: 0.9373 -- Gen gap 0.0381\n",
      "Epoch 78/100\n",
      "Avg loss: 0.0238 -- Train acc: 0.9754 -- Val acc: 0.9397 -- Test acc: 0.9375 -- Gen gap 0.0379\n",
      "Epoch 79/100\n",
      "Avg loss: 0.0231 -- Train acc: 0.9750 -- Val acc: 0.9397 -- Test acc: 0.9377 -- Gen gap 0.0373\n",
      "Epoch 80/100\n",
      "Avg loss: 0.0229 -- Train acc: 0.9754 -- Val acc: 0.9401 -- Test acc: 0.9374 -- Gen gap 0.0380\n",
      "Epoch 81/100\n",
      "Avg loss: 0.0227 -- Train acc: 0.9754 -- Val acc: 0.9400 -- Test acc: 0.9377 -- Gen gap 0.0377\n",
      "Epoch 82/100\n",
      "Avg loss: 0.0233 -- Train acc: 0.9750 -- Val acc: 0.9396 -- Test acc: 0.9376 -- Gen gap 0.0374\n",
      "Epoch 83/100\n",
      "Avg loss: 0.0224 -- Train acc: 0.9758 -- Val acc: 0.9400 -- Test acc: 0.9374 -- Gen gap 0.0384\n",
      "Epoch 84/100\n",
      "Avg loss: 0.0221 -- Train acc: 0.9758 -- Val acc: 0.9399 -- Test acc: 0.9379 -- Gen gap 0.0379\n",
      "Epoch 85/100\n",
      "Avg loss: 0.0227 -- Train acc: 0.9758 -- Val acc: 0.9398 -- Test acc: 0.9369 -- Gen gap 0.0389\n",
      "Epoch 86/100\n",
      "Avg loss: 0.0226 -- Train acc: 0.9746 -- Val acc: 0.9395 -- Test acc: 0.9363 -- Gen gap 0.0383\n",
      "Epoch 87/100\n",
      "Avg loss: 0.0214 -- Train acc: 0.9758 -- Val acc: 0.9404 -- Test acc: 0.9370 -- Gen gap 0.0388\n",
      "Epoch 88/100\n",
      "Avg loss: 0.0207 -- Train acc: 0.9758 -- Val acc: 0.9403 -- Test acc: 0.9373 -- Gen gap 0.0385\n",
      "Epoch 89/100\n",
      "Avg loss: 0.0206 -- Train acc: 0.9758 -- Val acc: 0.9401 -- Test acc: 0.9377 -- Gen gap 0.0381\n",
      "Epoch 90/100\n",
      "Avg loss: 0.0223 -- Train acc: 0.9758 -- Val acc: 0.9403 -- Test acc: 0.9362 -- Gen gap 0.0396\n",
      "Epoch 91/100\n",
      "Avg loss: 0.0201 -- Train acc: 0.9762 -- Val acc: 0.9403 -- Test acc: 0.9371 -- Gen gap 0.0391\n",
      "Epoch 92/100\n",
      "Avg loss: 0.0196 -- Train acc: 0.9758 -- Val acc: 0.9403 -- Test acc: 0.9371 -- Gen gap 0.0387\n",
      "Epoch 93/100\n",
      "Avg loss: 0.0200 -- Train acc: 0.9758 -- Val acc: 0.9402 -- Test acc: 0.9380 -- Gen gap 0.0378\n",
      "Epoch 94/100\n",
      "Avg loss: 0.0192 -- Train acc: 0.9766 -- Val acc: 0.9401 -- Test acc: 0.9372 -- Gen gap 0.0394\n",
      "Epoch 95/100\n",
      "Avg loss: 0.0195 -- Train acc: 0.9762 -- Val acc: 0.9404 -- Test acc: 0.9378 -- Gen gap 0.0384\n",
      "Epoch 96/100\n",
      "Avg loss: 0.0187 -- Train acc: 0.9766 -- Val acc: 0.9405 -- Test acc: 0.9379 -- Gen gap 0.0387\n",
      "Epoch 97/100\n",
      "Avg loss: 0.0186 -- Train acc: 0.9766 -- Val acc: 0.9405 -- Test acc: 0.9375 -- Gen gap 0.0391\n",
      "Epoch 98/100\n",
      "Avg loss: 0.0185 -- Train acc: 0.9762 -- Val acc: 0.9404 -- Test acc: 0.9381 -- Gen gap 0.0381\n",
      "Epoch 99/100\n",
      "Avg loss: 0.0184 -- Train acc: 0.9766 -- Val acc: 0.9408 -- Test acc: 0.9379 -- Gen gap 0.0387\n",
      "Epoch 100/100\n",
      "Avg loss: 0.0187 -- Train acc: 0.9766 -- Val acc: 0.9398 -- Test acc: 0.9379 -- Gen gap 0.0387\n",
      "Training done! Elapsed time: 0:00:23\n",
      "\n",
      "Iter 3\n",
      "Epoch 1/100\n",
      "Avg loss: 0.2015 -- Train acc: 0.9168 -- Val acc: 0.9359 -- Test acc: 0.9331 -- Gen gap -0.0163\n",
      "Epoch 2/100\n",
      "Avg loss: 0.1816 -- Train acc: 0.9359 -- Val acc: 0.9429 -- Test acc: 0.9409 -- Gen gap -0.0049\n",
      "Epoch 3/100\n",
      "Avg loss: 0.1653 -- Train acc: 0.9391 -- Val acc: 0.9429 -- Test acc: 0.9426 -- Gen gap -0.0035\n",
      "Epoch 4/100\n",
      "Avg loss: 0.1627 -- Train acc: 0.9242 -- Val acc: 0.9369 -- Test acc: 0.9323 -- Gen gap -0.0081\n",
      "Epoch 5/100\n",
      "Avg loss: 0.1473 -- Train acc: 0.9445 -- Val acc: 0.9440 -- Test acc: 0.9435 -- Gen gap 0.0011\n",
      "Epoch 6/100\n",
      "Avg loss: 0.1362 -- Train acc: 0.9434 -- Val acc: 0.9440 -- Test acc: 0.9432 -- Gen gap 0.0002\n",
      "Epoch 7/100\n",
      "Avg loss: 0.1280 -- Train acc: 0.9469 -- Val acc: 0.9449 -- Test acc: 0.9439 -- Gen gap 0.0030\n",
      "Epoch 8/100\n",
      "Avg loss: 0.1202 -- Train acc: 0.9477 -- Val acc: 0.9435 -- Test acc: 0.9431 -- Gen gap 0.0046\n",
      "Epoch 9/100\n",
      "Avg loss: 0.1154 -- Train acc: 0.9469 -- Val acc: 0.9446 -- Test acc: 0.9448 -- Gen gap 0.0021\n",
      "Epoch 10/100\n",
      "Avg loss: 0.1142 -- Train acc: 0.9398 -- Val acc: 0.9387 -- Test acc: 0.9378 -- Gen gap 0.0020\n",
      "Epoch 11/100\n",
      "Avg loss: 0.1085 -- Train acc: 0.9523 -- Val acc: 0.9437 -- Test acc: 0.9427 -- Gen gap 0.0097\n",
      "Epoch 12/100\n",
      "Avg loss: 0.1036 -- Train acc: 0.9523 -- Val acc: 0.9426 -- Test acc: 0.9417 -- Gen gap 0.0107\n",
      "Epoch 13/100\n",
      "Avg loss: 0.0986 -- Train acc: 0.9559 -- Val acc: 0.9441 -- Test acc: 0.9446 -- Gen gap 0.0113\n",
      "Epoch 14/100\n",
      "Avg loss: 0.0949 -- Train acc: 0.9555 -- Val acc: 0.9437 -- Test acc: 0.9444 -- Gen gap 0.0111\n",
      "Epoch 15/100\n",
      "Avg loss: 0.0911 -- Train acc: 0.9527 -- Val acc: 0.9423 -- Test acc: 0.9430 -- Gen gap 0.0098\n",
      "Epoch 16/100\n",
      "Avg loss: 0.0893 -- Train acc: 0.9590 -- Val acc: 0.9445 -- Test acc: 0.9444 -- Gen gap 0.0146\n",
      "Epoch 17/100\n",
      "Avg loss: 0.0862 -- Train acc: 0.9570 -- Val acc: 0.9453 -- Test acc: 0.9438 -- Gen gap 0.0133\n",
      "Epoch 18/100\n",
      "Avg loss: 0.0837 -- Train acc: 0.9594 -- Val acc: 0.9443 -- Test acc: 0.9448 -- Gen gap 0.0146\n",
      "Epoch 19/100\n",
      "Avg loss: 0.1024 -- Train acc: 0.9348 -- Val acc: 0.9278 -- Test acc: 0.9298 -- Gen gap 0.0049\n",
      "Epoch 20/100\n",
      "Avg loss: 0.0881 -- Train acc: 0.9609 -- Val acc: 0.9452 -- Test acc: 0.9442 -- Gen gap 0.0168\n",
      "Epoch 21/100\n",
      "Avg loss: 0.0827 -- Train acc: 0.9359 -- Val acc: 0.9266 -- Test acc: 0.9226 -- Gen gap 0.0134\n",
      "Epoch 22/100\n",
      "Avg loss: 0.0824 -- Train acc: 0.9590 -- Val acc: 0.9398 -- Test acc: 0.9372 -- Gen gap 0.0218\n",
      "Epoch 23/100\n",
      "Avg loss: 0.0741 -- Train acc: 0.9648 -- Val acc: 0.9459 -- Test acc: 0.9451 -- Gen gap 0.0198\n",
      "Epoch 24/100\n",
      "Avg loss: 0.0687 -- Train acc: 0.9656 -- Val acc: 0.9456 -- Test acc: 0.9444 -- Gen gap 0.0213\n",
      "Epoch 25/100\n",
      "Avg loss: 0.0669 -- Train acc: 0.9684 -- Val acc: 0.9441 -- Test acc: 0.9443 -- Gen gap 0.0241\n",
      "Epoch 26/100\n",
      "Avg loss: 0.0686 -- Train acc: 0.9625 -- Val acc: 0.9437 -- Test acc: 0.9424 -- Gen gap 0.0201\n",
      "Epoch 27/100\n",
      "Avg loss: 0.0656 -- Train acc: 0.9664 -- Val acc: 0.9448 -- Test acc: 0.9430 -- Gen gap 0.0234\n",
      "Epoch 28/100\n",
      "Avg loss: 0.0613 -- Train acc: 0.9688 -- Val acc: 0.9429 -- Test acc: 0.9439 -- Gen gap 0.0249\n",
      "Epoch 29/100\n",
      "Avg loss: 0.0599 -- Train acc: 0.9684 -- Val acc: 0.9443 -- Test acc: 0.9446 -- Gen gap 0.0238\n",
      "Epoch 30/100\n",
      "Avg loss: 0.0607 -- Train acc: 0.9598 -- Val acc: 0.9402 -- Test acc: 0.9378 -- Gen gap 0.0220\n",
      "Epoch 31/100\n",
      "Avg loss: 0.0685 -- Train acc: 0.9434 -- Val acc: 0.9262 -- Test acc: 0.9219 -- Gen gap 0.0215\n",
      "Epoch 32/100\n",
      "Avg loss: 0.0662 -- Train acc: 0.9688 -- Val acc: 0.9444 -- Test acc: 0.9442 -- Gen gap 0.0246\n",
      "Epoch 33/100\n",
      "Avg loss: 0.0556 -- Train acc: 0.9699 -- Val acc: 0.9457 -- Test acc: 0.9448 -- Gen gap 0.0252\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.0542 -- Train acc: 0.9695 -- Val acc: 0.9439 -- Test acc: 0.9431 -- Gen gap 0.0265\n",
      "Epoch 35/100\n",
      "Avg loss: 0.0516 -- Train acc: 0.9691 -- Val acc: 0.9464 -- Test acc: 0.9429 -- Gen gap 0.0263\n",
      "Epoch 36/100\n",
      "Avg loss: 0.0506 -- Train acc: 0.9703 -- Val acc: 0.9457 -- Test acc: 0.9449 -- Gen gap 0.0254\n",
      "Epoch 37/100\n",
      "Avg loss: 0.0489 -- Train acc: 0.9711 -- Val acc: 0.9458 -- Test acc: 0.9438 -- Gen gap 0.0273\n",
      "Epoch 38/100\n",
      "Avg loss: 0.0484 -- Train acc: 0.9676 -- Val acc: 0.9438 -- Test acc: 0.9414 -- Gen gap 0.0262\n",
      "Epoch 39/100\n",
      "Avg loss: 0.0471 -- Train acc: 0.9715 -- Val acc: 0.9457 -- Test acc: 0.9437 -- Gen gap 0.0278\n",
      "Epoch 40/100\n",
      "Avg loss: 0.0468 -- Train acc: 0.9703 -- Val acc: 0.9464 -- Test acc: 0.9448 -- Gen gap 0.0255\n",
      "Epoch 41/100\n",
      "Avg loss: 0.0450 -- Train acc: 0.9715 -- Val acc: 0.9464 -- Test acc: 0.9442 -- Gen gap 0.0273\n",
      "Epoch 42/100\n",
      "Avg loss: 0.0458 -- Train acc: 0.9684 -- Val acc: 0.9435 -- Test acc: 0.9390 -- Gen gap 0.0294\n",
      "Epoch 43/100\n",
      "Avg loss: 0.0448 -- Train acc: 0.9719 -- Val acc: 0.9459 -- Test acc: 0.9438 -- Gen gap 0.0281\n",
      "Epoch 44/100\n",
      "Avg loss: 0.0437 -- Train acc: 0.9719 -- Val acc: 0.9445 -- Test acc: 0.9437 -- Gen gap 0.0282\n",
      "Epoch 45/100\n",
      "Avg loss: 0.0411 -- Train acc: 0.9719 -- Val acc: 0.9457 -- Test acc: 0.9444 -- Gen gap 0.0275\n",
      "Epoch 46/100\n",
      "Avg loss: 0.0400 -- Train acc: 0.9727 -- Val acc: 0.9447 -- Test acc: 0.9440 -- Gen gap 0.0287\n",
      "Epoch 47/100\n",
      "Avg loss: 0.0397 -- Train acc: 0.9719 -- Val acc: 0.9457 -- Test acc: 0.9444 -- Gen gap 0.0275\n",
      "Epoch 48/100\n",
      "Avg loss: 0.0397 -- Train acc: 0.9723 -- Val acc: 0.9432 -- Test acc: 0.9425 -- Gen gap 0.0298\n",
      "Epoch 49/100\n",
      "Avg loss: 0.0389 -- Train acc: 0.9727 -- Val acc: 0.9444 -- Test acc: 0.9446 -- Gen gap 0.0281\n",
      "Epoch 50/100\n",
      "Avg loss: 0.0370 -- Train acc: 0.9730 -- Val acc: 0.9461 -- Test acc: 0.9448 -- Gen gap 0.0283\n",
      "Epoch 51/100\n",
      "Avg loss: 0.0364 -- Train acc: 0.9730 -- Val acc: 0.9457 -- Test acc: 0.9438 -- Gen gap 0.0293\n",
      "Epoch 52/100\n",
      "Avg loss: 0.0376 -- Train acc: 0.9699 -- Val acc: 0.9433 -- Test acc: 0.9398 -- Gen gap 0.0301\n",
      "Epoch 53/100\n",
      "Avg loss: 0.0363 -- Train acc: 0.9730 -- Val acc: 0.9451 -- Test acc: 0.9448 -- Gen gap 0.0283\n",
      "Epoch 54/100\n",
      "Avg loss: 0.0363 -- Train acc: 0.9727 -- Val acc: 0.9439 -- Test acc: 0.9442 -- Gen gap 0.0285\n",
      "Epoch 55/100\n",
      "Avg loss: 0.0340 -- Train acc: 0.9730 -- Val acc: 0.9460 -- Test acc: 0.9453 -- Gen gap 0.0278\n",
      "Epoch 56/100\n",
      "Avg loss: 0.0327 -- Train acc: 0.9730 -- Val acc: 0.9458 -- Test acc: 0.9436 -- Gen gap 0.0295\n",
      "Epoch 57/100\n",
      "Avg loss: 0.0336 -- Train acc: 0.9719 -- Val acc: 0.9443 -- Test acc: 0.9416 -- Gen gap 0.0303\n",
      "Epoch 58/100\n",
      "Avg loss: 0.0327 -- Train acc: 0.9734 -- Val acc: 0.9461 -- Test acc: 0.9445 -- Gen gap 0.0290\n",
      "Epoch 59/100\n",
      "Avg loss: 0.0314 -- Train acc: 0.9738 -- Val acc: 0.9454 -- Test acc: 0.9450 -- Gen gap 0.0289\n",
      "Epoch 60/100\n",
      "Avg loss: 0.0305 -- Train acc: 0.9738 -- Val acc: 0.9454 -- Test acc: 0.9445 -- Gen gap 0.0294\n",
      "Epoch 61/100\n",
      "Avg loss: 0.0303 -- Train acc: 0.9742 -- Val acc: 0.9453 -- Test acc: 0.9444 -- Gen gap 0.0299\n",
      "Epoch 62/100\n",
      "Avg loss: 0.0296 -- Train acc: 0.9738 -- Val acc: 0.9461 -- Test acc: 0.9445 -- Gen gap 0.0294\n",
      "Epoch 63/100\n",
      "Avg loss: 0.0296 -- Train acc: 0.9734 -- Val acc: 0.9455 -- Test acc: 0.9436 -- Gen gap 0.0299\n",
      "Epoch 64/100\n",
      "Avg loss: 0.0303 -- Train acc: 0.9734 -- Val acc: 0.9431 -- Test acc: 0.9432 -- Gen gap 0.0303\n",
      "Epoch 65/100\n",
      "Avg loss: 0.0289 -- Train acc: 0.9746 -- Val acc: 0.9460 -- Test acc: 0.9450 -- Gen gap 0.0296\n",
      "Epoch 66/100\n",
      "Avg loss: 0.0278 -- Train acc: 0.9746 -- Val acc: 0.9455 -- Test acc: 0.9448 -- Gen gap 0.0298\n",
      "Epoch 67/100\n",
      "Avg loss: 0.0272 -- Train acc: 0.9746 -- Val acc: 0.9466 -- Test acc: 0.9449 -- Gen gap 0.0297\n",
      "Epoch 68/100\n",
      "Avg loss: 0.0267 -- Train acc: 0.9746 -- Val acc: 0.9462 -- Test acc: 0.9449 -- Gen gap 0.0297\n",
      "Epoch 69/100\n",
      "Avg loss: 0.0262 -- Train acc: 0.9754 -- Val acc: 0.9460 -- Test acc: 0.9448 -- Gen gap 0.0306\n",
      "Epoch 70/100\n",
      "Avg loss: 0.0266 -- Train acc: 0.9754 -- Val acc: 0.9455 -- Test acc: 0.9446 -- Gen gap 0.0308\n",
      "Epoch 71/100\n",
      "Avg loss: 0.0256 -- Train acc: 0.9758 -- Val acc: 0.9466 -- Test acc: 0.9448 -- Gen gap 0.0310\n",
      "Epoch 72/100\n",
      "Avg loss: 0.0258 -- Train acc: 0.9762 -- Val acc: 0.9449 -- Test acc: 0.9439 -- Gen gap 0.0323\n",
      "Epoch 73/100\n",
      "Avg loss: 0.0251 -- Train acc: 0.9762 -- Val acc: 0.9462 -- Test acc: 0.9438 -- Gen gap 0.0324\n",
      "Epoch 74/100\n",
      "Avg loss: 0.0249 -- Train acc: 0.9758 -- Val acc: 0.9468 -- Test acc: 0.9447 -- Gen gap 0.0311\n",
      "Epoch 75/100\n",
      "Avg loss: 0.0240 -- Train acc: 0.9758 -- Val acc: 0.9466 -- Test acc: 0.9452 -- Gen gap 0.0306\n",
      "Epoch 76/100\n",
      "Avg loss: 0.0236 -- Train acc: 0.9758 -- Val acc: 0.9466 -- Test acc: 0.9450 -- Gen gap 0.0308\n",
      "Epoch 77/100\n",
      "Avg loss: 0.0232 -- Train acc: 0.9762 -- Val acc: 0.9468 -- Test acc: 0.9445 -- Gen gap 0.0317\n",
      "Epoch 78/100\n",
      "Avg loss: 0.0235 -- Train acc: 0.9762 -- Val acc: 0.9458 -- Test acc: 0.9444 -- Gen gap 0.0318\n",
      "Epoch 79/100\n",
      "Avg loss: 0.0226 -- Train acc: 0.9762 -- Val acc: 0.9462 -- Test acc: 0.9444 -- Gen gap 0.0318\n",
      "Epoch 80/100\n",
      "Avg loss: 0.0228 -- Train acc: 0.9762 -- Val acc: 0.9464 -- Test acc: 0.9452 -- Gen gap 0.0310\n",
      "Epoch 81/100\n",
      "Avg loss: 0.0221 -- Train acc: 0.9762 -- Val acc: 0.9461 -- Test acc: 0.9443 -- Gen gap 0.0319\n",
      "Epoch 82/100\n",
      "Avg loss: 0.0217 -- Train acc: 0.9762 -- Val acc: 0.9462 -- Test acc: 0.9451 -- Gen gap 0.0311\n",
      "Epoch 83/100\n",
      "Avg loss: 0.0219 -- Train acc: 0.9762 -- Val acc: 0.9459 -- Test acc: 0.9442 -- Gen gap 0.0320\n",
      "Epoch 84/100\n",
      "Avg loss: 0.0252 -- Train acc: 0.9703 -- Val acc: 0.9390 -- Test acc: 0.9378 -- Gen gap 0.0325\n",
      "Epoch 85/100\n",
      "Avg loss: 0.0239 -- Train acc: 0.9766 -- Val acc: 0.9456 -- Test acc: 0.9440 -- Gen gap 0.0326\n",
      "Epoch 86/100\n",
      "Avg loss: 0.0231 -- Train acc: 0.9754 -- Val acc: 0.9430 -- Test acc: 0.9416 -- Gen gap 0.0338\n",
      "Epoch 87/100\n",
      "Avg loss: 0.0214 -- Train acc: 0.9766 -- Val acc: 0.9464 -- Test acc: 0.9446 -- Gen gap 0.0320\n",
      "Epoch 88/100\n",
      "Avg loss: 0.0206 -- Train acc: 0.9766 -- Val acc: 0.9463 -- Test acc: 0.9441 -- Gen gap 0.0325\n",
      "Epoch 89/100\n",
      "Avg loss: 0.0202 -- Train acc: 0.9766 -- Val acc: 0.9460 -- Test acc: 0.9447 -- Gen gap 0.0319\n",
      "Epoch 90/100\n",
      "Avg loss: 0.0199 -- Train acc: 0.9766 -- Val acc: 0.9458 -- Test acc: 0.9445 -- Gen gap 0.0321\n",
      "Epoch 91/100\n",
      "Avg loss: 0.0194 -- Train acc: 0.9766 -- Val acc: 0.9461 -- Test acc: 0.9444 -- Gen gap 0.0322\n",
      "Epoch 92/100\n",
      "Avg loss: 0.0191 -- Train acc: 0.9766 -- Val acc: 0.9460 -- Test acc: 0.9445 -- Gen gap 0.0321\n",
      "Epoch 93/100\n",
      "Avg loss: 0.0187 -- Train acc: 0.9766 -- Val acc: 0.9460 -- Test acc: 0.9447 -- Gen gap 0.0319\n",
      "Epoch 94/100\n",
      "Avg loss: 0.0184 -- Train acc: 0.9766 -- Val acc: 0.9461 -- Test acc: 0.9445 -- Gen gap 0.0321\n",
      "Epoch 95/100\n",
      "Avg loss: 0.0183 -- Train acc: 0.9766 -- Val acc: 0.9459 -- Test acc: 0.9444 -- Gen gap 0.0322\n",
      "Epoch 96/100\n",
      "Avg loss: 0.0181 -- Train acc: 0.9766 -- Val acc: 0.9463 -- Test acc: 0.9443 -- Gen gap 0.0323\n",
      "Epoch 97/100\n",
      "Avg loss: 0.0192 -- Train acc: 0.9766 -- Val acc: 0.9461 -- Test acc: 0.9446 -- Gen gap 0.0320\n",
      "Epoch 98/100\n",
      "Avg loss: 0.0183 -- Train acc: 0.9766 -- Val acc: 0.9468 -- Test acc: 0.9445 -- Gen gap 0.0321\n",
      "Epoch 99/100\n",
      "Avg loss: 0.0180 -- Train acc: 0.9766 -- Val acc: 0.9463 -- Test acc: 0.9447 -- Gen gap 0.0319\n",
      "Epoch 100/100\n",
      "Avg loss: 0.0181 -- Train acc: 0.9766 -- Val acc: 0.9466 -- Test acc: 0.9446 -- Gen gap 0.0320\n",
      "Training done! Elapsed time: 0:00:23\n",
      "\n",
      "==============================\n",
      "a = 0.10, Na = 5000\n",
      "------------------------------\n",
      "Iter 1\n",
      "Epoch 1/100\n",
      "Avg loss: 0.1620 -- Train acc: 0.9462 -- Val acc: 0.9468 -- Test acc: 0.9443 -- Gen gap 0.0019\n",
      "Epoch 2/100\n",
      "Avg loss: 0.1444 -- Train acc: 0.9472 -- Val acc: 0.9445 -- Test acc: 0.9423 -- Gen gap 0.0049\n",
      "Epoch 3/100\n",
      "Avg loss: 0.1292 -- Train acc: 0.9547 -- Val acc: 0.9473 -- Test acc: 0.9452 -- Gen gap 0.0095\n",
      "Epoch 4/100\n",
      "Avg loss: 0.1176 -- Train acc: 0.9581 -- Val acc: 0.9511 -- Test acc: 0.9488 -- Gen gap 0.0092\n",
      "Epoch 5/100\n",
      "Avg loss: 0.1095 -- Train acc: 0.9634 -- Val acc: 0.9506 -- Test acc: 0.9482 -- Gen gap 0.0152\n",
      "Epoch 6/100\n",
      "Avg loss: 0.1033 -- Train acc: 0.9636 -- Val acc: 0.9492 -- Test acc: 0.9479 -- Gen gap 0.0157\n",
      "Epoch 7/100\n",
      "Avg loss: 0.0969 -- Train acc: 0.9636 -- Val acc: 0.9492 -- Test acc: 0.9466 -- Gen gap 0.0171\n",
      "Epoch 8/100\n",
      "Avg loss: 0.0918 -- Train acc: 0.9660 -- Val acc: 0.9514 -- Test acc: 0.9486 -- Gen gap 0.0173\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.0877 -- Train acc: 0.9660 -- Val acc: 0.9505 -- Test acc: 0.9495 -- Gen gap 0.0164\n",
      "Epoch 10/100\n",
      "Avg loss: 0.0907 -- Train acc: 0.9680 -- Val acc: 0.9484 -- Test acc: 0.9473 -- Gen gap 0.0207\n",
      "Epoch 11/100\n",
      "Avg loss: 0.0802 -- Train acc: 0.9705 -- Val acc: 0.9509 -- Test acc: 0.9481 -- Gen gap 0.0224\n",
      "Epoch 12/100\n",
      "Avg loss: 0.0766 -- Train acc: 0.9701 -- Val acc: 0.9504 -- Test acc: 0.9495 -- Gen gap 0.0206\n",
      "Epoch 13/100\n",
      "Avg loss: 0.0743 -- Train acc: 0.9717 -- Val acc: 0.9486 -- Test acc: 0.9479 -- Gen gap 0.0239\n",
      "Epoch 14/100\n",
      "Avg loss: 0.0703 -- Train acc: 0.9715 -- Val acc: 0.9502 -- Test acc: 0.9506 -- Gen gap 0.0209\n",
      "Epoch 15/100\n",
      "Avg loss: 0.0673 -- Train acc: 0.9747 -- Val acc: 0.9514 -- Test acc: 0.9504 -- Gen gap 0.0242\n",
      "Epoch 16/100\n",
      "Avg loss: 0.0649 -- Train acc: 0.9747 -- Val acc: 0.9504 -- Test acc: 0.9515 -- Gen gap 0.0232\n",
      "Epoch 17/100\n",
      "Avg loss: 0.0637 -- Train acc: 0.9757 -- Val acc: 0.9504 -- Test acc: 0.9511 -- Gen gap 0.0245\n",
      "Epoch 18/100\n",
      "Avg loss: 0.0615 -- Train acc: 0.9769 -- Val acc: 0.9509 -- Test acc: 0.9519 -- Gen gap 0.0249\n",
      "Epoch 19/100\n",
      "Avg loss: 0.0587 -- Train acc: 0.9775 -- Val acc: 0.9515 -- Test acc: 0.9499 -- Gen gap 0.0275\n",
      "Epoch 20/100\n",
      "Avg loss: 0.0583 -- Train acc: 0.9751 -- Val acc: 0.9503 -- Test acc: 0.9499 -- Gen gap 0.0251\n",
      "Epoch 21/100\n",
      "Avg loss: 0.0548 -- Train acc: 0.9784 -- Val acc: 0.9515 -- Test acc: 0.9507 -- Gen gap 0.0277\n",
      "Epoch 22/100\n",
      "Avg loss: 0.0528 -- Train acc: 0.9790 -- Val acc: 0.9504 -- Test acc: 0.9502 -- Gen gap 0.0288\n",
      "Epoch 23/100\n",
      "Avg loss: 0.0522 -- Train acc: 0.9771 -- Val acc: 0.9513 -- Test acc: 0.9513 -- Gen gap 0.0257\n",
      "Epoch 24/100\n",
      "Avg loss: 0.0504 -- Train acc: 0.9804 -- Val acc: 0.9518 -- Test acc: 0.9517 -- Gen gap 0.0287\n",
      "Epoch 25/100\n",
      "Avg loss: 0.0483 -- Train acc: 0.9800 -- Val acc: 0.9519 -- Test acc: 0.9505 -- Gen gap 0.0295\n",
      "Epoch 26/100\n",
      "Avg loss: 0.0468 -- Train acc: 0.9806 -- Val acc: 0.9520 -- Test acc: 0.9511 -- Gen gap 0.0295\n",
      "Epoch 27/100\n",
      "Avg loss: 0.0493 -- Train acc: 0.9802 -- Val acc: 0.9514 -- Test acc: 0.9506 -- Gen gap 0.0296\n",
      "Epoch 28/100\n",
      "Avg loss: 0.0461 -- Train acc: 0.9804 -- Val acc: 0.9500 -- Test acc: 0.9499 -- Gen gap 0.0305\n",
      "Epoch 29/100\n",
      "Avg loss: 0.0429 -- Train acc: 0.9816 -- Val acc: 0.9516 -- Test acc: 0.9502 -- Gen gap 0.0314\n",
      "Epoch 30/100\n",
      "Avg loss: 0.0488 -- Train acc: 0.9745 -- Val acc: 0.9478 -- Test acc: 0.9469 -- Gen gap 0.0276\n",
      "Epoch 31/100\n",
      "Avg loss: 0.0482 -- Train acc: 0.9806 -- Val acc: 0.9523 -- Test acc: 0.9515 -- Gen gap 0.0291\n",
      "Epoch 32/100\n",
      "Avg loss: 0.0397 -- Train acc: 0.9826 -- Val acc: 0.9524 -- Test acc: 0.9512 -- Gen gap 0.0314\n",
      "Epoch 33/100\n",
      "Avg loss: 0.0389 -- Train acc: 0.9826 -- Val acc: 0.9517 -- Test acc: 0.9513 -- Gen gap 0.0313\n",
      "Epoch 34/100\n",
      "Avg loss: 0.0373 -- Train acc: 0.9832 -- Val acc: 0.9521 -- Test acc: 0.9512 -- Gen gap 0.0320\n",
      "Epoch 35/100\n",
      "Avg loss: 0.0375 -- Train acc: 0.9828 -- Val acc: 0.9519 -- Test acc: 0.9510 -- Gen gap 0.0318\n",
      "Epoch 36/100\n",
      "Avg loss: 0.0354 -- Train acc: 0.9840 -- Val acc: 0.9519 -- Test acc: 0.9516 -- Gen gap 0.0323\n",
      "Epoch 37/100\n",
      "Avg loss: 0.0351 -- Train acc: 0.9830 -- Val acc: 0.9524 -- Test acc: 0.9500 -- Gen gap 0.0330\n",
      "Epoch 38/100\n",
      "Avg loss: 0.0340 -- Train acc: 0.9838 -- Val acc: 0.9526 -- Test acc: 0.9515 -- Gen gap 0.0322\n",
      "Epoch 39/100\n",
      "Avg loss: 0.0328 -- Train acc: 0.9848 -- Val acc: 0.9533 -- Test acc: 0.9520 -- Gen gap 0.0327\n",
      "Epoch 40/100\n",
      "Avg loss: 0.0318 -- Train acc: 0.9848 -- Val acc: 0.9524 -- Test acc: 0.9508 -- Gen gap 0.0339\n",
      "Epoch 41/100\n",
      "Avg loss: 0.0315 -- Train acc: 0.9844 -- Val acc: 0.9527 -- Test acc: 0.9531 -- Gen gap 0.0312\n",
      "Epoch 42/100\n",
      "Avg loss: 0.0303 -- Train acc: 0.9850 -- Val acc: 0.9519 -- Test acc: 0.9515 -- Gen gap 0.0334\n",
      "Epoch 43/100\n",
      "Avg loss: 0.0304 -- Train acc: 0.9850 -- Val acc: 0.9535 -- Test acc: 0.9527 -- Gen gap 0.0322\n",
      "Epoch 44/100\n",
      "Avg loss: 0.0295 -- Train acc: 0.9852 -- Val acc: 0.9531 -- Test acc: 0.9511 -- Gen gap 0.0340\n",
      "Epoch 45/100\n",
      "Avg loss: 0.0286 -- Train acc: 0.9858 -- Val acc: 0.9529 -- Test acc: 0.9512 -- Gen gap 0.0345\n",
      "Epoch 46/100\n",
      "Avg loss: 0.0281 -- Train acc: 0.9860 -- Val acc: 0.9533 -- Test acc: 0.9517 -- Gen gap 0.0342\n",
      "Epoch 47/100\n",
      "Avg loss: 0.0274 -- Train acc: 0.9860 -- Val acc: 0.9531 -- Test acc: 0.9521 -- Gen gap 0.0338\n",
      "Epoch 48/100\n",
      "Avg loss: 0.0273 -- Train acc: 0.9858 -- Val acc: 0.9534 -- Test acc: 0.9520 -- Gen gap 0.0337\n",
      "Epoch 49/100\n",
      "Avg loss: 0.0262 -- Train acc: 0.9862 -- Val acc: 0.9533 -- Test acc: 0.9515 -- Gen gap 0.0346\n",
      "Epoch 50/100\n",
      "Avg loss: 0.0260 -- Train acc: 0.9864 -- Val acc: 0.9534 -- Test acc: 0.9525 -- Gen gap 0.0338\n",
      "Epoch 51/100\n",
      "Avg loss: 0.0252 -- Train acc: 0.9864 -- Val acc: 0.9532 -- Test acc: 0.9522 -- Gen gap 0.0341\n",
      "Epoch 52/100\n",
      "Avg loss: 0.0246 -- Train acc: 0.9869 -- Val acc: 0.9530 -- Test acc: 0.9512 -- Gen gap 0.0357\n",
      "Epoch 53/100\n",
      "Avg loss: 0.0241 -- Train acc: 0.9866 -- Val acc: 0.9532 -- Test acc: 0.9522 -- Gen gap 0.0343\n",
      "Epoch 54/100\n",
      "Avg loss: 0.0237 -- Train acc: 0.9864 -- Val acc: 0.9529 -- Test acc: 0.9520 -- Gen gap 0.0343\n",
      "Epoch 55/100\n",
      "Avg loss: 0.0233 -- Train acc: 0.9871 -- Val acc: 0.9535 -- Test acc: 0.9525 -- Gen gap 0.0346\n",
      "Epoch 56/100\n",
      "Avg loss: 0.0227 -- Train acc: 0.9871 -- Val acc: 0.9527 -- Test acc: 0.9523 -- Gen gap 0.0348\n",
      "Epoch 57/100\n",
      "Avg loss: 0.0226 -- Train acc: 0.9871 -- Val acc: 0.9534 -- Test acc: 0.9524 -- Gen gap 0.0347\n",
      "Epoch 58/100\n",
      "Avg loss: 0.0219 -- Train acc: 0.9871 -- Val acc: 0.9534 -- Test acc: 0.9527 -- Gen gap 0.0344\n",
      "Epoch 59/100\n",
      "Avg loss: 0.0215 -- Train acc: 0.9875 -- Val acc: 0.9538 -- Test acc: 0.9521 -- Gen gap 0.0354\n",
      "Epoch 60/100\n",
      "Avg loss: 0.0211 -- Train acc: 0.9871 -- Val acc: 0.9532 -- Test acc: 0.9523 -- Gen gap 0.0348\n",
      "Epoch 61/100\n",
      "Avg loss: 0.0217 -- Train acc: 0.9875 -- Val acc: 0.9535 -- Test acc: 0.9521 -- Gen gap 0.0354\n",
      "Epoch 62/100\n",
      "Avg loss: 0.0204 -- Train acc: 0.9879 -- Val acc: 0.9537 -- Test acc: 0.9522 -- Gen gap 0.0357\n",
      "Epoch 63/100\n",
      "Avg loss: 0.0201 -- Train acc: 0.9877 -- Val acc: 0.9539 -- Test acc: 0.9516 -- Gen gap 0.0361\n",
      "Epoch 64/100\n",
      "Avg loss: 0.0196 -- Train acc: 0.9877 -- Val acc: 0.9534 -- Test acc: 0.9522 -- Gen gap 0.0355\n",
      "Epoch 65/100\n",
      "Avg loss: 0.0193 -- Train acc: 0.9879 -- Val acc: 0.9538 -- Test acc: 0.9518 -- Gen gap 0.0361\n",
      "Epoch 66/100\n",
      "Avg loss: 0.0193 -- Train acc: 0.9879 -- Val acc: 0.9533 -- Test acc: 0.9522 -- Gen gap 0.0357\n",
      "Epoch 67/100\n",
      "Avg loss: 0.0186 -- Train acc: 0.9881 -- Val acc: 0.9536 -- Test acc: 0.9523 -- Gen gap 0.0358\n",
      "Epoch 68/100\n",
      "Avg loss: 0.0185 -- Train acc: 0.9885 -- Val acc: 0.9538 -- Test acc: 0.9524 -- Gen gap 0.0361\n",
      "Epoch 69/100\n",
      "Avg loss: 0.0185 -- Train acc: 0.9883 -- Val acc: 0.9537 -- Test acc: 0.9526 -- Gen gap 0.0357\n",
      "Epoch 70/100\n",
      "Avg loss: 0.0179 -- Train acc: 0.9885 -- Val acc: 0.9536 -- Test acc: 0.9520 -- Gen gap 0.0365\n",
      "Epoch 71/100\n",
      "Avg loss: 0.0178 -- Train acc: 0.9885 -- Val acc: 0.9536 -- Test acc: 0.9516 -- Gen gap 0.0369\n",
      "Epoch 72/100\n",
      "Avg loss: 0.0175 -- Train acc: 0.9885 -- Val acc: 0.9540 -- Test acc: 0.9525 -- Gen gap 0.0360\n",
      "Epoch 73/100\n",
      "Avg loss: 0.0172 -- Train acc: 0.9883 -- Val acc: 0.9535 -- Test acc: 0.9527 -- Gen gap 0.0356\n",
      "Epoch 74/100\n",
      "Avg loss: 0.0169 -- Train acc: 0.9887 -- Val acc: 0.9541 -- Test acc: 0.9523 -- Gen gap 0.0364\n",
      "Epoch 75/100\n",
      "Avg loss: 0.0164 -- Train acc: 0.9885 -- Val acc: 0.9539 -- Test acc: 0.9523 -- Gen gap 0.0362\n",
      "Epoch 76/100\n",
      "Avg loss: 0.0163 -- Train acc: 0.9887 -- Val acc: 0.9542 -- Test acc: 0.9521 -- Gen gap 0.0366\n",
      "Epoch 77/100\n",
      "Avg loss: 0.0164 -- Train acc: 0.9887 -- Val acc: 0.9539 -- Test acc: 0.9521 -- Gen gap 0.0366\n",
      "Epoch 78/100\n",
      "Avg loss: 0.0158 -- Train acc: 0.9887 -- Val acc: 0.9535 -- Test acc: 0.9525 -- Gen gap 0.0362\n",
      "Epoch 79/100\n",
      "Avg loss: 0.0160 -- Train acc: 0.9887 -- Val acc: 0.9523 -- Test acc: 0.9506 -- Gen gap 0.0381\n",
      "Epoch 80/100\n",
      "Avg loss: 0.0155 -- Train acc: 0.9889 -- Val acc: 0.9540 -- Test acc: 0.9520 -- Gen gap 0.0369\n",
      "Epoch 81/100\n",
      "Avg loss: 0.0152 -- Train acc: 0.9889 -- Val acc: 0.9537 -- Test acc: 0.9535 -- Gen gap 0.0354\n",
      "Epoch 82/100\n",
      "Avg loss: 0.0149 -- Train acc: 0.9887 -- Val acc: 0.9536 -- Test acc: 0.9529 -- Gen gap 0.0358\n",
      "Epoch 83/100\n",
      "Avg loss: 0.0147 -- Train acc: 0.9889 -- Val acc: 0.9538 -- Test acc: 0.9530 -- Gen gap 0.0359\n",
      "Epoch 84/100\n",
      "Avg loss: 0.0146 -- Train acc: 0.9889 -- Val acc: 0.9536 -- Test acc: 0.9519 -- Gen gap 0.0370\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.0143 -- Train acc: 0.9889 -- Val acc: 0.9538 -- Test acc: 0.9527 -- Gen gap 0.0362\n",
      "Epoch 86/100\n",
      "Avg loss: 0.0141 -- Train acc: 0.9889 -- Val acc: 0.9536 -- Test acc: 0.9530 -- Gen gap 0.0359\n",
      "Epoch 87/100\n",
      "Avg loss: 0.0139 -- Train acc: 0.9889 -- Val acc: 0.9540 -- Test acc: 0.9518 -- Gen gap 0.0371\n",
      "Epoch 88/100\n",
      "Avg loss: 0.0139 -- Train acc: 0.9887 -- Val acc: 0.9536 -- Test acc: 0.9519 -- Gen gap 0.0368\n",
      "Epoch 89/100\n",
      "Avg loss: 0.0136 -- Train acc: 0.9889 -- Val acc: 0.9540 -- Test acc: 0.9529 -- Gen gap 0.0360\n",
      "Epoch 90/100\n",
      "Avg loss: 0.0134 -- Train acc: 0.9889 -- Val acc: 0.9536 -- Test acc: 0.9526 -- Gen gap 0.0363\n",
      "Epoch 91/100\n",
      "Avg loss: 0.0132 -- Train acc: 0.9889 -- Val acc: 0.9537 -- Test acc: 0.9531 -- Gen gap 0.0358\n",
      "Epoch 92/100\n",
      "Avg loss: 0.0134 -- Train acc: 0.9889 -- Val acc: 0.9539 -- Test acc: 0.9533 -- Gen gap 0.0356\n",
      "Epoch 93/100\n",
      "Avg loss: 0.0129 -- Train acc: 0.9889 -- Val acc: 0.9541 -- Test acc: 0.9529 -- Gen gap 0.0360\n",
      "Epoch 94/100\n",
      "Avg loss: 0.0127 -- Train acc: 0.9889 -- Val acc: 0.9539 -- Test acc: 0.9527 -- Gen gap 0.0362\n",
      "Epoch 95/100\n",
      "Avg loss: 0.0129 -- Train acc: 0.9889 -- Val acc: 0.9538 -- Test acc: 0.9519 -- Gen gap 0.0370\n",
      "Epoch 96/100\n",
      "Avg loss: 0.0126 -- Train acc: 0.9889 -- Val acc: 0.9539 -- Test acc: 0.9525 -- Gen gap 0.0364\n",
      "Epoch 97/100\n",
      "Avg loss: 0.0123 -- Train acc: 0.9889 -- Val acc: 0.9540 -- Test acc: 0.9527 -- Gen gap 0.0362\n",
      "Epoch 98/100\n",
      "Avg loss: 0.0123 -- Train acc: 0.9889 -- Val acc: 0.9541 -- Test acc: 0.9537 -- Gen gap 0.0352\n",
      "Epoch 99/100\n",
      "Avg loss: 0.0121 -- Train acc: 0.9889 -- Val acc: 0.9540 -- Test acc: 0.9528 -- Gen gap 0.0361\n",
      "Epoch 100/100\n",
      "Avg loss: 0.0120 -- Train acc: 0.9889 -- Val acc: 0.9542 -- Test acc: 0.9524 -- Gen gap 0.0365\n",
      "Training done! Elapsed time: 0:00:33\n",
      "\n",
      "Iter 2\n",
      "Epoch 1/100\n",
      "Avg loss: 0.1530 -- Train acc: 0.9527 -- Val acc: 0.9551 -- Test acc: 0.9544 -- Gen gap -0.0017\n",
      "Epoch 2/100\n",
      "Avg loss: 0.1344 -- Train acc: 0.9571 -- Val acc: 0.9557 -- Test acc: 0.9545 -- Gen gap 0.0026\n",
      "Epoch 3/100\n",
      "Avg loss: 0.1234 -- Train acc: 0.9598 -- Val acc: 0.9567 -- Test acc: 0.9555 -- Gen gap 0.0043\n",
      "Epoch 4/100\n",
      "Avg loss: 0.1133 -- Train acc: 0.9634 -- Val acc: 0.9573 -- Test acc: 0.9565 -- Gen gap 0.0069\n",
      "Epoch 5/100\n",
      "Avg loss: 0.1047 -- Train acc: 0.9646 -- Val acc: 0.9578 -- Test acc: 0.9566 -- Gen gap 0.0080\n",
      "Epoch 6/100\n",
      "Avg loss: 0.0985 -- Train acc: 0.9654 -- Val acc: 0.9575 -- Test acc: 0.9564 -- Gen gap 0.0090\n",
      "Epoch 7/100\n",
      "Avg loss: 0.0977 -- Train acc: 0.9670 -- Val acc: 0.9566 -- Test acc: 0.9565 -- Gen gap 0.0105\n",
      "Epoch 8/100\n",
      "Avg loss: 0.0875 -- Train acc: 0.9686 -- Val acc: 0.9576 -- Test acc: 0.9567 -- Gen gap 0.0118\n",
      "Epoch 9/100\n",
      "Avg loss: 0.0855 -- Train acc: 0.9470 -- Val acc: 0.9405 -- Test acc: 0.9397 -- Gen gap 0.0073\n",
      "Epoch 10/100\n",
      "Avg loss: 0.0817 -- Train acc: 0.9709 -- Val acc: 0.9580 -- Test acc: 0.9568 -- Gen gap 0.0141\n",
      "Epoch 11/100\n",
      "Avg loss: 0.0757 -- Train acc: 0.9703 -- Val acc: 0.9574 -- Test acc: 0.9571 -- Gen gap 0.0132\n",
      "Epoch 12/100\n",
      "Avg loss: 0.0716 -- Train acc: 0.9733 -- Val acc: 0.9587 -- Test acc: 0.9582 -- Gen gap 0.0151\n",
      "Epoch 13/100\n",
      "Avg loss: 0.0684 -- Train acc: 0.9737 -- Val acc: 0.9576 -- Test acc: 0.9575 -- Gen gap 0.0162\n",
      "Epoch 14/100\n",
      "Avg loss: 0.0652 -- Train acc: 0.9751 -- Val acc: 0.9578 -- Test acc: 0.9582 -- Gen gap 0.0169\n",
      "Epoch 15/100\n",
      "Avg loss: 0.0642 -- Train acc: 0.9743 -- Val acc: 0.9568 -- Test acc: 0.9570 -- Gen gap 0.0173\n",
      "Epoch 16/100\n",
      "Avg loss: 0.0602 -- Train acc: 0.9765 -- Val acc: 0.9584 -- Test acc: 0.9574 -- Gen gap 0.0191\n",
      "Epoch 17/100\n",
      "Avg loss: 0.0576 -- Train acc: 0.9777 -- Val acc: 0.9578 -- Test acc: 0.9570 -- Gen gap 0.0206\n",
      "Epoch 18/100\n",
      "Avg loss: 0.0552 -- Train acc: 0.9782 -- Val acc: 0.9583 -- Test acc: 0.9563 -- Gen gap 0.0219\n",
      "Epoch 19/100\n",
      "Avg loss: 0.0534 -- Train acc: 0.9788 -- Val acc: 0.9574 -- Test acc: 0.9582 -- Gen gap 0.0206\n",
      "Epoch 20/100\n",
      "Avg loss: 0.0528 -- Train acc: 0.9788 -- Val acc: 0.9570 -- Test acc: 0.9565 -- Gen gap 0.0223\n",
      "Epoch 21/100\n",
      "Avg loss: 0.0511 -- Train acc: 0.9796 -- Val acc: 0.9584 -- Test acc: 0.9581 -- Gen gap 0.0215\n",
      "Epoch 22/100\n",
      "Avg loss: 0.0483 -- Train acc: 0.9810 -- Val acc: 0.9586 -- Test acc: 0.9578 -- Gen gap 0.0232\n",
      "Epoch 23/100\n",
      "Avg loss: 0.0468 -- Train acc: 0.9812 -- Val acc: 0.9586 -- Test acc: 0.9578 -- Gen gap 0.0234\n",
      "Epoch 24/100\n",
      "Avg loss: 0.0450 -- Train acc: 0.9820 -- Val acc: 0.9576 -- Test acc: 0.9572 -- Gen gap 0.0248\n",
      "Epoch 25/100\n",
      "Avg loss: 0.0436 -- Train acc: 0.9820 -- Val acc: 0.9588 -- Test acc: 0.9577 -- Gen gap 0.0243\n",
      "Epoch 26/100\n",
      "Avg loss: 0.0422 -- Train acc: 0.9830 -- Val acc: 0.9585 -- Test acc: 0.9575 -- Gen gap 0.0255\n",
      "Epoch 27/100\n",
      "Avg loss: 0.0408 -- Train acc: 0.9838 -- Val acc: 0.9582 -- Test acc: 0.9585 -- Gen gap 0.0253\n",
      "Epoch 28/100\n",
      "Avg loss: 0.0396 -- Train acc: 0.9836 -- Val acc: 0.9585 -- Test acc: 0.9571 -- Gen gap 0.0265\n",
      "Epoch 29/100\n",
      "Avg loss: 0.0384 -- Train acc: 0.9850 -- Val acc: 0.9580 -- Test acc: 0.9580 -- Gen gap 0.0270\n",
      "Epoch 30/100\n",
      "Avg loss: 0.0376 -- Train acc: 0.9850 -- Val acc: 0.9576 -- Test acc: 0.9574 -- Gen gap 0.0276\n",
      "Epoch 31/100\n",
      "Avg loss: 0.0365 -- Train acc: 0.9846 -- Val acc: 0.9584 -- Test acc: 0.9572 -- Gen gap 0.0274\n",
      "Epoch 32/100\n",
      "Avg loss: 0.0355 -- Train acc: 0.9850 -- Val acc: 0.9585 -- Test acc: 0.9568 -- Gen gap 0.0282\n",
      "Epoch 33/100\n",
      "Avg loss: 0.0342 -- Train acc: 0.9854 -- Val acc: 0.9587 -- Test acc: 0.9571 -- Gen gap 0.0283\n",
      "Epoch 34/100\n",
      "Avg loss: 0.0344 -- Train acc: 0.9856 -- Val acc: 0.9587 -- Test acc: 0.9589 -- Gen gap 0.0267\n",
      "Epoch 35/100\n",
      "Avg loss: 0.0325 -- Train acc: 0.9852 -- Val acc: 0.9578 -- Test acc: 0.9577 -- Gen gap 0.0275\n",
      "Epoch 36/100\n",
      "Avg loss: 0.0323 -- Train acc: 0.9850 -- Val acc: 0.9588 -- Test acc: 0.9574 -- Gen gap 0.0276\n",
      "Epoch 37/100\n",
      "Avg loss: 0.0313 -- Train acc: 0.9864 -- Val acc: 0.9583 -- Test acc: 0.9574 -- Gen gap 0.0289\n",
      "Epoch 38/100\n",
      "Avg loss: 0.0312 -- Train acc: 0.9862 -- Val acc: 0.9585 -- Test acc: 0.9568 -- Gen gap 0.0293\n",
      "Epoch 39/100\n",
      "Avg loss: 0.0297 -- Train acc: 0.9867 -- Val acc: 0.9581 -- Test acc: 0.9568 -- Gen gap 0.0299\n",
      "Epoch 40/100\n",
      "Avg loss: 0.0288 -- Train acc: 0.9866 -- Val acc: 0.9590 -- Test acc: 0.9572 -- Gen gap 0.0293\n",
      "Epoch 41/100\n",
      "Avg loss: 0.0282 -- Train acc: 0.9864 -- Val acc: 0.9581 -- Test acc: 0.9566 -- Gen gap 0.0297\n",
      "Epoch 42/100\n",
      "Avg loss: 0.0275 -- Train acc: 0.9869 -- Val acc: 0.9586 -- Test acc: 0.9577 -- Gen gap 0.0292\n",
      "Epoch 43/100\n",
      "Avg loss: 0.0267 -- Train acc: 0.9871 -- Val acc: 0.9587 -- Test acc: 0.9574 -- Gen gap 0.0297\n",
      "Epoch 44/100\n",
      "Avg loss: 0.0263 -- Train acc: 0.9867 -- Val acc: 0.9583 -- Test acc: 0.9577 -- Gen gap 0.0290\n",
      "Epoch 45/100\n",
      "Avg loss: 0.0261 -- Train acc: 0.9873 -- Val acc: 0.9590 -- Test acc: 0.9579 -- Gen gap 0.0294\n",
      "Epoch 46/100\n",
      "Avg loss: 0.0251 -- Train acc: 0.9875 -- Val acc: 0.9585 -- Test acc: 0.9572 -- Gen gap 0.0303\n",
      "Epoch 47/100\n",
      "Avg loss: 0.0245 -- Train acc: 0.9875 -- Val acc: 0.9585 -- Test acc: 0.9572 -- Gen gap 0.0303\n",
      "Epoch 48/100\n",
      "Avg loss: 0.0240 -- Train acc: 0.9875 -- Val acc: 0.9586 -- Test acc: 0.9577 -- Gen gap 0.0298\n",
      "Epoch 49/100\n",
      "Avg loss: 0.0252 -- Train acc: 0.9848 -- Val acc: 0.9566 -- Test acc: 0.9540 -- Gen gap 0.0307\n",
      "Epoch 50/100\n",
      "Avg loss: 0.0235 -- Train acc: 0.9875 -- Val acc: 0.9586 -- Test acc: 0.9575 -- Gen gap 0.0300\n",
      "Epoch 51/100\n",
      "Avg loss: 0.0224 -- Train acc: 0.9875 -- Val acc: 0.9585 -- Test acc: 0.9576 -- Gen gap 0.0299\n",
      "Epoch 52/100\n",
      "Avg loss: 0.0222 -- Train acc: 0.9875 -- Val acc: 0.9583 -- Test acc: 0.9576 -- Gen gap 0.0299\n",
      "Epoch 53/100\n",
      "Avg loss: 0.0220 -- Train acc: 0.9877 -- Val acc: 0.9588 -- Test acc: 0.9574 -- Gen gap 0.0303\n",
      "Epoch 54/100\n",
      "Avg loss: 0.0214 -- Train acc: 0.9879 -- Val acc: 0.9584 -- Test acc: 0.9574 -- Gen gap 0.0305\n",
      "Epoch 55/100\n",
      "Avg loss: 0.0209 -- Train acc: 0.9881 -- Val acc: 0.9583 -- Test acc: 0.9572 -- Gen gap 0.0309\n",
      "Epoch 56/100\n",
      "Avg loss: 0.0206 -- Train acc: 0.9881 -- Val acc: 0.9592 -- Test acc: 0.9573 -- Gen gap 0.0308\n",
      "Epoch 57/100\n",
      "Avg loss: 0.0200 -- Train acc: 0.9881 -- Val acc: 0.9588 -- Test acc: 0.9571 -- Gen gap 0.0310\n",
      "Epoch 58/100\n",
      "Avg loss: 0.0197 -- Train acc: 0.9881 -- Val acc: 0.9586 -- Test acc: 0.9575 -- Gen gap 0.0306\n",
      "Epoch 59/100\n",
      "Avg loss: 0.0199 -- Train acc: 0.9881 -- Val acc: 0.9586 -- Test acc: 0.9567 -- Gen gap 0.0314\n",
      "Epoch 60/100\n",
      "Avg loss: 0.0191 -- Train acc: 0.9881 -- Val acc: 0.9589 -- Test acc: 0.9575 -- Gen gap 0.0306\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.0188 -- Train acc: 0.9883 -- Val acc: 0.9587 -- Test acc: 0.9575 -- Gen gap 0.0308\n",
      "Epoch 62/100\n",
      "Avg loss: 0.0184 -- Train acc: 0.9883 -- Val acc: 0.9584 -- Test acc: 0.9570 -- Gen gap 0.0313\n",
      "Epoch 63/100\n",
      "Avg loss: 0.0186 -- Train acc: 0.9881 -- Val acc: 0.9590 -- Test acc: 0.9566 -- Gen gap 0.0315\n",
      "Epoch 64/100\n",
      "Avg loss: 0.0180 -- Train acc: 0.9883 -- Val acc: 0.9579 -- Test acc: 0.9576 -- Gen gap 0.0307\n",
      "Epoch 65/100\n",
      "Avg loss: 0.0175 -- Train acc: 0.9885 -- Val acc: 0.9585 -- Test acc: 0.9572 -- Gen gap 0.0313\n",
      "Epoch 66/100\n",
      "Avg loss: 0.0174 -- Train acc: 0.9885 -- Val acc: 0.9587 -- Test acc: 0.9573 -- Gen gap 0.0312\n",
      "Epoch 67/100\n",
      "Avg loss: 0.0168 -- Train acc: 0.9885 -- Val acc: 0.9586 -- Test acc: 0.9571 -- Gen gap 0.0314\n",
      "Epoch 68/100\n",
      "Avg loss: 0.0168 -- Train acc: 0.9885 -- Val acc: 0.9589 -- Test acc: 0.9575 -- Gen gap 0.0310\n",
      "Epoch 69/100\n",
      "Avg loss: 0.0165 -- Train acc: 0.9885 -- Val acc: 0.9581 -- Test acc: 0.9572 -- Gen gap 0.0313\n",
      "Epoch 70/100\n",
      "Avg loss: 0.0163 -- Train acc: 0.9885 -- Val acc: 0.9579 -- Test acc: 0.9571 -- Gen gap 0.0314\n",
      "Epoch 71/100\n",
      "Avg loss: 0.0158 -- Train acc: 0.9885 -- Val acc: 0.9589 -- Test acc: 0.9577 -- Gen gap 0.0308\n",
      "Epoch 72/100\n",
      "Avg loss: 0.0162 -- Train acc: 0.9885 -- Val acc: 0.9574 -- Test acc: 0.9559 -- Gen gap 0.0326\n",
      "Epoch 73/100\n",
      "Avg loss: 0.0155 -- Train acc: 0.9885 -- Val acc: 0.9581 -- Test acc: 0.9577 -- Gen gap 0.0308\n",
      "Epoch 74/100\n",
      "Avg loss: 0.0154 -- Train acc: 0.9885 -- Val acc: 0.9584 -- Test acc: 0.9581 -- Gen gap 0.0304\n",
      "Epoch 75/100\n",
      "Avg loss: 0.0149 -- Train acc: 0.9885 -- Val acc: 0.9580 -- Test acc: 0.9575 -- Gen gap 0.0310\n",
      "Epoch 76/100\n",
      "Avg loss: 0.0148 -- Train acc: 0.9885 -- Val acc: 0.9587 -- Test acc: 0.9578 -- Gen gap 0.0307\n",
      "Epoch 77/100\n",
      "Avg loss: 0.0147 -- Train acc: 0.9885 -- Val acc: 0.9583 -- Test acc: 0.9574 -- Gen gap 0.0311\n",
      "Epoch 78/100\n",
      "Avg loss: 0.0144 -- Train acc: 0.9885 -- Val acc: 0.9585 -- Test acc: 0.9575 -- Gen gap 0.0310\n",
      "Epoch 79/100\n",
      "Avg loss: 0.0144 -- Train acc: 0.9885 -- Val acc: 0.9580 -- Test acc: 0.9578 -- Gen gap 0.0307\n",
      "Epoch 80/100\n",
      "Avg loss: 0.0140 -- Train acc: 0.9885 -- Val acc: 0.9583 -- Test acc: 0.9571 -- Gen gap 0.0314\n",
      "Epoch 81/100\n",
      "Avg loss: 0.0139 -- Train acc: 0.9885 -- Val acc: 0.9583 -- Test acc: 0.9576 -- Gen gap 0.0309\n",
      "Epoch 82/100\n",
      "Avg loss: 0.0136 -- Train acc: 0.9885 -- Val acc: 0.9586 -- Test acc: 0.9577 -- Gen gap 0.0308\n",
      "Epoch 83/100\n",
      "Avg loss: 0.0137 -- Train acc: 0.9885 -- Val acc: 0.9584 -- Test acc: 0.9574 -- Gen gap 0.0311\n",
      "Epoch 84/100\n",
      "Avg loss: 0.0133 -- Train acc: 0.9885 -- Val acc: 0.9585 -- Test acc: 0.9573 -- Gen gap 0.0312\n",
      "Epoch 85/100\n",
      "Avg loss: 0.0131 -- Train acc: 0.9885 -- Val acc: 0.9580 -- Test acc: 0.9578 -- Gen gap 0.0307\n",
      "Epoch 86/100\n",
      "Avg loss: 0.0130 -- Train acc: 0.9885 -- Val acc: 0.9584 -- Test acc: 0.9577 -- Gen gap 0.0308\n",
      "Epoch 87/100\n",
      "Avg loss: 0.0129 -- Train acc: 0.9885 -- Val acc: 0.9589 -- Test acc: 0.9573 -- Gen gap 0.0312\n",
      "Epoch 88/100\n",
      "Avg loss: 0.0127 -- Train acc: 0.9885 -- Val acc: 0.9578 -- Test acc: 0.9563 -- Gen gap 0.0322\n",
      "Epoch 89/100\n",
      "Avg loss: 0.0126 -- Train acc: 0.9885 -- Val acc: 0.9581 -- Test acc: 0.9571 -- Gen gap 0.0314\n",
      "Epoch 90/100\n",
      "Avg loss: 0.0138 -- Train acc: 0.9883 -- Val acc: 0.9572 -- Test acc: 0.9559 -- Gen gap 0.0324\n",
      "Epoch 91/100\n",
      "Avg loss: 0.0130 -- Train acc: 0.9887 -- Val acc: 0.9580 -- Test acc: 0.9568 -- Gen gap 0.0319\n",
      "Epoch 92/100\n",
      "Avg loss: 0.0121 -- Train acc: 0.9887 -- Val acc: 0.9582 -- Test acc: 0.9573 -- Gen gap 0.0314\n",
      "Epoch 93/100\n",
      "Avg loss: 0.0118 -- Train acc: 0.9887 -- Val acc: 0.9583 -- Test acc: 0.9576 -- Gen gap 0.0311\n",
      "Epoch 94/100\n",
      "Avg loss: 0.0119 -- Train acc: 0.9887 -- Val acc: 0.9582 -- Test acc: 0.9571 -- Gen gap 0.0316\n",
      "Epoch 95/100\n",
      "Avg loss: 0.0115 -- Train acc: 0.9887 -- Val acc: 0.9581 -- Test acc: 0.9579 -- Gen gap 0.0308\n",
      "Epoch 96/100\n",
      "Avg loss: 0.0113 -- Train acc: 0.9887 -- Val acc: 0.9583 -- Test acc: 0.9576 -- Gen gap 0.0311\n",
      "Epoch 97/100\n",
      "Avg loss: 0.0112 -- Train acc: 0.9887 -- Val acc: 0.9581 -- Test acc: 0.9573 -- Gen gap 0.0314\n",
      "Epoch 98/100\n",
      "Avg loss: 0.0111 -- Train acc: 0.9887 -- Val acc: 0.9583 -- Test acc: 0.9575 -- Gen gap 0.0312\n",
      "Epoch 99/100\n",
      "Avg loss: 0.0109 -- Train acc: 0.9887 -- Val acc: 0.9582 -- Test acc: 0.9573 -- Gen gap 0.0314\n",
      "Epoch 100/100\n",
      "Avg loss: 0.0108 -- Train acc: 0.9887 -- Val acc: 0.9582 -- Test acc: 0.9575 -- Gen gap 0.0312\n",
      "Training done! Elapsed time: 0:00:33\n",
      "\n",
      "Iter 3\n",
      "Epoch 1/100\n",
      "Avg loss: 0.0996 -- Train acc: 0.9640 -- Val acc: 0.9597 -- Test acc: 0.9578 -- Gen gap 0.0062\n",
      "Epoch 2/100\n",
      "Avg loss: 0.0861 -- Train acc: 0.9662 -- Val acc: 0.9585 -- Test acc: 0.9583 -- Gen gap 0.0079\n",
      "Epoch 3/100\n",
      "Avg loss: 0.0775 -- Train acc: 0.9676 -- Val acc: 0.9590 -- Test acc: 0.9587 -- Gen gap 0.0089\n",
      "Epoch 4/100\n",
      "Avg loss: 0.0696 -- Train acc: 0.9721 -- Val acc: 0.9585 -- Test acc: 0.9577 -- Gen gap 0.0144\n",
      "Epoch 5/100\n",
      "Avg loss: 0.0636 -- Train acc: 0.9727 -- Val acc: 0.9600 -- Test acc: 0.9597 -- Gen gap 0.0130\n",
      "Epoch 6/100\n",
      "Avg loss: 0.0581 -- Train acc: 0.9721 -- Val acc: 0.9570 -- Test acc: 0.9577 -- Gen gap 0.0144\n",
      "Epoch 7/100\n",
      "Avg loss: 0.0543 -- Train acc: 0.9761 -- Val acc: 0.9591 -- Test acc: 0.9601 -- Gen gap 0.0160\n",
      "Epoch 8/100\n",
      "Avg loss: 0.0499 -- Train acc: 0.9777 -- Val acc: 0.9599 -- Test acc: 0.9601 -- Gen gap 0.0176\n",
      "Epoch 9/100\n",
      "Avg loss: 0.0525 -- Train acc: 0.9733 -- Val acc: 0.9554 -- Test acc: 0.9549 -- Gen gap 0.0184\n",
      "Epoch 10/100\n",
      "Avg loss: 0.0454 -- Train acc: 0.9790 -- Val acc: 0.9589 -- Test acc: 0.9597 -- Gen gap 0.0193\n",
      "Epoch 11/100\n",
      "Avg loss: 0.0412 -- Train acc: 0.9804 -- Val acc: 0.9597 -- Test acc: 0.9591 -- Gen gap 0.0213\n",
      "Epoch 12/100\n",
      "Avg loss: 0.0387 -- Train acc: 0.9818 -- Val acc: 0.9594 -- Test acc: 0.9601 -- Gen gap 0.0217\n",
      "Epoch 13/100\n",
      "Avg loss: 0.0368 -- Train acc: 0.9818 -- Val acc: 0.9596 -- Test acc: 0.9600 -- Gen gap 0.0218\n",
      "Epoch 14/100\n",
      "Avg loss: 0.0352 -- Train acc: 0.9818 -- Val acc: 0.9602 -- Test acc: 0.9603 -- Gen gap 0.0215\n",
      "Epoch 15/100\n",
      "Avg loss: 0.0331 -- Train acc: 0.9836 -- Val acc: 0.9598 -- Test acc: 0.9598 -- Gen gap 0.0238\n",
      "Epoch 16/100\n",
      "Avg loss: 0.0317 -- Train acc: 0.9830 -- Val acc: 0.9607 -- Test acc: 0.9608 -- Gen gap 0.0222\n",
      "Epoch 17/100\n",
      "Avg loss: 0.0300 -- Train acc: 0.9842 -- Val acc: 0.9598 -- Test acc: 0.9600 -- Gen gap 0.0242\n",
      "Epoch 18/100\n",
      "Avg loss: 0.0291 -- Train acc: 0.9844 -- Val acc: 0.9595 -- Test acc: 0.9604 -- Gen gap 0.0240\n",
      "Epoch 19/100\n",
      "Avg loss: 0.0280 -- Train acc: 0.9856 -- Val acc: 0.9591 -- Test acc: 0.9594 -- Gen gap 0.0262\n",
      "Epoch 20/100\n",
      "Avg loss: 0.0266 -- Train acc: 0.9862 -- Val acc: 0.9592 -- Test acc: 0.9607 -- Gen gap 0.0255\n",
      "Epoch 21/100\n",
      "Avg loss: 0.0261 -- Train acc: 0.9862 -- Val acc: 0.9586 -- Test acc: 0.9601 -- Gen gap 0.0261\n",
      "Epoch 22/100\n",
      "Avg loss: 0.0248 -- Train acc: 0.9866 -- Val acc: 0.9597 -- Test acc: 0.9605 -- Gen gap 0.0261\n",
      "Epoch 23/100\n",
      "Avg loss: 0.0238 -- Train acc: 0.9869 -- Val acc: 0.9603 -- Test acc: 0.9608 -- Gen gap 0.0262\n",
      "Epoch 24/100\n",
      "Avg loss: 0.0231 -- Train acc: 0.9875 -- Val acc: 0.9599 -- Test acc: 0.9605 -- Gen gap 0.0270\n",
      "Epoch 25/100\n",
      "Avg loss: 0.0223 -- Train acc: 0.9873 -- Val acc: 0.9596 -- Test acc: 0.9603 -- Gen gap 0.0271\n",
      "Epoch 26/100\n",
      "Avg loss: 0.0215 -- Train acc: 0.9877 -- Val acc: 0.9598 -- Test acc: 0.9604 -- Gen gap 0.0273\n",
      "Epoch 27/100\n",
      "Avg loss: 0.0209 -- Train acc: 0.9875 -- Val acc: 0.9598 -- Test acc: 0.9610 -- Gen gap 0.0266\n",
      "Epoch 28/100\n",
      "Avg loss: 0.0202 -- Train acc: 0.9879 -- Val acc: 0.9600 -- Test acc: 0.9610 -- Gen gap 0.0269\n",
      "Epoch 29/100\n",
      "Avg loss: 0.0200 -- Train acc: 0.9879 -- Val acc: 0.9594 -- Test acc: 0.9604 -- Gen gap 0.0275\n",
      "Epoch 30/100\n",
      "Avg loss: 0.0192 -- Train acc: 0.9879 -- Val acc: 0.9596 -- Test acc: 0.9610 -- Gen gap 0.0269\n",
      "Epoch 31/100\n",
      "Avg loss: 0.0186 -- Train acc: 0.9881 -- Val acc: 0.9601 -- Test acc: 0.9612 -- Gen gap 0.0269\n",
      "Epoch 32/100\n",
      "Avg loss: 0.0185 -- Train acc: 0.9879 -- Val acc: 0.9589 -- Test acc: 0.9603 -- Gen gap 0.0276\n",
      "Epoch 33/100\n",
      "Avg loss: 0.0176 -- Train acc: 0.9881 -- Val acc: 0.9603 -- Test acc: 0.9607 -- Gen gap 0.0274\n",
      "Epoch 34/100\n",
      "Avg loss: 0.0172 -- Train acc: 0.9881 -- Val acc: 0.9601 -- Test acc: 0.9605 -- Gen gap 0.0276\n",
      "Epoch 35/100\n",
      "Avg loss: 0.0167 -- Train acc: 0.9881 -- Val acc: 0.9596 -- Test acc: 0.9611 -- Gen gap 0.0270\n",
      "Epoch 36/100\n",
      "Avg loss: 0.0163 -- Train acc: 0.9883 -- Val acc: 0.9596 -- Test acc: 0.9611 -- Gen gap 0.0272\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.0158 -- Train acc: 0.9881 -- Val acc: 0.9605 -- Test acc: 0.9610 -- Gen gap 0.0271\n",
      "Epoch 38/100\n",
      "Avg loss: 0.0158 -- Train acc: 0.9883 -- Val acc: 0.9604 -- Test acc: 0.9612 -- Gen gap 0.0271\n",
      "Epoch 39/100\n",
      "Avg loss: 0.0154 -- Train acc: 0.9883 -- Val acc: 0.9606 -- Test acc: 0.9612 -- Gen gap 0.0271\n",
      "Epoch 40/100\n",
      "Avg loss: 0.0150 -- Train acc: 0.9883 -- Val acc: 0.9597 -- Test acc: 0.9610 -- Gen gap 0.0273\n",
      "Epoch 41/100\n",
      "Avg loss: 0.0145 -- Train acc: 0.9883 -- Val acc: 0.9595 -- Test acc: 0.9609 -- Gen gap 0.0274\n",
      "Epoch 42/100\n",
      "Avg loss: 0.0142 -- Train acc: 0.9883 -- Val acc: 0.9604 -- Test acc: 0.9611 -- Gen gap 0.0272\n",
      "Epoch 43/100\n",
      "Avg loss: 0.0140 -- Train acc: 0.9883 -- Val acc: 0.9600 -- Test acc: 0.9616 -- Gen gap 0.0267\n",
      "Epoch 44/100\n",
      "Avg loss: 0.0137 -- Train acc: 0.9883 -- Val acc: 0.9601 -- Test acc: 0.9611 -- Gen gap 0.0272\n",
      "Epoch 45/100\n",
      "Avg loss: 0.0138 -- Train acc: 0.9879 -- Val acc: 0.9589 -- Test acc: 0.9605 -- Gen gap 0.0274\n",
      "Epoch 46/100\n",
      "Avg loss: 0.0133 -- Train acc: 0.9883 -- Val acc: 0.9596 -- Test acc: 0.9608 -- Gen gap 0.0275\n",
      "Epoch 47/100\n",
      "Avg loss: 0.0127 -- Train acc: 0.9885 -- Val acc: 0.9601 -- Test acc: 0.9612 -- Gen gap 0.0273\n",
      "Epoch 48/100\n",
      "Avg loss: 0.0126 -- Train acc: 0.9883 -- Val acc: 0.9605 -- Test acc: 0.9609 -- Gen gap 0.0274\n",
      "Epoch 49/100\n",
      "Avg loss: 0.0123 -- Train acc: 0.9885 -- Val acc: 0.9604 -- Test acc: 0.9610 -- Gen gap 0.0275\n",
      "Epoch 50/100\n",
      "Avg loss: 0.0122 -- Train acc: 0.9885 -- Val acc: 0.9602 -- Test acc: 0.9609 -- Gen gap 0.0276\n",
      "Epoch 51/100\n",
      "Avg loss: 0.0120 -- Train acc: 0.9887 -- Val acc: 0.9601 -- Test acc: 0.9609 -- Gen gap 0.0278\n",
      "Epoch 52/100\n",
      "Avg loss: 0.0116 -- Train acc: 0.9887 -- Val acc: 0.9596 -- Test acc: 0.9613 -- Gen gap 0.0274\n",
      "Epoch 53/100\n",
      "Avg loss: 0.0116 -- Train acc: 0.9887 -- Val acc: 0.9600 -- Test acc: 0.9615 -- Gen gap 0.0272\n",
      "Epoch 54/100\n",
      "Avg loss: 0.0115 -- Train acc: 0.9887 -- Val acc: 0.9593 -- Test acc: 0.9608 -- Gen gap 0.0279\n",
      "Epoch 55/100\n",
      "Avg loss: 0.0111 -- Train acc: 0.9887 -- Val acc: 0.9596 -- Test acc: 0.9615 -- Gen gap 0.0272\n",
      "Epoch 56/100\n",
      "Avg loss: 0.0108 -- Train acc: 0.9887 -- Val acc: 0.9589 -- Test acc: 0.9623 -- Gen gap 0.0264\n",
      "Epoch 57/100\n",
      "Avg loss: 0.0106 -- Train acc: 0.9889 -- Val acc: 0.9600 -- Test acc: 0.9614 -- Gen gap 0.0275\n",
      "Epoch 58/100\n",
      "Avg loss: 0.0106 -- Train acc: 0.9889 -- Val acc: 0.9591 -- Test acc: 0.9617 -- Gen gap 0.0272\n",
      "Epoch 59/100\n",
      "Avg loss: 0.0104 -- Train acc: 0.9887 -- Val acc: 0.9606 -- Test acc: 0.9619 -- Gen gap 0.0268\n",
      "Epoch 60/100\n",
      "Avg loss: 0.0103 -- Train acc: 0.9889 -- Val acc: 0.9599 -- Test acc: 0.9612 -- Gen gap 0.0277\n",
      "Epoch 61/100\n",
      "Avg loss: 0.0104 -- Train acc: 0.9887 -- Val acc: 0.9599 -- Test acc: 0.9612 -- Gen gap 0.0275\n",
      "Epoch 62/100\n",
      "Avg loss: 0.0102 -- Train acc: 0.9889 -- Val acc: 0.9596 -- Test acc: 0.9614 -- Gen gap 0.0275\n",
      "Epoch 63/100\n",
      "Avg loss: 0.0098 -- Train acc: 0.9889 -- Val acc: 0.9597 -- Test acc: 0.9617 -- Gen gap 0.0272\n",
      "Epoch 64/100\n",
      "Avg loss: 0.0097 -- Train acc: 0.9889 -- Val acc: 0.9598 -- Test acc: 0.9616 -- Gen gap 0.0273\n",
      "Epoch 65/100\n",
      "Avg loss: 0.0096 -- Train acc: 0.9889 -- Val acc: 0.9604 -- Test acc: 0.9614 -- Gen gap 0.0275\n",
      "Epoch 66/100\n",
      "Avg loss: 0.0097 -- Train acc: 0.9889 -- Val acc: 0.9598 -- Test acc: 0.9611 -- Gen gap 0.0278\n",
      "Epoch 67/100\n",
      "Avg loss: 0.0097 -- Train acc: 0.9889 -- Val acc: 0.9604 -- Test acc: 0.9614 -- Gen gap 0.0275\n",
      "Epoch 68/100\n",
      "Avg loss: 0.0092 -- Train acc: 0.9889 -- Val acc: 0.9603 -- Test acc: 0.9617 -- Gen gap 0.0272\n",
      "Epoch 69/100\n",
      "Avg loss: 0.0089 -- Train acc: 0.9889 -- Val acc: 0.9603 -- Test acc: 0.9620 -- Gen gap 0.0269\n",
      "Epoch 70/100\n",
      "Avg loss: 0.0091 -- Train acc: 0.9889 -- Val acc: 0.9590 -- Test acc: 0.9616 -- Gen gap 0.0273\n",
      "Epoch 71/100\n",
      "Avg loss: 0.0091 -- Train acc: 0.9889 -- Val acc: 0.9599 -- Test acc: 0.9614 -- Gen gap 0.0275\n",
      "Epoch 72/100\n",
      "Avg loss: 0.0088 -- Train acc: 0.9889 -- Val acc: 0.9597 -- Test acc: 0.9614 -- Gen gap 0.0275\n",
      "Epoch 73/100\n",
      "Avg loss: 0.0085 -- Train acc: 0.9889 -- Val acc: 0.9604 -- Test acc: 0.9618 -- Gen gap 0.0271\n",
      "Epoch 74/100\n",
      "Avg loss: 0.0087 -- Train acc: 0.9889 -- Val acc: 0.9602 -- Test acc: 0.9621 -- Gen gap 0.0268\n",
      "Epoch 75/100\n",
      "Avg loss: 0.0084 -- Train acc: 0.9889 -- Val acc: 0.9601 -- Test acc: 0.9612 -- Gen gap 0.0277\n",
      "Epoch 76/100\n",
      "Avg loss: 0.0083 -- Train acc: 0.9889 -- Val acc: 0.9605 -- Test acc: 0.9618 -- Gen gap 0.0271\n",
      "Epoch 77/100\n",
      "Avg loss: 0.0081 -- Train acc: 0.9889 -- Val acc: 0.9604 -- Test acc: 0.9618 -- Gen gap 0.0271\n",
      "Epoch 78/100\n",
      "Avg loss: 0.0080 -- Train acc: 0.9889 -- Val acc: 0.9603 -- Test acc: 0.9623 -- Gen gap 0.0266\n",
      "Epoch 79/100\n",
      "Avg loss: 0.0080 -- Train acc: 0.9889 -- Val acc: 0.9599 -- Test acc: 0.9613 -- Gen gap 0.0276\n",
      "Epoch 80/100\n",
      "Avg loss: 0.0079 -- Train acc: 0.9889 -- Val acc: 0.9600 -- Test acc: 0.9617 -- Gen gap 0.0272\n",
      "Epoch 81/100\n",
      "Avg loss: 0.0079 -- Train acc: 0.9889 -- Val acc: 0.9603 -- Test acc: 0.9619 -- Gen gap 0.0270\n",
      "Epoch 82/100\n",
      "Avg loss: 0.0076 -- Train acc: 0.9889 -- Val acc: 0.9602 -- Test acc: 0.9623 -- Gen gap 0.0266\n",
      "Epoch 83/100\n",
      "Avg loss: 0.0076 -- Train acc: 0.9889 -- Val acc: 0.9603 -- Test acc: 0.9623 -- Gen gap 0.0266\n",
      "Epoch 84/100\n",
      "Avg loss: 0.0074 -- Train acc: 0.9889 -- Val acc: 0.9603 -- Test acc: 0.9620 -- Gen gap 0.0269\n",
      "Epoch 85/100\n",
      "Avg loss: 0.0074 -- Train acc: 0.9889 -- Val acc: 0.9600 -- Test acc: 0.9623 -- Gen gap 0.0266\n",
      "Epoch 86/100\n",
      "Avg loss: 0.0073 -- Train acc: 0.9889 -- Val acc: 0.9603 -- Test acc: 0.9622 -- Gen gap 0.0267\n",
      "Epoch 87/100\n",
      "Avg loss: 0.0072 -- Train acc: 0.9889 -- Val acc: 0.9603 -- Test acc: 0.9619 -- Gen gap 0.0270\n",
      "Epoch 88/100\n",
      "Avg loss: 0.0071 -- Train acc: 0.9889 -- Val acc: 0.9604 -- Test acc: 0.9624 -- Gen gap 0.0265\n",
      "Epoch 89/100\n",
      "Avg loss: 0.0071 -- Train acc: 0.9889 -- Val acc: 0.9601 -- Test acc: 0.9621 -- Gen gap 0.0268\n",
      "Epoch 90/100\n",
      "Avg loss: 0.0070 -- Train acc: 0.9889 -- Val acc: 0.9601 -- Test acc: 0.9624 -- Gen gap 0.0265\n",
      "Epoch 91/100\n",
      "Avg loss: 0.0069 -- Train acc: 0.9889 -- Val acc: 0.9601 -- Test acc: 0.9624 -- Gen gap 0.0265\n",
      "Epoch 92/100\n",
      "Avg loss: 0.0069 -- Train acc: 0.9889 -- Val acc: 0.9607 -- Test acc: 0.9618 -- Gen gap 0.0271\n",
      "Epoch 93/100\n",
      "Avg loss: 0.0068 -- Train acc: 0.9889 -- Val acc: 0.9602 -- Test acc: 0.9624 -- Gen gap 0.0265\n",
      "Epoch 94/100\n",
      "Avg loss: 0.0067 -- Train acc: 0.9889 -- Val acc: 0.9602 -- Test acc: 0.9622 -- Gen gap 0.0267\n",
      "Epoch 95/100\n",
      "Avg loss: 0.0067 -- Train acc: 0.9889 -- Val acc: 0.9605 -- Test acc: 0.9623 -- Gen gap 0.0266\n",
      "Epoch 96/100\n",
      "Avg loss: 0.0066 -- Train acc: 0.9889 -- Val acc: 0.9601 -- Test acc: 0.9623 -- Gen gap 0.0266\n",
      "Epoch 97/100\n",
      "Avg loss: 0.0066 -- Train acc: 0.9889 -- Val acc: 0.9601 -- Test acc: 0.9622 -- Gen gap 0.0267\n",
      "Epoch 98/100\n",
      "Avg loss: 0.0065 -- Train acc: 0.9889 -- Val acc: 0.9601 -- Test acc: 0.9617 -- Gen gap 0.0272\n",
      "Epoch 99/100\n",
      "Avg loss: 0.0066 -- Train acc: 0.9889 -- Val acc: 0.9604 -- Test acc: 0.9621 -- Gen gap 0.0268\n",
      "Epoch 100/100\n",
      "Avg loss: 0.0064 -- Train acc: 0.9889 -- Val acc: 0.9602 -- Test acc: 0.9622 -- Gen gap 0.0267\n",
      "Training done! Elapsed time: 0:00:34\n",
      "\n",
      "==============================\n",
      "a = 1.00, Na = 50000\n",
      "------------------------------\n",
      "Iter 1\n",
      "Epoch 1/100\n",
      "Avg loss: 0.0938 -- Train acc: 0.9768 -- Val acc: 0.9650 -- Test acc: 0.9642 -- Gen gap 0.0127\n",
      "Epoch 2/100\n",
      "Avg loss: 0.0780 -- Train acc: 0.9788 -- Val acc: 0.9656 -- Test acc: 0.9656 -- Gen gap 0.0132\n",
      "Epoch 3/100\n",
      "Avg loss: 0.0692 -- Train acc: 0.9812 -- Val acc: 0.9663 -- Test acc: 0.9661 -- Gen gap 0.0151\n",
      "Epoch 4/100\n",
      "Avg loss: 0.0640 -- Train acc: 0.9822 -- Val acc: 0.9682 -- Test acc: 0.9668 -- Gen gap 0.0154\n",
      "Epoch 5/100\n",
      "Avg loss: 0.0590 -- Train acc: 0.9844 -- Val acc: 0.9696 -- Test acc: 0.9678 -- Gen gap 0.0166\n",
      "Epoch 6/100\n",
      "Avg loss: 0.0553 -- Train acc: 0.9854 -- Val acc: 0.9694 -- Test acc: 0.9681 -- Gen gap 0.0174\n",
      "Epoch 7/100\n",
      "Avg loss: 0.0524 -- Train acc: 0.9857 -- Val acc: 0.9701 -- Test acc: 0.9687 -- Gen gap 0.0171\n",
      "Epoch 8/100\n",
      "Avg loss: 0.0496 -- Train acc: 0.9865 -- Val acc: 0.9691 -- Test acc: 0.9684 -- Gen gap 0.0181\n",
      "Epoch 9/100\n",
      "Avg loss: 0.0470 -- Train acc: 0.9873 -- Val acc: 0.9694 -- Test acc: 0.9685 -- Gen gap 0.0189\n",
      "Epoch 10/100\n",
      "Avg loss: 0.0447 -- Train acc: 0.9886 -- Val acc: 0.9711 -- Test acc: 0.9691 -- Gen gap 0.0194\n",
      "Epoch 11/100\n",
      "Avg loss: 0.0428 -- Train acc: 0.9890 -- Val acc: 0.9709 -- Test acc: 0.9696 -- Gen gap 0.0193\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.0407 -- Train acc: 0.9891 -- Val acc: 0.9709 -- Test acc: 0.9693 -- Gen gap 0.0198\n",
      "Epoch 13/100\n",
      "Avg loss: 0.0390 -- Train acc: 0.9900 -- Val acc: 0.9719 -- Test acc: 0.9694 -- Gen gap 0.0206\n",
      "Epoch 14/100\n",
      "Avg loss: 0.0375 -- Train acc: 0.9908 -- Val acc: 0.9718 -- Test acc: 0.9697 -- Gen gap 0.0210\n",
      "Epoch 15/100\n",
      "Avg loss: 0.0358 -- Train acc: 0.9915 -- Val acc: 0.9723 -- Test acc: 0.9705 -- Gen gap 0.0209\n",
      "Epoch 16/100\n",
      "Avg loss: 0.0345 -- Train acc: 0.9918 -- Val acc: 0.9725 -- Test acc: 0.9701 -- Gen gap 0.0217\n",
      "Epoch 17/100\n",
      "Avg loss: 0.0332 -- Train acc: 0.9925 -- Val acc: 0.9724 -- Test acc: 0.9702 -- Gen gap 0.0222\n",
      "Epoch 18/100\n",
      "Avg loss: 0.0319 -- Train acc: 0.9919 -- Val acc: 0.9711 -- Test acc: 0.9707 -- Gen gap 0.0212\n",
      "Epoch 19/100\n",
      "Avg loss: 0.0306 -- Train acc: 0.9930 -- Val acc: 0.9719 -- Test acc: 0.9708 -- Gen gap 0.0222\n",
      "Epoch 20/100\n",
      "Avg loss: 0.0295 -- Train acc: 0.9938 -- Val acc: 0.9722 -- Test acc: 0.9710 -- Gen gap 0.0228\n",
      "Epoch 21/100\n",
      "Avg loss: 0.0286 -- Train acc: 0.9935 -- Val acc: 0.9736 -- Test acc: 0.9706 -- Gen gap 0.0229\n",
      "Epoch 22/100\n",
      "Avg loss: 0.0276 -- Train acc: 0.9937 -- Val acc: 0.9728 -- Test acc: 0.9705 -- Gen gap 0.0232\n",
      "Epoch 23/100\n",
      "Avg loss: 0.0266 -- Train acc: 0.9948 -- Val acc: 0.9735 -- Test acc: 0.9706 -- Gen gap 0.0241\n",
      "Epoch 24/100\n",
      "Avg loss: 0.0254 -- Train acc: 0.9948 -- Val acc: 0.9728 -- Test acc: 0.9705 -- Gen gap 0.0243\n",
      "Epoch 25/100\n",
      "Avg loss: 0.0247 -- Train acc: 0.9950 -- Val acc: 0.9730 -- Test acc: 0.9722 -- Gen gap 0.0228\n",
      "Epoch 26/100\n",
      "Avg loss: 0.0236 -- Train acc: 0.9952 -- Val acc: 0.9735 -- Test acc: 0.9704 -- Gen gap 0.0247\n",
      "Epoch 27/100\n",
      "Avg loss: 0.0228 -- Train acc: 0.9957 -- Val acc: 0.9732 -- Test acc: 0.9707 -- Gen gap 0.0249\n",
      "Epoch 28/100\n",
      "Avg loss: 0.0222 -- Train acc: 0.9954 -- Val acc: 0.9731 -- Test acc: 0.9729 -- Gen gap 0.0225\n",
      "Epoch 29/100\n",
      "Avg loss: 0.0214 -- Train acc: 0.9958 -- Val acc: 0.9739 -- Test acc: 0.9716 -- Gen gap 0.0242\n",
      "Epoch 30/100\n",
      "Avg loss: 0.0205 -- Train acc: 0.9961 -- Val acc: 0.9735 -- Test acc: 0.9709 -- Gen gap 0.0251\n",
      "Epoch 31/100\n",
      "Avg loss: 0.0201 -- Train acc: 0.9964 -- Val acc: 0.9743 -- Test acc: 0.9722 -- Gen gap 0.0242\n",
      "Epoch 32/100\n",
      "Avg loss: 0.0193 -- Train acc: 0.9965 -- Val acc: 0.9736 -- Test acc: 0.9713 -- Gen gap 0.0252\n",
      "Epoch 33/100\n",
      "Avg loss: 0.0188 -- Train acc: 0.9968 -- Val acc: 0.9740 -- Test acc: 0.9717 -- Gen gap 0.0251\n",
      "Epoch 34/100\n",
      "Avg loss: 0.0180 -- Train acc: 0.9967 -- Val acc: 0.9743 -- Test acc: 0.9718 -- Gen gap 0.0249\n",
      "Epoch 35/100\n",
      "Avg loss: 0.0176 -- Train acc: 0.9970 -- Val acc: 0.9744 -- Test acc: 0.9726 -- Gen gap 0.0243\n",
      "Epoch 36/100\n",
      "Avg loss: 0.0170 -- Train acc: 0.9972 -- Val acc: 0.9736 -- Test acc: 0.9719 -- Gen gap 0.0252\n",
      "Epoch 37/100\n",
      "Avg loss: 0.0165 -- Train acc: 0.9966 -- Val acc: 0.9743 -- Test acc: 0.9726 -- Gen gap 0.0240\n",
      "Epoch 38/100\n",
      "Avg loss: 0.0160 -- Train acc: 0.9972 -- Val acc: 0.9737 -- Test acc: 0.9722 -- Gen gap 0.0250\n",
      "Epoch 39/100\n",
      "Avg loss: 0.0155 -- Train acc: 0.9973 -- Val acc: 0.9750 -- Test acc: 0.9728 -- Gen gap 0.0245\n",
      "Epoch 40/100\n",
      "Avg loss: 0.0150 -- Train acc: 0.9971 -- Val acc: 0.9740 -- Test acc: 0.9728 -- Gen gap 0.0243\n",
      "Epoch 41/100\n",
      "Avg loss: 0.0145 -- Train acc: 0.9974 -- Val acc: 0.9747 -- Test acc: 0.9733 -- Gen gap 0.0241\n",
      "Epoch 42/100\n",
      "Avg loss: 0.0141 -- Train acc: 0.9977 -- Val acc: 0.9746 -- Test acc: 0.9726 -- Gen gap 0.0251\n",
      "Epoch 43/100\n",
      "Avg loss: 0.0138 -- Train acc: 0.9976 -- Val acc: 0.9747 -- Test acc: 0.9724 -- Gen gap 0.0252\n",
      "Epoch 44/100\n",
      "Avg loss: 0.0133 -- Train acc: 0.9977 -- Val acc: 0.9749 -- Test acc: 0.9734 -- Gen gap 0.0243\n",
      "Epoch 45/100\n",
      "Avg loss: 0.0129 -- Train acc: 0.9977 -- Val acc: 0.9748 -- Test acc: 0.9730 -- Gen gap 0.0247\n",
      "Epoch 46/100\n",
      "Avg loss: 0.0125 -- Train acc: 0.9979 -- Val acc: 0.9749 -- Test acc: 0.9731 -- Gen gap 0.0248\n",
      "Epoch 47/100\n",
      "Avg loss: 0.0121 -- Train acc: 0.9979 -- Val acc: 0.9747 -- Test acc: 0.9735 -- Gen gap 0.0243\n",
      "Epoch 48/100\n",
      "Avg loss: 0.0118 -- Train acc: 0.9979 -- Val acc: 0.9748 -- Test acc: 0.9735 -- Gen gap 0.0244\n",
      "Epoch 49/100\n",
      "Avg loss: 0.0116 -- Train acc: 0.9981 -- Val acc: 0.9746 -- Test acc: 0.9729 -- Gen gap 0.0252\n",
      "Epoch 50/100\n",
      "Avg loss: 0.0113 -- Train acc: 0.9980 -- Val acc: 0.9743 -- Test acc: 0.9738 -- Gen gap 0.0242\n",
      "Epoch 51/100\n",
      "Avg loss: 0.0110 -- Train acc: 0.9982 -- Val acc: 0.9756 -- Test acc: 0.9731 -- Gen gap 0.0251\n",
      "Epoch 52/100\n",
      "Avg loss: 0.0106 -- Train acc: 0.9983 -- Val acc: 0.9748 -- Test acc: 0.9733 -- Gen gap 0.0250\n",
      "Epoch 53/100\n",
      "Avg loss: 0.0104 -- Train acc: 0.9984 -- Val acc: 0.9749 -- Test acc: 0.9736 -- Gen gap 0.0247\n",
      "Epoch 54/100\n",
      "Avg loss: 0.0101 -- Train acc: 0.9983 -- Val acc: 0.9739 -- Test acc: 0.9729 -- Gen gap 0.0254\n",
      "Epoch 55/100\n",
      "Avg loss: 0.0098 -- Train acc: 0.9984 -- Val acc: 0.9749 -- Test acc: 0.9733 -- Gen gap 0.0250\n",
      "Epoch 56/100\n",
      "Avg loss: 0.0096 -- Train acc: 0.9985 -- Val acc: 0.9748 -- Test acc: 0.9740 -- Gen gap 0.0244\n",
      "Epoch 57/100\n",
      "Avg loss: 0.0093 -- Train acc: 0.9984 -- Val acc: 0.9747 -- Test acc: 0.9740 -- Gen gap 0.0244\n",
      "Epoch 58/100\n",
      "Avg loss: 0.0090 -- Train acc: 0.9984 -- Val acc: 0.9748 -- Test acc: 0.9736 -- Gen gap 0.0248\n",
      "Epoch 59/100\n",
      "Avg loss: 0.0088 -- Train acc: 0.9985 -- Val acc: 0.9749 -- Test acc: 0.9733 -- Gen gap 0.0252\n",
      "Epoch 60/100\n",
      "Avg loss: 0.0086 -- Train acc: 0.9987 -- Val acc: 0.9746 -- Test acc: 0.9734 -- Gen gap 0.0253\n",
      "Epoch 61/100\n",
      "Avg loss: 0.0084 -- Train acc: 0.9986 -- Val acc: 0.9749 -- Test acc: 0.9728 -- Gen gap 0.0258\n",
      "Epoch 62/100\n",
      "Avg loss: 0.0082 -- Train acc: 0.9986 -- Val acc: 0.9745 -- Test acc: 0.9742 -- Gen gap 0.0244\n",
      "Epoch 63/100\n",
      "Avg loss: 0.0080 -- Train acc: 0.9986 -- Val acc: 0.9749 -- Test acc: 0.9742 -- Gen gap 0.0244\n",
      "Epoch 64/100\n",
      "Avg loss: 0.0078 -- Train acc: 0.9986 -- Val acc: 0.9750 -- Test acc: 0.9729 -- Gen gap 0.0257\n",
      "Epoch 65/100\n",
      "Avg loss: 0.0077 -- Train acc: 0.9987 -- Val acc: 0.9753 -- Test acc: 0.9731 -- Gen gap 0.0256\n",
      "Epoch 66/100\n",
      "Avg loss: 0.0074 -- Train acc: 0.9986 -- Val acc: 0.9749 -- Test acc: 0.9741 -- Gen gap 0.0245\n",
      "Epoch 67/100\n",
      "Avg loss: 0.0073 -- Train acc: 0.9987 -- Val acc: 0.9747 -- Test acc: 0.9735 -- Gen gap 0.0252\n",
      "Epoch 68/100\n",
      "Avg loss: 0.0071 -- Train acc: 0.9988 -- Val acc: 0.9754 -- Test acc: 0.9736 -- Gen gap 0.0251\n",
      "Epoch 69/100\n",
      "Avg loss: 0.0070 -- Train acc: 0.9988 -- Val acc: 0.9748 -- Test acc: 0.9732 -- Gen gap 0.0256\n",
      "Epoch 70/100\n",
      "Avg loss: 0.0068 -- Train acc: 0.9988 -- Val acc: 0.9746 -- Test acc: 0.9742 -- Gen gap 0.0245\n",
      "Epoch 71/100\n",
      "Avg loss: 0.0066 -- Train acc: 0.9988 -- Val acc: 0.9751 -- Test acc: 0.9737 -- Gen gap 0.0251\n",
      "Epoch 72/100\n",
      "Avg loss: 0.0065 -- Train acc: 0.9988 -- Val acc: 0.9751 -- Test acc: 0.9742 -- Gen gap 0.0245\n",
      "Epoch 73/100\n",
      "Avg loss: 0.0063 -- Train acc: 0.9988 -- Val acc: 0.9755 -- Test acc: 0.9737 -- Gen gap 0.0251\n",
      "Epoch 74/100\n",
      "Avg loss: 0.0062 -- Train acc: 0.9988 -- Val acc: 0.9752 -- Test acc: 0.9741 -- Gen gap 0.0247\n",
      "Epoch 75/100\n",
      "Avg loss: 0.0061 -- Train acc: 0.9989 -- Val acc: 0.9754 -- Test acc: 0.9740 -- Gen gap 0.0248\n",
      "Epoch 76/100\n",
      "Avg loss: 0.0059 -- Train acc: 0.9989 -- Val acc: 0.9746 -- Test acc: 0.9741 -- Gen gap 0.0248\n",
      "Epoch 77/100\n",
      "Avg loss: 0.0058 -- Train acc: 0.9989 -- Val acc: 0.9752 -- Test acc: 0.9733 -- Gen gap 0.0256\n",
      "Epoch 78/100\n",
      "Avg loss: 0.0057 -- Train acc: 0.9989 -- Val acc: 0.9753 -- Test acc: 0.9742 -- Gen gap 0.0247\n",
      "Epoch 79/100\n",
      "Avg loss: 0.0056 -- Train acc: 0.9988 -- Val acc: 0.9749 -- Test acc: 0.9743 -- Gen gap 0.0245\n",
      "Epoch 80/100\n",
      "Avg loss: 0.0055 -- Train acc: 0.9989 -- Val acc: 0.9749 -- Test acc: 0.9741 -- Gen gap 0.0248\n",
      "Epoch 81/100\n",
      "Avg loss: 0.0054 -- Train acc: 0.9989 -- Val acc: 0.9758 -- Test acc: 0.9741 -- Gen gap 0.0248\n",
      "Epoch 82/100\n",
      "Avg loss: 0.0053 -- Train acc: 0.9990 -- Val acc: 0.9758 -- Test acc: 0.9742 -- Gen gap 0.0247\n",
      "Epoch 83/100\n",
      "Avg loss: 0.0052 -- Train acc: 0.9989 -- Val acc: 0.9753 -- Test acc: 0.9737 -- Gen gap 0.0252\n",
      "Epoch 84/100\n",
      "Avg loss: 0.0051 -- Train acc: 0.9989 -- Val acc: 0.9752 -- Test acc: 0.9743 -- Gen gap 0.0246\n",
      "Epoch 85/100\n",
      "Avg loss: 0.0050 -- Train acc: 0.9990 -- Val acc: 0.9748 -- Test acc: 0.9743 -- Gen gap 0.0246\n",
      "Epoch 86/100\n",
      "Avg loss: 0.0049 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9741 -- Gen gap 0.0248\n",
      "Epoch 87/100\n",
      "Avg loss: 0.0048 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9745 -- Gen gap 0.0244\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.0047 -- Train acc: 0.9990 -- Val acc: 0.9750 -- Test acc: 0.9748 -- Gen gap 0.0241\n",
      "Epoch 89/100\n",
      "Avg loss: 0.0046 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9742 -- Gen gap 0.0248\n",
      "Epoch 90/100\n",
      "Avg loss: 0.0045 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9743 -- Gen gap 0.0247\n",
      "Epoch 91/100\n",
      "Avg loss: 0.0045 -- Train acc: 0.9990 -- Val acc: 0.9750 -- Test acc: 0.9742 -- Gen gap 0.0248\n",
      "Epoch 92/100\n",
      "Avg loss: 0.0044 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9740 -- Gen gap 0.0250\n",
      "Epoch 93/100\n",
      "Avg loss: 0.0043 -- Train acc: 0.9990 -- Val acc: 0.9749 -- Test acc: 0.9744 -- Gen gap 0.0246\n",
      "Epoch 94/100\n",
      "Avg loss: 0.0042 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9738 -- Gen gap 0.0252\n",
      "Epoch 95/100\n",
      "Avg loss: 0.0042 -- Train acc: 0.9990 -- Val acc: 0.9748 -- Test acc: 0.9743 -- Gen gap 0.0247\n",
      "Epoch 96/100\n",
      "Avg loss: 0.0041 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9740 -- Gen gap 0.0250\n",
      "Epoch 97/100\n",
      "Avg loss: 0.0040 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9744 -- Gen gap 0.0246\n",
      "Epoch 98/100\n",
      "Avg loss: 0.0040 -- Train acc: 0.9990 -- Val acc: 0.9750 -- Test acc: 0.9746 -- Gen gap 0.0244\n",
      "Epoch 99/100\n",
      "Avg loss: 0.0039 -- Train acc: 0.9990 -- Val acc: 0.9748 -- Test acc: 0.9740 -- Gen gap 0.0250\n",
      "Epoch 100/100\n",
      "Avg loss: 0.0039 -- Train acc: 0.9990 -- Val acc: 0.9748 -- Test acc: 0.9742 -- Gen gap 0.0248\n",
      "Training done! Elapsed time: 0:03:28\n",
      "\n",
      "Iter 2\n",
      "Epoch 1/100\n",
      "Avg loss: 0.0038 -- Train acc: 0.9990 -- Val acc: 0.9759 -- Test acc: 0.9745 -- Gen gap 0.0245\n",
      "Epoch 2/100\n",
      "Avg loss: 0.0037 -- Train acc: 0.9990 -- Val acc: 0.9750 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 3/100\n",
      "Avg loss: 0.0037 -- Train acc: 0.9990 -- Val acc: 0.9748 -- Test acc: 0.9741 -- Gen gap 0.0249\n",
      "Epoch 4/100\n",
      "Avg loss: 0.0036 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9742 -- Gen gap 0.0248\n",
      "Epoch 5/100\n",
      "Avg loss: 0.0036 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9745 -- Gen gap 0.0245\n",
      "Epoch 6/100\n",
      "Avg loss: 0.0035 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9747 -- Gen gap 0.0243\n",
      "Epoch 7/100\n",
      "Avg loss: 0.0035 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9743 -- Gen gap 0.0247\n",
      "Epoch 8/100\n",
      "Avg loss: 0.0034 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9745 -- Gen gap 0.0245\n",
      "Epoch 9/100\n",
      "Avg loss: 0.0034 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9743 -- Gen gap 0.0247\n",
      "Epoch 10/100\n",
      "Avg loss: 0.0033 -- Train acc: 0.9990 -- Val acc: 0.9756 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 11/100\n",
      "Avg loss: 0.0033 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9746 -- Gen gap 0.0244\n",
      "Epoch 12/100\n",
      "Avg loss: 0.0032 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9745 -- Gen gap 0.0245\n",
      "Epoch 13/100\n",
      "Avg loss: 0.0032 -- Train acc: 0.9990 -- Val acc: 0.9750 -- Test acc: 0.9744 -- Gen gap 0.0246\n",
      "Epoch 14/100\n",
      "Avg loss: 0.0031 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9745 -- Gen gap 0.0245\n",
      "Epoch 15/100\n",
      "Avg loss: 0.0031 -- Train acc: 0.9990 -- Val acc: 0.9756 -- Test acc: 0.9747 -- Gen gap 0.0243\n",
      "Epoch 16/100\n",
      "Avg loss: 0.0031 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 17/100\n",
      "Avg loss: 0.0030 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9746 -- Gen gap 0.0244\n",
      "Epoch 18/100\n",
      "Avg loss: 0.0030 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 19/100\n",
      "Avg loss: 0.0029 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9742 -- Gen gap 0.0248\n",
      "Epoch 20/100\n",
      "Avg loss: 0.0029 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9747 -- Gen gap 0.0243\n",
      "Epoch 21/100\n",
      "Avg loss: 0.0029 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 22/100\n",
      "Avg loss: 0.0028 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9745 -- Gen gap 0.0245\n",
      "Epoch 23/100\n",
      "Avg loss: 0.0028 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9747 -- Gen gap 0.0243\n",
      "Epoch 24/100\n",
      "Avg loss: 0.0028 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9745 -- Gen gap 0.0245\n",
      "Epoch 25/100\n",
      "Avg loss: 0.0027 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9744 -- Gen gap 0.0246\n",
      "Epoch 26/100\n",
      "Avg loss: 0.0027 -- Train acc: 0.9990 -- Val acc: 0.9749 -- Test acc: 0.9745 -- Gen gap 0.0245\n",
      "Epoch 27/100\n",
      "Avg loss: 0.0027 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9745 -- Gen gap 0.0245\n",
      "Epoch 28/100\n",
      "Avg loss: 0.0026 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9745 -- Gen gap 0.0245\n",
      "Epoch 29/100\n",
      "Avg loss: 0.0026 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9745 -- Gen gap 0.0245\n",
      "Epoch 30/100\n",
      "Avg loss: 0.0026 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 31/100\n",
      "Avg loss: 0.0025 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9746 -- Gen gap 0.0244\n",
      "Epoch 32/100\n",
      "Avg loss: 0.0025 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9744 -- Gen gap 0.0246\n",
      "Epoch 33/100\n",
      "Avg loss: 0.0025 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 34/100\n",
      "Avg loss: 0.0025 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 35/100\n",
      "Avg loss: 0.0024 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 36/100\n",
      "Avg loss: 0.0024 -- Train acc: 0.9990 -- Val acc: 0.9757 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 37/100\n",
      "Avg loss: 0.0024 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9747 -- Gen gap 0.0243\n",
      "Epoch 38/100\n",
      "Avg loss: 0.0024 -- Train acc: 0.9990 -- Val acc: 0.9749 -- Test acc: 0.9745 -- Gen gap 0.0245\n",
      "Epoch 39/100\n",
      "Avg loss: 0.0023 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 40/100\n",
      "Avg loss: 0.0023 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9745 -- Gen gap 0.0245\n",
      "Epoch 41/100\n",
      "Avg loss: 0.0023 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 42/100\n",
      "Avg loss: 0.0022 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 43/100\n",
      "Avg loss: 0.0022 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 44/100\n",
      "Avg loss: 0.0022 -- Train acc: 0.9990 -- Val acc: 0.9758 -- Test acc: 0.9745 -- Gen gap 0.0245\n",
      "Epoch 45/100\n",
      "Avg loss: 0.0022 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9747 -- Gen gap 0.0243\n",
      "Epoch 46/100\n",
      "Avg loss: 0.0022 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9747 -- Gen gap 0.0243\n",
      "Epoch 47/100\n",
      "Avg loss: 0.0021 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9747 -- Gen gap 0.0243\n",
      "Epoch 48/100\n",
      "Avg loss: 0.0021 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 49/100\n",
      "Avg loss: 0.0021 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9747 -- Gen gap 0.0243\n",
      "Epoch 50/100\n",
      "Avg loss: 0.0021 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 51/100\n",
      "Avg loss: 0.0020 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9747 -- Gen gap 0.0243\n",
      "Epoch 52/100\n",
      "Avg loss: 0.0020 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9746 -- Gen gap 0.0244\n",
      "Epoch 53/100\n",
      "Avg loss: 0.0020 -- Train acc: 0.9990 -- Val acc: 0.9750 -- Test acc: 0.9746 -- Gen gap 0.0244\n",
      "Epoch 54/100\n",
      "Avg loss: 0.0020 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 55/100\n",
      "Avg loss: 0.0020 -- Train acc: 0.9990 -- Val acc: 0.9756 -- Test acc: 0.9754 -- Gen gap 0.0236\n",
      "Epoch 56/100\n",
      "Avg loss: 0.0020 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 57/100\n",
      "Avg loss: 0.0019 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 58/100\n",
      "Avg loss: 0.0019 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 59/100\n",
      "Avg loss: 0.0019 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 60/100\n",
      "Avg loss: 0.0019 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 61/100\n",
      "Avg loss: 0.0019 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 62/100\n",
      "Avg loss: 0.0018 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 63/100\n",
      "Avg loss: 0.0018 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.0018 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 65/100\n",
      "Avg loss: 0.0018 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 66/100\n",
      "Avg loss: 0.0018 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9746 -- Gen gap 0.0244\n",
      "Epoch 67/100\n",
      "Avg loss: 0.0018 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 68/100\n",
      "Avg loss: 0.0017 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 69/100\n",
      "Avg loss: 0.0017 -- Train acc: 0.9990 -- Val acc: 0.9757 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 70/100\n",
      "Avg loss: 0.0017 -- Train acc: 0.9990 -- Val acc: 0.9756 -- Test acc: 0.9747 -- Gen gap 0.0243\n",
      "Epoch 71/100\n",
      "Avg loss: 0.0017 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 72/100\n",
      "Avg loss: 0.0017 -- Train acc: 0.9990 -- Val acc: 0.9759 -- Test acc: 0.9747 -- Gen gap 0.0243\n",
      "Epoch 73/100\n",
      "Avg loss: 0.0017 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 74/100\n",
      "Avg loss: 0.0017 -- Train acc: 0.9990 -- Val acc: 0.9750 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 75/100\n",
      "Avg loss: 0.0016 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 76/100\n",
      "Avg loss: 0.0016 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 77/100\n",
      "Avg loss: 0.0016 -- Train acc: 0.9990 -- Val acc: 0.9750 -- Test acc: 0.9747 -- Gen gap 0.0243\n",
      "Epoch 78/100\n",
      "Avg loss: 0.0016 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 79/100\n",
      "Avg loss: 0.0016 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 80/100\n",
      "Avg loss: 0.0016 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 81/100\n",
      "Avg loss: 0.0016 -- Train acc: 0.9990 -- Val acc: 0.9749 -- Test acc: 0.9747 -- Gen gap 0.0243\n",
      "Epoch 82/100\n",
      "Avg loss: 0.0016 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 83/100\n",
      "Avg loss: 0.0015 -- Train acc: 0.9990 -- Val acc: 0.9758 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 84/100\n",
      "Avg loss: 0.0015 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 85/100\n",
      "Avg loss: 0.0015 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 86/100\n",
      "Avg loss: 0.0015 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 87/100\n",
      "Avg loss: 0.0015 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 88/100\n",
      "Avg loss: 0.0015 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 89/100\n",
      "Avg loss: 0.0015 -- Train acc: 0.9990 -- Val acc: 0.9756 -- Test acc: 0.9754 -- Gen gap 0.0236\n",
      "Epoch 90/100\n",
      "Avg loss: 0.0015 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 91/100\n",
      "Avg loss: 0.0014 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 92/100\n",
      "Avg loss: 0.0014 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 93/100\n",
      "Avg loss: 0.0014 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 94/100\n",
      "Avg loss: 0.0014 -- Train acc: 0.9990 -- Val acc: 0.9757 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 95/100\n",
      "Avg loss: 0.0014 -- Train acc: 0.9990 -- Val acc: 0.9757 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 96/100\n",
      "Avg loss: 0.0014 -- Train acc: 0.9990 -- Val acc: 0.9757 -- Test acc: 0.9747 -- Gen gap 0.0243\n",
      "Epoch 97/100\n",
      "Avg loss: 0.0014 -- Train acc: 0.9990 -- Val acc: 0.9750 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 98/100\n",
      "Avg loss: 0.0014 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 99/100\n",
      "Avg loss: 0.0014 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 100/100\n",
      "Avg loss: 0.0014 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Training done! Elapsed time: 0:03:27\n",
      "\n",
      "Iter 3\n",
      "Epoch 1/100\n",
      "Avg loss: 0.0013 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 2/100\n",
      "Avg loss: 0.0013 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 3/100\n",
      "Avg loss: 0.0013 -- Train acc: 0.9990 -- Val acc: 0.9758 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 4/100\n",
      "Avg loss: 0.0013 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 5/100\n",
      "Avg loss: 0.0013 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 6/100\n",
      "Avg loss: 0.0013 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 7/100\n",
      "Avg loss: 0.0013 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 8/100\n",
      "Avg loss: 0.0013 -- Train acc: 0.9990 -- Val acc: 0.9758 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 9/100\n",
      "Avg loss: 0.0013 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9755 -- Gen gap 0.0235\n",
      "Epoch 10/100\n",
      "Avg loss: 0.0013 -- Train acc: 0.9990 -- Val acc: 0.9749 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 11/100\n",
      "Avg loss: 0.0013 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 12/100\n",
      "Avg loss: 0.0012 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 13/100\n",
      "Avg loss: 0.0012 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9755 -- Gen gap 0.0235\n",
      "Epoch 14/100\n",
      "Avg loss: 0.0012 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 15/100\n",
      "Avg loss: 0.0012 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 16/100\n",
      "Avg loss: 0.0012 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 17/100\n",
      "Avg loss: 0.0012 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 18/100\n",
      "Avg loss: 0.0012 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 19/100\n",
      "Avg loss: 0.0012 -- Train acc: 0.9990 -- Val acc: 0.9758 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 20/100\n",
      "Avg loss: 0.0012 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 21/100\n",
      "Avg loss: 0.0012 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 22/100\n",
      "Avg loss: 0.0012 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 23/100\n",
      "Avg loss: 0.0012 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 24/100\n",
      "Avg loss: 0.0012 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 25/100\n",
      "Avg loss: 0.0011 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 26/100\n",
      "Avg loss: 0.0011 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 27/100\n",
      "Avg loss: 0.0011 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 28/100\n",
      "Avg loss: 0.0011 -- Train acc: 0.9990 -- Val acc: 0.9756 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 29/100\n",
      "Avg loss: 0.0011 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 30/100\n",
      "Avg loss: 0.0011 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 31/100\n",
      "Avg loss: 0.0011 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 32/100\n",
      "Avg loss: 0.0011 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 33/100\n",
      "Avg loss: 0.0011 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 34/100\n",
      "Avg loss: 0.0011 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 35/100\n",
      "Avg loss: 0.0011 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 36/100\n",
      "Avg loss: 0.0011 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 37/100\n",
      "Avg loss: 0.0011 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 38/100\n",
      "Avg loss: 0.0011 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 39/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 41/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 42/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 43/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 44/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 45/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 46/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 47/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 48/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 49/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 50/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 51/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 52/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 53/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 54/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 55/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 56/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 57/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 58/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 59/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 60/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9756 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 61/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 62/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 63/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 64/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 65/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 66/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9754 -- Gen gap 0.0236\n",
      "Epoch 67/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 68/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 69/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 70/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 71/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 72/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9757 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 73/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9754 -- Gen gap 0.0236\n",
      "Epoch 74/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 75/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9754 -- Gen gap 0.0236\n",
      "Epoch 76/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9754 -- Gen gap 0.0236\n",
      "Epoch 77/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 78/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 79/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9754 -- Gen gap 0.0236\n",
      "Epoch 80/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 81/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9755 -- Gen gap 0.0235\n",
      "Epoch 82/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9756 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 83/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 84/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9754 -- Gen gap 0.0236\n",
      "Epoch 85/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 86/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9756 -- Test acc: 0.9754 -- Gen gap 0.0236\n",
      "Epoch 87/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 88/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9754 -- Gen gap 0.0236\n",
      "Epoch 89/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9754 -- Gen gap 0.0236\n",
      "Epoch 90/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 91/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 92/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 93/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 94/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 95/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 96/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9755 -- Gen gap 0.0235\n",
      "Epoch 97/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 98/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 99/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 100/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Training done! Elapsed time: 0:03:29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize best model so far\n",
    "mlp = MNIST(layers, learning_rate, \"glorot\")\n",
    "ratios = [0.01, 0.02, 0.05, 0.1, 1.0]\n",
    "nb_epochs = 100\n",
    "nb_trials = 3\n",
    "\n",
    "# Generalization gaps\n",
    "Ga = np.zeros(len(ratios), nb_trials)\n",
    "             \n",
    "for i, a in enumerate(ratios):\n",
    "    length = int(a * len(train_loader.dataset))\n",
    "    print(\"%s\\na = %.2f, Na = %d\\n%s\" % (\"=\"*30, a, length, \"-\"*30))\n",
    "    \n",
    "    for j in range(nb_trials):\n",
    "        print(\"Iter {:d}\".format(j + 1))\n",
    "        # Subsample from training set\n",
    "        Na, sub_train_loader = subsample_train(a, train_loader, batch_size)\n",
    "    \n",
    "        # Train\n",
    "        train_loss, train_acc, valid_acc, test_acc = \\\n",
    "            mlp.train(nb_epochs, sub_train_loader, valid_loader, test_loader, Na, gen_gap=True)\n",
    "            \n",
    "        # Get best validation epoch\n",
    "        best_valid = max(valid_acc)\n",
    "        max_valid_idx = valid_acc.index(best_valid)\n",
    "        \n",
    "        # Save generalization gap\n",
    "        Ga[i,j] = train_acc[max_valid_idx] - test_acc[max_valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f091c251850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "means, stds = Ga.mean(1), Ga.std(1)\n",
    "labels = [\"0.01\",\"0.02\",\"0.05\",\"0.1\",\"1.\"]\n",
    "plot_error_bars(labels, means, stds, \"Ratios\", \"Avg generalization gap\",\n",
    "    \"Average generalization gap for different training subsets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Discuss this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
