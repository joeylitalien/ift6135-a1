{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for this multilayer perceptron can be found in `mnist.py`. The module `utils.py` contains helper functions to load the dataset, display progress bar, plot graphs, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from mnist_v2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build an MLP and choose the values of $h^1$ and $h^2$ such that the total number of parameters (including biases) falls within the range of $I = [0.5M, 1.0M]$. This can be achieved by choosing $h^1 = h^2 = 512$. Since MNIST samples are $28 \\times 28 = 784$ pixels, the total number of parameters is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668672\n"
     ]
    }
   ],
   "source": [
    "num_params = (28*28)*512 + 512*512 + 512*10\n",
    "print(num_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is within range. We thus build the MLP with the parameters below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "layers = [784, 512, 512, 10]\n",
    "learning_rate = 1e-2\n",
    "batch_size = 64\n",
    "data_filename = \"../data/mnist/mnist.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load the tensors via Torch data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader = get_data_loaders(data_filename, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hardcoded parameters used for all three initilization schemes are:\n",
    "* **Activation functions:** Rectified linear unit (ReLU)\n",
    "* **Loss function:** Cross entropy\n",
    "* **Optimizer:** Stochastic gradient descent (SGD) with learning rate `learning_rate`\n",
    "\n",
    "For each initialization scheme, we compile the model and train by keeping track of the average loss. After training, we plot the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Avg loss: 2.3019 -- Train acc: 0.1135  \n",
      "Epoch 2/10\n",
      "Avg loss: 2.3012 -- Train acc: 0.1135  \n",
      "Epoch 3/10\n",
      "Avg loss: 2.3011 -- Train acc: 0.1135  \n",
      "Epoch 4/10\n",
      "Avg loss: 2.3011 -- Train acc: 0.1135  \n",
      "Epoch 5/10\n",
      "Avg loss: 2.3011 -- Train acc: 0.1135  \n",
      "Epoch 6/10\n",
      "Avg loss: 2.3011 -- Train acc: 0.1135  \n",
      "Epoch 7/10\n",
      "Avg loss: 2.3011 -- Train acc: 0.1135  \n",
      "Epoch 8/10\n",
      "Avg loss: 2.3011 -- Train acc: 0.1135  \n",
      "Epoch 9/10\n",
      "Avg loss: 2.3011 -- Train acc: 0.1135  \n",
      "Epoch 10/10\n",
      "Avg loss: 2.3011 -- Train acc: 0.1135  \n",
      "Training done! Elapsed time: 0:00:19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile and train model\n",
    "mlp_z = MNIST(layers, learning_rate, \"zeros\")\n",
    "zeros_losses = mlp_z.train(10, train_loader, [], [], len(train_loader.dataset))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzt3XmcXXV9//HXWwJUEpZAAmKWRooaKbKOFAVZXAIoymJbRIS4osjPJpaqLVVRwJ/LA3EXGsFiLVDQBEUpS0ojuEYnMZKQxKAsEogQSCCBICbw7h/nO3IzzHKTM3fuDLyfj8c8cu4533PO59yZ3Pc937PJNhEREZvrOe0uICIihrcESURE1JIgiYiIWhIkERFRS4IkIiJqSZBEREQtCZIYUJK2kPSIpIkD2bZVJF0k6cw+pp8r6ZJBLGlASfqNpFcORFtJN0g6qcllLZd0WBn+qKQLmyp4E/T3u4vBo1xH8uwm6ZGGl9sAjwNPlNfvsX3p4FfVHpJeA1xke1LDuHOB8bbf1q662qHudktaDrzV9g8HqJ53leUdNhDLi4E1ot0FRHvZHtU1LOlO4F22/6e39pJG2N4wGLU9W+U9juEmXVvRp9K1c4WkyyWtBd4q6eWSfi7pIUkrJH1J0pal/QhJljSpvP7PMv1aSWsl/UzSCza1bZl+lKRlkh6W9GVJP5H0th5q3kbSHyWNLq/PkrRe0sjy+lOSzmtY58clbQ98H5hYutsekbRzWeTWpd1aSYsk7dfLe3Vmw7yPlHVeVKbtIOnfy/u1XNLZkp5Tpr1L0s1l21cBH5H0HEkfk3SXpPslXSJpu4btu0zSg+V38AtJY3qpqbGL6dzye+xxW7raSjoa+BBwUtmOeWX6j7veb0kvlDRH0ipJD0j6VnkPe/sbuqQMX9jtPdog6SNl2kck3V5qu1XSG8v4lwJfAV5Z5nmg8XfXsJ73SvpteV++K2nXMr7r7+w9ZfpqSV/qqdbYPAmSaMZxwGXA9sAVwAZgGjAGOAg4EnhPH/O/BfgosCPwe+CcTW1bPtSvBD5Y1nsHcEBPC7C9DpgPHFJGHVqW9YqG1zd1m+dh4A3A722PKj/3l8nHAt8CdgCuBXr8ELL9/7vmBf4aeKDUTJn/MeCvgP2B1wNvb5j9FcASYCzwGeBdwFuBw8o8o4EvlrZvp+qGHA/sBLwP+GNPNfWg322x/QPgs8ClZXv272E5As4FngfsAexG9Xvrk+33NrxHhwKrgavL5GVUf0/bA58ELpO0i+2FwP8DflTmfVpoSpoCnA38LTAOuBfo3i37Oqr3fl+qL0Sv6a/eaE6CJJrxY9vft/2k7cds/9L2XNsbbN8OzKD6UOjNd2x32l5P9Z97n81oezSwwPb3yrTPU31Q9+Ym4NCyp7QH1TfaQyVtA+wH/KiJ7f7zsmxfb/sJqg/hvuqnrON7wHm2b5A0DngN8AHb62zfB3wBeHPDbL+3fYHtJ2w/BpxU5r/D9lrgTOAtZS9mPVWY7l7ad9puPNY1YNvSG9vLbN9o+08lcD9P338DG5G0C3AVcJrtW8oyr7S9ovydXQbcCXQ0uciTqI5vLbD9R+CfqX7f4xvafMr2w7bvBH7IZm57PF2CJJpxd+MLSZMlXSPpD5LWUH0T7LFrpfhDw/A6YFRvDfto+/zGOlydJbK8j+XcRPVt/mXAr4AbqT7oXgEssf1QH/P2V9PIftpfAtxi+3Pl9V8CWwP3la6oh4CvArs0zHP3xovg+cBdDa/vArai2mO5BPgf4EpJ90j6tKRmj3du6rb0SNLzJHWtf02pqa+/gcZ5twJmApfY/k7D+LdJ+nXDezS52WXS7f2yvYZqb2dcQ5tN+TuMTZAgiWZ0P7Xv34BFVN+ItwM+RtXV0UorqLpyAJAkNv6Q6O4nVN1Lb6QKlYVUXURH0q1bq0HtUxhLf/8k4NSG0XdTfXDtaHuH8rOd7b36WPe9VAHUZSLwJ2Bl2Qv4uO2XAAdTdT02dVruJujvvfgM1Rl+Ly1/A2+j+b+Br1LtTZ7VNULSbsAFwGnATrZ3AJY2LLO/ejZ6vyRtS9UdeE+TNUUNCZLYHNsCDwOPSnoJfR8fGSg/APaT9Iby7Xsa1bfzHpXuoF9THT+4qezBzKX6gO8tSO4DxpQPoU0m6Q3Ae4FjS/dKVy13l3WeJ2m7ciB9d0mH9LYs4HLgHyVNKvV8Erjc9pOSXiVpz9LNtYaqq+vJzam5D/cBk0pg92Rb4FHgYUkTgH9qZqGSTgdeDpzsja89GEUVFiurZno31R5JYz3jS1dlTy4H3ilpL0lbA5+iOqbS115rDJAESWyOM4CpwFqqvZMrWr3CclzhBOB84EGqvYtfUX0r7s1NwBZAZ8PrUfRyfMT2IqoulztL98rOPbXrwwnAzsCyhrOSvlKmvZWqG2kxVZfLt6kOVPfm61Tv64+A26ne62ll2vOBWVQhcitVN9dlm1hrf66g6kpbJekXPUw/i+pkh4epDpbPbHK5JwIvBFY0vEcfKsdJvgz8gmrv88VUwd9lNnAbVffgH7ov1PZ1VF2sV5X5JzLwe2nRi1yQGMOSpC2oujP+1vamHDiPiAGWPZIYNiQdqep6jK2pTjVdT/UNNiLaKEESw8nBVN08K4EjgONs99W1FRGDIF1bERFRS8v2SCRNKLdQWFxudzCthzbHSLpF0gJJnZIObpg2VdJt5Wdqw/gTJS0s812nXm4NERERg6NleyTlPje72p5fTl+cR3Va5OKGNqOAR21b0l7AlbYnS9qR6kybDqpTAudR3dpgLdUB1j1sPyDps8A62x/vq5YxY8Z40qRJA7+RERHPYPPmzXvAdq+n2Xdp2d1/ba+gOg0P22slLaG6gGxxQ5vG2zqM5KmLjo4AZtteBSBpNtWFZN+hukBppKQHge2A3/ZXy6RJk+js7OyvWURENJB0V/+tBulgu6q7u+7LxueFd007TtJS4BrgHWX0ODa+ZcRyYFy5x9JpVFcp30t1D6WLe1nnqaW7rHPlypUDtCUREdFdy4OkdF/NBKaX+99sxPZVtidT3ZW0r7vCUq5qPY0qlJ4P3AL8S09tbc+w3WG7Y+zYfvfMIiJiM7U0SMoH/0yq21HP6qut7ZuB3crB83uACQ2Tx5dx+5S2vyu3V7iSp24NHhERbdDKs7ZE1e20xPb5vbTZvetePqoesLM11e0vrgemSBqt6uFEU8q4e4A9JHXtYryW6hkOERHRJq181O5BwMnAQkkLyrgzqe6Bg+0LgTcBp0haT/XQnxPKnsYqSecAvyzznd1w4P0TwM1lnruo7joaERFt8qy4ILGjo8M5aysiYtNImme734eL5RYpERFRS4IkIiJqSZBEREQtCZKIiKglQRIREbUkSCIiopYESURE1JIgiYiIWhIkERFRS4IkIiJqSZBEREQtCZKIiKglQRIREbUkSCIiopYESURE1JIgiYiIWhIkERFRS4IkIiJqSZBEREQtCZKIiKglQRIREbUkSCIiopYESURE1JIgiYiIWloWJJImSJojabGkWyVN66HNMZJukbRAUqekgxumTZV0W/mZ2jB+K0kzJC2TtFTSm1q1DRER0b8RLVz2BuAM2/MlbQvMkzTb9uKGNjcCV9u2pL2AK4HJknYEzgI6AJd5r7a9GvhX4H7bL5L0HGDHFm5DRET0o2V7JLZX2J5fhtcCS4Bx3do8Ytvl5Uiq0AA4Aphte1UJj9nAkWXaO4BPlfmftP1Aq7YhIiL6NyjHSCRNAvYF5vYw7ThJS4FrqEICqsC5u6HZcmCcpB3K63MkzZf0bUm79LLOU0t3WefKlSsHaEsiIqK7lgeJpFHATGC67TXdp9u+yvZk4FjgnH4WNwIYD/zU9n7Az4Dzempoe4btDtsdY8eOrbUNERHRu5YGiaQtqULkUtuz+mpr+2ZgN0ljgHuACQ2Tx5dxDwLrgK5lfRvYb6DrjoiI5rXyrC0BFwNLbJ/fS5vdSzsk7QdsTRUW1wNTJI2WNBqYAlxfjqd8HzisLOLVwOKnLTgiIgZNK8/aOgg4GVgoaUEZdyYwEcD2hcCbgFMkrQceA04oYbFK0jnAL8t8Z9teVYY/DHxL0heAlcDbW7gNERHRDz110tQzV0dHhzs7O9tdRkTEsCJpnu2O/trlyvaIiKglQRIREbUkSCIiopYESURE1JIgiYiIWhIkERFRS4IkIiJqSZBEREQtCZKIiKglQRIREbUkSCIiopYESURE1JIgiYiIWhIkERFRS4IkIiJqSZBEREQtCZKIiKglQRIREbUkSCIiopYESURE1JIgiYiIWhIkERFRS4IkIiJqaVmQSJogaY6kxZJulTSthzbHSLpF0gJJnZIObpg2VdJt5WdqD/NeLWlRq+qPiIjmjGjhsjcAZ9ieL2lbYJ6k2bYXN7S5EbjatiXtBVwJTJa0I3AW0AG4zHu17dUAko4HHmlh7RER0aSW7ZHYXmF7fhleCywBxnVr84htl5cjqUID4Ahgtu1VJTxmA0cCSBoF/CNwbqtqj4iI5g3KMRJJk4B9gbk9TDtO0lLgGuAdZfQ44O6GZst5KoTOAT4HrGtRuRERsQlaHiRlD2ImMN32mu7TbV9lezJwLFVI9LWsfYC/sn1VE+s9tRx36Vy5cuVmVh8REf1paZBI2pIqRC61PauvtrZvBnaTNAa4B5jQMHl8GfdyoEPSncCPgRdJ+mEvy5thu8N2x9ixY2tvS0RE9KyVZ20JuBhYYvv8XtrsXtohaT9ga+BB4HpgiqTRkkYDU4DrbV9g+/m2JwEHA8tsH9aqbYiIiP618qytg4CTgYWSFpRxZwITAWxfCLwJOEXSeuAx4IRy8H2VpHOAX5b5zra9qoW1RkTEZtJTJ009c3V0dLizs7PdZUREDCuS5tnu6K9drmyPiIhaEiQREVFLgiQiImpJkERERC0JkoiIqCVBEhERtSRIIiKilgRJRETUkiCJiIhaEiQREVFLgiQiImpJkERERC0JkoiIqCVBEhERtSRIIiKilgRJRETU0m+QSPo7SduW4Y9ImlUeixsREdHUHslHba+VdDDwGqrnsF/Q2rIiImK4aCZInij/vh6YYfsaYKvWlRQREcNJM0Fyj6R/A04A/lvS1k3OFxERzwLNBMLfA9cDR9h+CNgR+GBLq4qIiGFjRBNtdgWusf24pMOAvYD/aGlVERExbDSzRzITeELS7sAMYAJwWUurioiIYaOZIHnS9gbgeODLtj9ItZcSERHRVJCsl3QicArwgzJuy/5mkjRB0hxJiyXdKmlaD22OkXSLpAWSOsspxl3Tpkq6rfxMLeO2kXSNpKVlmZ9ubjMjIqJVmjlG8nbgvcAnbd8h6QXAt5qYbwNwhu355YLGeZJm217c0OZG4GrblrQXcCUwWdKOwFlAB+Ay79XA48B5tudI2gq4UdJRtq9tdoMjImJg9btHUj74/wlYKGlPYLntzzQx3wrb88vwWmAJMK5bm0dsu7wcSRUaAEcAs22vsr0amA0caXud7Tll3j8B84HxTWxnRES0SDO3SDkMuA34KvA1YJmkQzZlJZImAfsCc3uYdpykpcA1wDvK6HHA3Q3NltMthCTtALyBaq+mp3WeWrrLOleuXLkp5UZExCZo5hjJ54Aptg+1fQjV3sLnm12BpFFUZ35Nt72m+3TbV9meDBwLnNPkMkcAlwNfsn17T21sz7DdYbtj7NixzZa7kXXrYP786t+IiOhZM0Gype3fdL2wvYwmDrYDSNqSKkQutT2rr7a2bwZ2kzQGuIfqNOMu48u4LjOA22x/oZk6Nse6dfDSl8Ihh1T/JkwiInrWTJB0SrpI0mHl5+tAZ38zSRLVDR6X2D6/lza7l3aUOwpvDTxIdSX9FEmjJY0GppRxSDoX2B6Y3kTtm23pUrjvPnj00erfpUtbubaIiOGrmbO2TgNOB/6hvP4R1fGS/hwEnEx1kH5BGXcmMBHA9oXAm4BTJK0HHgNOKAffV0k6B/hlme9s26skjQf+FVgKzC8Z9BXbFzVRzyaZPBl22aUKkV12qV5HRMTT6amTpjZhJukK2ye0oJ6W6OjocGdnvztRT7NuXbUnMnkybLNNCwqLiBjCJM2z3dFfu2b2SHry8s2cb1jZZhvYL4/wiojoU24HHxERtfS6R9LH43RFk2dtRUTEM19fXVuf62NazmGKiAigjyCxffhgFhIREcNTjpEMA7nCPiKGss09aysGSdcV9l3XsyxcmFORI2JoyR7JEDeUrrDPntFThsp7kTqGpqHwfgxmDf3ukfRy9tbDwF3lyYnRQkPlCvuhtGfU7gtFh8p7kTp6rqXdFxEPhfdjsGtoZo/ka8DPqW6U+HXgZ8C3gd9ImtK60gKqX/7ChXDzze39DzpU9oyGws00h8p7kTo2NhT+NmBovB+DXUMzQXIvsG+5Jfv+VM8VuR14LfDZVhYXla4r7Nt5bKRrz2jkyPbuGQ2F/6RD5b1IHRsbCn8bMDTej8Guod97bUlaZHvPnsZJWmB7n5ZWOAA2915bsbF0G2xcR7vfi9Tx9BqGwt9GVy1D4f2oW0Oz99pqJkiuAFYB/1VGnQCMobqz749tv2zzShw8CZJnlqHwnzSGpvxtDKyBvGnj24D38dTzP35C9Qz39UAuWoxBl5tpRm/yt9EezQTJUVTP/OjplimPDHA9ERExzDRzsP0NwDJJ35J0dHleekREBNBEkNh+O7A71Sm/JwK/kzTgTySMiIjhqam9C9vrJV0LGHgucCzwrlYWFhERw0O/eySSjpJ0CXAb1TPWLwKe1+K6IiJimGhmj+QU4ArgPbYfb3E9ERExzPQbJLZPbHwt6WDgRNunt6yqiIgYNpo6RiJpX+AtwN8BdwCzWllUREQMH309s/1FVGdpnQg8QNW9pTw5MSIiGvW1R7IU+BFwtO3fAkj6wKBUFRERw0ZfZ20dD6wA5kj6uqRXA2p2wZImSJojabGkWyVN66HNMZJukbRAUmc5/tI1baqk28rP1Ibx+0taKOm3kr4kqemaIiJi4PUaJLa/a/vNwGRgDtW9tnaWdEGTzyHZAJxhew/gQOB0SXt0a3MjsHe5g/A7qE4tRtKOwFnA3wAHAGdJGl3muQB4N/DC8nNkU1saEREt0cyV7Y/avsz2G4DxwK+ADzcx3wrb88vwWmAJMK5bm0f81O2HR1Jd8AhwBDDb9irbq4HZwJGSdgW2s/3zMt9/UF0cGRERbbJJz2y3vdr2DNuv3pT5JE2ieiDW3B6mHSdpKXAN1V4JVIFzd0Oz5WXcuDLcfXxP6zy1dJd1rly5clPKjYiITbBJQbI5JI0CZgLTba/pPt32VbYnU+1ZnDNQ6y2B12G7Y+zYsQO12IiI6KalQSJpS6oQudR2n9ee2L4Z2E3SGOAeYELD5PFl3D1luPv4iIhok5YFSTmb6mJgie3ze2mze9dZV5L2A7YGHgSuB6ZIGl0Osk8Brre9Algj6cAy3ynA91q1DRER0b9WPlvkIKrH8S6UtKCMOxOYCGD7QqqbQJ4iaT3wGHBCOYi+StI5wC/LfGfbXlWG3wdcQnUX4mvLT0REtEm/z2x/Jsgz2yMiNl2zz2xv+cH2iIh4ZkuQRERELQmSiIioJUESERG1JEgiIqKWBElERNSSIImIiFoSJBERUUuCJCIiakmQRERELQmSiIioJUESERG1JEgiIqKWBElERNSSIImIiFoSJBERUUuCJCIiakmQRERELQmSiIioJUESERG1JEgiIqKWBElERNSSIImIiFoSJBERUUvLgkTSBElzJC2WdKukaT20OUnSLZIWSvqppL0bpk2TtKjMO71h/D6Sfi5pgaROSQe0ahsiIqJ/rdwj2QCcYXsP4EDgdEl7dGtzB3Co7ZcC5wAzACTtCbwbOADYGzha0u5lns8Cn7C9D/Cx8joiItqkZUFie4Xt+WV4LbAEGNetzU9try4vfw6ML8MvAebaXmd7A3ATcHzXbMB2ZXh74N5WbUNERPRvxGCsRNIkYF9gbh/N3glcW4YXAZ+UtBPwGPA6oLNMmw5cL+k8qiB8RS/rPBU4FWDixIn1NiAiInrV8oPtkkYBM4Hpttf00uZwqiD5MIDtJcBngBuA64AFwBOl+WnAB2xPAD4AXNzTMm3PsN1hu2Ps2LEDuEUREdGopUEiaUuqELnU9qxe2uwFXAQcY/vBrvG2L7a9v+1DgNXAsjJpKtC1rG9THUeJiIg2aeVZW6LaW1hi+/xe2kykCoWTbS/rNm3nhjbHA5eVSfcCh5bhVwG3DXz1ERHRrFYeIzkIOBlYKGlBGXcmMBHA9oVUZ13tBHytyh022O4obWeWYyTrgdNtP1TGvxv4oqQRwB8px0EiIqI9ZLvdNbRcR0eHOzs7+28YERF/Jmlew5f7XuXK9oiIqCVBEhERtSRIIiKilgRJRETUkiCJiIhaEiQREVFLgiQiImpJkERERC0JkoiIqCVBEhERtSRIIiKilgRJRETUkiCJiIhaEiQREVFLgiQiImpJkERERC0JkoiIqCVBEhERtSRIIiKilgRJRETUkiCJiIhaEiQREVFLgiQiImppWZBImiBpjqTFkm6VNK2HNidJukXSQkk/lbR3w7RpkhaVead3m+/9kpaWaZ9t1TZERET/RrRw2RuAM2zPl7QtME/SbNuLG9rcARxqe7Wko4AZwN9I2hN4N3AA8CfgOkk/sP1bSYcDxwB7235c0s4t3IaIiOhHy/ZIbK+wPb8MrwWWAOO6tfmp7dXl5c+B8WX4JcBc2+tsbwBuAo4v004DPm378bKM+1u1DRER0b9BOUYiaRKwLzC3j2bvBK4tw4uAV0raSdI2wOuACWXai8q0uZJukvSy1lQdERHNaGXXFgCSRgEzgem21/TS5nCqIDkYwPYSSZ8BbgAeBRYATzTUvCNwIPAy4EpJu9l2t2WeCpwKMHHixIHerIiIKFq6RyJpS6oQudT2rF7a7AVcBBxj+8Gu8bYvtr2/7UOA1cCyMmk5MMuVXwBPAmO6L9f2DNsdtjvGjh07sBsWERF/1sqztgRcDCyxfX4vbSYCs4CTbS/rNm3nhjbHA5eVSd8FDi/TXgRsBTzQim2IiIj+tbJr6yDgZGChpAVl3JnARADbFwIfA3YCvlblDhtsd5S2MyXtBKwHTrf9UBn/DeAbkhZRndE1tXu3VkREDB49Gz6DOzo63NnZ2e4yIiKGFUnzGr7c9ypXtkdERC0JkoiIqCVBEhERtSRIIiKilgRJRETUkiCJiIhaEiQREVFLgiQiImpJkERERC0JkoiIqCVBEhERtSRIIiKilgRJRETUkiCJiIhanhW3kZe0ErhrM2cfw9B4cFbq2NhQqGMo1ACpo7vUMXA1/KXtfh8x+6wIkjokdTZzP/7U8eyrYyjUkDpSx1CoIV1bERFRS4IkIiJqSZD0b0a7CyhSx8aGQh1DoQZIHd2ljqcMSg05RhIREbVkjyQiImpJkERERC0Jkl5I+oak+yUtanMdEyTNkbRY0q2SprWhhr+Q9AtJvy41fGKwa+hWzxaSfiXpB22s4U5JCyUtkNTZxjp2kPQdSUslLZH08jbU8OLyPnT9rJE0vQ11fKD8fS6SdLmkvxjsGkod00oNtw7m+9DTZ5akHSXNlnRb+Xd0K9adIOndJcCR7S4C2ACcYXsP4EDgdEl7DHINjwOvsr03sA9wpKQDB7mGRtOAJW1cf5fDbe/T5msFvghcZ3sysDdteF9s/6a8D/sA+wPrgKsGswZJ44B/ADps7wlsAbx5MGsodewJvBs4gOr3cbSk3Qdp9Zfw9M+sfwZutP1C4MbyesAlSHph+2Zg1RCoY4Xt+WV4LdUHxbhBrsG2Hykvtyw/bTlLQ9J44PXARe1Y/1AiaXvgEOBiANt/sv1Qe6vi1cDvbG/unSTqGAE8V9IIYBvg3jbU8BJgru11tjcANwHHD8aKe/nMOgb4Zhn+JnBsK9adIBlGJE0C9gXmtmHdW0haANwPzLY96DUUXwA+BDzZpvV3MXCDpHmSTm1TDS8AVgL/Xrr6LpI0sk21dHkzcPlgr9T2PcB5wO+BFcDDtm8Y7DqARcArJe0kaRvgdcCENtTRZRfbK8rwH4BdWrGSBMkwIWkUMBOYbnvNYK/f9hOl62I8cEDZhR9Uko4G7rc9b7DX3YODbe8HHEXV3XhIG2oYAewHXGB7X+BRWtR10QxJWwFvBL7dhnWPpvr2/QLg+cBISW8d7DpsLwE+A9wAXAcsAJ4Y7Dp64upaj5b0JCRIhgFJW1KFyKW2Z7WzltJ1Mof2HD86CHijpDuB/wJeJek/21BH1zdgbN9PdTzggDaUsRxY3rB3+B2qYGmXo4D5tu9rw7pfA9xhe6Xt9cAs4BVtqAPbF9ve3/YhwGpgWTvqKO6TtCtA+ff+VqwkQTLESRJVH/gS2+e3qYaxknYow88FXgssHew6bP+L7fG2J1F1ofyv7UH/1ilppKRtu4aBKVRdGoPK9h+AuyW9uIx6NbB4sOtocCJt6NYqfg8cKGmb8n/m1bTphAxJO5d/J1IdH7msHXUUVwNTy/BU4HutWMmIViz0mUDS5cBhwBhJy4GzbF/chlIOAk4GFpZjFABn2v7vQaxhV+Cbkrag+vJxpe22nXo7BOwCXFV9XjECuMz2dW2q5f3ApaVb6Xbg7e0oogTqa4H3tGP9tudK+g4wn+pMx1/RvluUzJS0E7AeOH2wToDo6TML+DRwpaR3Uj1K4+9bsu7cIiUiIupI11ZERNSSIImIiFoSJBERUUuCJCIiakmQRERELQmSiAEg6Ylud8AdsCvMJU1q912oI/qS60giBsZj5RYyEc862SOJaKHy3JLPlmeX/KLrluJlL+N/Jd0i6cZyFTSSdpF0VXn2y68ldd3mYwtJXy/PuLih3GEgYkhIkEQMjOd269o6oWHaw7ZfCnyF6u7FAF8Gvml7L+BS4Etl/JeAm8qzX/YDbi3jXwh81fZfAw8Bb2rx9kQ0LVe2RwwASY/YHtXD+DupHgp2e7n55h9s7yTpAWBX2+vL+BW2x0haCYy3/XjDMiZR3br/heX1h4EtbZ/b+i2L6F/2SCJaz70Mb4rHG4afIMc3YwhJkES03gkN//6sDP+Upx4FexLwozItgt++AAAAg0lEQVR8I3Aa/PlhYtsPVpERmyvfaiIGxnMb7s4M1XPUu04BHi3pFqq9ihPLuPdTPdnwg1RPOey6a+80YEa5W+sTVKGygoghLMdIIlqoHCPpsP1Au2uJaJV0bUVERC3ZI4mIiFqyRxIREbUkSCIiopYESURE1JIgiYiIWhIkERFRy/8Bkiu27L3atNkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2be86fcf10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot avg loss / epoch\n",
    "%matplotlib inline\n",
    "plot_per_epoch(zeros_losses, \"Avg Loss\", \"Training with zeros initialization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Avg loss: 104.9912 -- Train acc: 0.9345 -- Val acc: 0.9200\n",
      "Epoch 2/10\n",
      "Avg loss: 12.6231 -- Train acc: 0.9454 -- Val acc: 0.9222\n",
      "Epoch 3/10\n",
      "Avg loss: 6.4455 -- Train acc: 0.9667 -- Val acc: 0.9337\n",
      "Epoch 4/10\n",
      "Avg loss: 3.7461 -- Train acc: 0.9730 -- Val acc: 0.9334\n",
      "Epoch 5/10\n",
      "Avg loss: 2.2310 -- Train acc: 0.9827 -- Val acc: 0.9367\n",
      "Epoch 6/10\n",
      "Avg loss: 1.3076 -- Train acc: 0.9861 -- Val acc: 0.9409\n",
      "Epoch 7/10\n",
      "Avg loss: 0.8106 -- Train acc: 0.9902 -- Val acc: 0.9406\n",
      "Epoch 8/10\n",
      "Avg loss: 0.4756 -- Train acc: 0.9913 -- Val acc: 0.9413\n",
      "Epoch 9/10\n",
      "Avg loss: 0.3016 -- Train acc: 0.9940 -- Val acc: 0.9402\n",
      "Epoch 10/10\n",
      "Avg loss: 0.1916 -- Train acc: 0.9960 -- Val acc: 0.9398\n",
      "Training done! Elapsed time: 0:00:19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile and train model\n",
    "mlp_n = MNIST(layers, learning_rate, \"normal\")\n",
    "normal_losses = mlp_n.train(10, train_loader, valid_loader, [], len(train_loader.dataset))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2be86e0090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot avg loss / epoch\n",
    "%matplotlib inline\n",
    "plot_per_epoch(normal_losses, \"Avg Loss\", \"Training with Normal(0,1) initialization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glorot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Avg loss: 0.8869 -- Train acc: 0.8873 -- Val acc: 0.8943\n",
      "Epoch 2/10\n",
      "Avg loss: 0.3695 -- Train acc: 0.9073 -- Val acc: 0.9101\n",
      "Epoch 3/10\n",
      "Avg loss: 0.3072 -- Train acc: 0.9178 -- Val acc: 0.9170\n",
      "Epoch 4/10\n",
      "Avg loss: 0.2725 -- Train acc: 0.9262 -- Val acc: 0.9271\n",
      "Epoch 5/10\n",
      "Avg loss: 0.2477 -- Train acc: 0.9334 -- Val acc: 0.9329\n",
      "Epoch 6/10\n",
      "Avg loss: 0.2280 -- Train acc: 0.9361 -- Val acc: 0.9351\n",
      "Epoch 7/10\n",
      "Avg loss: 0.2111 -- Train acc: 0.9427 -- Val acc: 0.9403\n",
      "Epoch 8/10\n",
      "Avg loss: 0.1971 -- Train acc: 0.9456 -- Val acc: 0.9433\n",
      "Epoch 9/10\n",
      "Avg loss: 0.1840 -- Train acc: 0.9489 -- Val acc: 0.9480\n",
      "Epoch 10/10\n",
      "Avg loss: 0.1727 -- Train acc: 0.9525 -- Val acc: 0.9497\n",
      "Training done! Elapsed time: 0:00:19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile and train model\n",
    "mlp_g = MNIST(layers, learning_rate, \"glorot\")\n",
    "glorot_losses = mlp_g.train(10, train_loader, valid_loader, [], len(train_loader.dataset))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0974872f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot avg loss / epoch\n",
    "%matplotlib inline\n",
    "plot_per_epoch(glorot_losses, \"Avg Loss\", \"Training with Glorot initialization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the network with zero weights sets them once and for all. Only the biases can then change. We observe this since the loss gets stuck at 2.3 with an awful accuracy of 0.11. The interesting comparison then is between glorot and normal initialization. We find that glorot initialization, after a single epoch, has already attained a small loss of 0.88, while normal initialization is still has a loss of 104 after a single epoch. Nonetheless, after 10 epochs, both have reached a similar loss around 0.15. This is probably because we are dealing with a relatively small network. With a very deep network, glorot would clearly be useful, since it would reduce optimization time by a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Avg loss: 0.8531 -- Train acc: 0.8788 -- Val acc: 0.8890\n",
      "Epoch 2/100\n",
      "Avg loss: 0.3724 -- Train acc: 0.9061 -- Val acc: 0.9101\n",
      "Epoch 3/100\n",
      "Avg loss: 0.3103 -- Train acc: 0.9157 -- Val acc: 0.9178\n",
      "Epoch 4/100\n",
      "Avg loss: 0.2767 -- Train acc: 0.9260 -- Val acc: 0.9269\n",
      "Epoch 5/100\n",
      "Avg loss: 0.2516 -- Train acc: 0.9319 -- Val acc: 0.9332\n",
      "Epoch 6/100\n",
      "Avg loss: 0.2314 -- Train acc: 0.9369 -- Val acc: 0.9366\n",
      "Epoch 7/100\n",
      "Avg loss: 0.2145 -- Train acc: 0.9410 -- Val acc: 0.9408\n",
      "Epoch 8/100\n",
      "Avg loss: 0.2001 -- Train acc: 0.9456 -- Val acc: 0.9445\n",
      "Epoch 9/100\n",
      "Avg loss: 0.1873 -- Train acc: 0.9491 -- Val acc: 0.9478\n",
      "Epoch 10/100\n",
      "Avg loss: 0.1758 -- Train acc: 0.9520 -- Val acc: 0.9488\n",
      "Epoch 11/100\n",
      "Avg loss: 0.1658 -- Train acc: 0.9526 -- Val acc: 0.9512\n",
      "Epoch 12/100\n",
      "Avg loss: 0.1565 -- Train acc: 0.9567 -- Val acc: 0.9532\n",
      "Epoch 13/100\n",
      "Avg loss: 0.1479 -- Train acc: 0.9601 -- Val acc: 0.9562\n",
      "Epoch 14/100\n",
      "Avg loss: 0.1405 -- Train acc: 0.9615 -- Val acc: 0.9573\n",
      "Epoch 15/100\n",
      "Avg loss: 0.1335 -- Train acc: 0.9629 -- Val acc: 0.9593\n",
      "Epoch 16/100\n",
      "Avg loss: 0.1268 -- Train acc: 0.9650 -- Val acc: 0.9599\n",
      "Epoch 17/100\n",
      "Avg loss: 0.1209 -- Train acc: 0.9666 -- Val acc: 0.9630\n",
      "Epoch 18/100\n",
      "Avg loss: 0.1155 -- Train acc: 0.9688 -- Val acc: 0.9638\n",
      "Epoch 19/100\n",
      "Avg loss: 0.1105 -- Train acc: 0.9696 -- Val acc: 0.9646\n",
      "Epoch 20/100\n",
      "Avg loss: 0.1057 -- Train acc: 0.9706 -- Val acc: 0.9632\n",
      "Epoch 21/100\n",
      "Avg loss: 0.1015 -- Train acc: 0.9725 -- Val acc: 0.9665\n",
      "Epoch 22/100\n",
      "Avg loss: 0.0967 -- Train acc: 0.9738 -- Val acc: 0.9656\n",
      "Epoch 23/100\n",
      "Avg loss: 0.0928 -- Train acc: 0.9752 -- Val acc: 0.9669\n",
      "Epoch 24/100\n",
      "Avg loss: 0.0892 -- Train acc: 0.9761 -- Val acc: 0.9665\n",
      "Epoch 25/100\n",
      "Avg loss: 0.0853 -- Train acc: 0.9766 -- Val acc: 0.9677\n",
      "Epoch 26/100\n",
      "Avg loss: 0.0824 -- Train acc: 0.9778 -- Val acc: 0.9675\n",
      "Epoch 27/100\n",
      "Avg loss: 0.0792 -- Train acc: 0.9791 -- Val acc: 0.9689\n",
      "Epoch 28/100\n",
      "Avg loss: 0.0762 -- Train acc: 0.9798 -- Val acc: 0.9693\n",
      "Epoch 29/100\n",
      "Avg loss: 0.0736 -- Train acc: 0.9802 -- Val acc: 0.9683\n",
      "Epoch 30/100\n",
      "Avg loss: 0.0710 -- Train acc: 0.9813 -- Val acc: 0.9696\n",
      "Epoch 31/100\n",
      "Avg loss: 0.0682 -- Train acc: 0.9823 -- Val acc: 0.9702\n",
      "Epoch 32/100\n",
      "Avg loss: 0.0657 -- Train acc: 0.9830 -- Val acc: 0.9704\n",
      "Epoch 33/100\n",
      "Avg loss: 0.0635 -- Train acc: 0.9828 -- Val acc: 0.9688\n",
      "Epoch 34/100\n",
      "Avg loss: 0.0616 -- Train acc: 0.9841 -- Val acc: 0.9693\n",
      "Epoch 35/100\n",
      "Avg loss: 0.0592 -- Train acc: 0.9847 -- Val acc: 0.9709\n",
      "Epoch 36/100\n",
      "Avg loss: 0.0576 -- Train acc: 0.9837 -- Val acc: 0.9702\n",
      "Epoch 37/100\n",
      "Avg loss: 0.0554 -- Train acc: 0.9855 -- Val acc: 0.9713\n",
      "Epoch 38/100\n",
      "Avg loss: 0.0535 -- Train acc: 0.9862 -- Val acc: 0.9714\n",
      "Epoch 39/100\n",
      "Avg loss: 0.0518 -- Train acc: 0.9870 -- Val acc: 0.9715\n",
      "Epoch 40/100\n",
      "Avg loss: 0.0501 -- Train acc: 0.9876 -- Val acc: 0.9724\n",
      "Epoch 41/100\n",
      "Avg loss: 0.0485 -- Train acc: 0.9879 -- Val acc: 0.9719\n",
      "Epoch 42/100\n",
      "Avg loss: 0.0469 -- Train acc: 0.9880 -- Val acc: 0.9716\n",
      "Epoch 43/100\n",
      "Avg loss: 0.0455 -- Train acc: 0.9893 -- Val acc: 0.9721\n",
      "Epoch 44/100\n",
      "Avg loss: 0.0440 -- Train acc: 0.9889 -- Val acc: 0.9728\n",
      "Epoch 45/100\n",
      "Avg loss: 0.0426 -- Train acc: 0.9894 -- Val acc: 0.9717\n",
      "Epoch 46/100\n",
      "Avg loss: 0.0413 -- Train acc: 0.9902 -- Val acc: 0.9729\n",
      "Epoch 47/100\n",
      "Avg loss: 0.0400 -- Train acc: 0.9907 -- Val acc: 0.9728\n",
      "Epoch 48/100\n",
      "Avg loss: 0.0387 -- Train acc: 0.9909 -- Val acc: 0.9728\n",
      "Epoch 49/100\n",
      "Avg loss: 0.0377 -- Train acc: 0.9912 -- Val acc: 0.9726\n",
      "Epoch 50/100\n",
      "Avg loss: 0.0364 -- Train acc: 0.9915 -- Val acc: 0.9739\n",
      "Epoch 51/100\n",
      "Avg loss: 0.0352 -- Train acc: 0.9921 -- Val acc: 0.9743\n",
      "Epoch 52/100\n",
      "Avg loss: 0.0341 -- Train acc: 0.9914 -- Val acc: 0.9726\n",
      "Epoch 53/100\n",
      "Avg loss: 0.0331 -- Train acc: 0.9924 -- Val acc: 0.9735\n",
      "Epoch 54/100\n",
      "Avg loss: 0.0323 -- Train acc: 0.9927 -- Val acc: 0.9742\n",
      "Epoch 55/100\n",
      "Avg loss: 0.0312 -- Train acc: 0.9931 -- Val acc: 0.9747\n",
      "Epoch 56/100\n",
      "Avg loss: 0.0304 -- Train acc: 0.9934 -- Val acc: 0.9740\n",
      "Epoch 57/100\n",
      "Avg loss: 0.0295 -- Train acc: 0.9934 -- Val acc: 0.9742\n",
      "Epoch 58/100\n",
      "Avg loss: 0.0287 -- Train acc: 0.9939 -- Val acc: 0.9748\n",
      "Epoch 59/100\n",
      "Avg loss: 0.0277 -- Train acc: 0.9940 -- Val acc: 0.9740\n",
      "Epoch 60/100\n",
      "Avg loss: 0.0270 -- Train acc: 0.9946 -- Val acc: 0.9740\n",
      "Epoch 61/100\n",
      "Avg loss: 0.0262 -- Train acc: 0.9944 -- Val acc: 0.9746\n",
      "Epoch 62/100\n",
      "Avg loss: 0.0253 -- Train acc: 0.9950 -- Val acc: 0.9734\n",
      "Epoch 63/100\n",
      "Avg loss: 0.0247 -- Train acc: 0.9949 -- Val acc: 0.9740\n",
      "Epoch 64/100\n",
      "Avg loss: 0.0240 -- Train acc: 0.9954 -- Val acc: 0.9744\n",
      "Epoch 65/100\n",
      "Avg loss: 0.0233 -- Train acc: 0.9958 -- Val acc: 0.9745\n",
      "Epoch 66/100\n",
      "Avg loss: 0.0226 -- Train acc: 0.9958 -- Val acc: 0.9739\n",
      "Epoch 67/100\n",
      "Avg loss: 0.0221 -- Train acc: 0.9959 -- Val acc: 0.9745\n",
      "Epoch 68/100\n",
      "Avg loss: 0.0214 -- Train acc: 0.9963 -- Val acc: 0.9748\n",
      "Epoch 69/100\n",
      "Avg loss: 0.0208 -- Train acc: 0.9961 -- Val acc: 0.9743\n",
      "Epoch 70/100\n",
      "Avg loss: 0.0203 -- Train acc: 0.9966 -- Val acc: 0.9749\n",
      "Epoch 71/100\n",
      "Avg loss: 0.0197 -- Train acc: 0.9963 -- Val acc: 0.9751\n",
      "Epoch 72/100\n",
      "Avg loss: 0.0192 -- Train acc: 0.9967 -- Val acc: 0.9751\n",
      "Epoch 73/100\n",
      "Avg loss: 0.0187 -- Train acc: 0.9965 -- Val acc: 0.9748\n",
      "Epoch 74/100\n",
      "Avg loss: 0.0182 -- Train acc: 0.9970 -- Val acc: 0.9750\n",
      "Epoch 75/100\n",
      "Avg loss: 0.0177 -- Train acc: 0.9966 -- Val acc: 0.9752\n",
      "Epoch 76/100\n",
      "Avg loss: 0.0172 -- Train acc: 0.9971 -- Val acc: 0.9751\n",
      "Epoch 77/100\n",
      "Avg loss: 0.0168 -- Train acc: 0.9969 -- Val acc: 0.9749\n",
      "Epoch 78/100\n",
      "Avg loss: 0.0164 -- Train acc: 0.9972 -- Val acc: 0.9747\n",
      "Epoch 79/100\n",
      "Avg loss: 0.0160 -- Train acc: 0.9973 -- Val acc: 0.9754\n",
      "Epoch 80/100\n",
      "Avg loss: 0.0155 -- Train acc: 0.9971 -- Val acc: 0.9753\n",
      "Epoch 81/100\n",
      "Avg loss: 0.0152 -- Train acc: 0.9973 -- Val acc: 0.9753\n",
      "Epoch 82/100\n",
      "Avg loss: 0.0148 -- Train acc: 0.9975 -- Val acc: 0.9746\n",
      "Epoch 83/100\n",
      "Avg loss: 0.0144 -- Train acc: 0.9976 -- Val acc: 0.9750\n",
      "Epoch 84/100\n",
      "Avg loss: 0.0141 -- Train acc: 0.9977 -- Val acc: 0.9755\n",
      "Epoch 85/100\n",
      "Avg loss: 0.0137 -- Train acc: 0.9977 -- Val acc: 0.9760\n",
      "Epoch 86/100\n",
      "Avg loss: 0.0134 -- Train acc: 0.9979 -- Val acc: 0.9750\n",
      "Epoch 87/100\n",
      "Avg loss: 0.0130 -- Train acc: 0.9979 -- Val acc: 0.9749\n",
      "Epoch 88/100\n",
      "Avg loss: 0.0128 -- Train acc: 0.9980 -- Val acc: 0.9749\n",
      "Epoch 89/100\n",
      "Avg loss: 0.0124 -- Train acc: 0.9978 -- Val acc: 0.9749\n",
      "Epoch 90/100\n",
      "Avg loss: 0.0121 -- Train acc: 0.9980 -- Val acc: 0.9749\n",
      "Epoch 91/100\n",
      "Avg loss: 0.0118 -- Train acc: 0.9981 -- Val acc: 0.9757\n",
      "Epoch 92/100\n",
      "Avg loss: 0.0116 -- Train acc: 0.9982 -- Val acc: 0.9752\n",
      "Epoch 93/100\n",
      "Avg loss: 0.0113 -- Train acc: 0.9982 -- Val acc: 0.9762\n",
      "Epoch 94/100\n",
      "Avg loss: 0.0110 -- Train acc: 0.9981 -- Val acc: 0.9749\n",
      "Epoch 95/100\n",
      "Avg loss: 0.0107 -- Train acc: 0.9982 -- Val acc: 0.9747\n",
      "Epoch 96/100\n",
      "Avg loss: 0.0105 -- Train acc: 0.9982 -- Val acc: 0.9751\n",
      "Epoch 97/100\n",
      "Avg loss: 0.0103 -- Train acc: 0.9983 -- Val acc: 0.9756\n",
      "Epoch 98/100\n",
      "Avg loss: 0.0101 -- Train acc: 0.9983 -- Val acc: 0.9754\n",
      "Epoch 99/100\n",
      "Avg loss: 0.0098 -- Train acc: 0.9984 -- Val acc: 0.9753\n",
      "Epoch 100/100\n",
      "Avg loss: 0.0096 -- Train acc: 0.9984 -- Val acc: 0.9750\n",
      "Training done! Elapsed time: 0:03:20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MNIST(layers, learning_rate, \"glorot\")\n",
    "_, train_acc, valid_acc, _ = mlp.train(100, train_loader, valid_loader, [], len(train_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f096006d650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and validation accuracy / epoch\n",
    "%matplotlib inline\n",
    "plots_per_epoch([train_acc, valid_acc], [\"Train\", \"Valid\"], \"Accuracy\", \"Accuracy per epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train by doubling the model capacity. This is done by doubling the number of neurons at the first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1332224\n"
     ]
    }
   ],
   "source": [
    "num_params = (28*28)*2*512 + 2*512*512 + 512*10\n",
    "print(num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Avg loss: 0.7889 -- Train acc: 0.8936 -- Val acc: 0.9014\n",
      "Epoch 2/100\n",
      "Avg loss: 0.3488 -- Train acc: 0.9129 -- Val acc: 0.9174\n",
      "Epoch 3/100\n",
      "Avg loss: 0.2900 -- Train acc: 0.9254 -- Val acc: 0.9257\n",
      "Epoch 4/100\n",
      "Avg loss: 0.2566 -- Train acc: 0.9316 -- Val acc: 0.9306\n",
      "Epoch 5/100\n",
      "Avg loss: 0.2322 -- Train acc: 0.9366 -- Val acc: 0.9371\n",
      "Epoch 6/100\n",
      "Avg loss: 0.2124 -- Train acc: 0.9432 -- Val acc: 0.9440\n",
      "Epoch 7/100\n",
      "Avg loss: 0.1957 -- Train acc: 0.9460 -- Val acc: 0.9459\n",
      "Epoch 8/100\n",
      "Avg loss: 0.1815 -- Train acc: 0.9511 -- Val acc: 0.9509\n",
      "Epoch 9/100\n",
      "Avg loss: 0.1688 -- Train acc: 0.9530 -- Val acc: 0.9514\n",
      "Epoch 10/100\n",
      "Avg loss: 0.1578 -- Train acc: 0.9568 -- Val acc: 0.9530\n",
      "Epoch 11/100\n",
      "Avg loss: 0.1478 -- Train acc: 0.9597 -- Val acc: 0.9552\n",
      "Epoch 12/100\n",
      "Avg loss: 0.1389 -- Train acc: 0.9619 -- Val acc: 0.9575\n",
      "Epoch 13/100\n",
      "Avg loss: 0.1310 -- Train acc: 0.9630 -- Val acc: 0.9572\n",
      "Epoch 14/100\n",
      "Avg loss: 0.1237 -- Train acc: 0.9659 -- Val acc: 0.9598\n",
      "Epoch 15/100\n",
      "Avg loss: 0.1170 -- Train acc: 0.9680 -- Val acc: 0.9614\n",
      "Epoch 16/100\n",
      "Avg loss: 0.1108 -- Train acc: 0.9702 -- Val acc: 0.9635\n",
      "Epoch 17/100\n",
      "Avg loss: 0.1049 -- Train acc: 0.9719 -- Val acc: 0.9642\n",
      "Epoch 18/100\n",
      "Avg loss: 0.0997 -- Train acc: 0.9735 -- Val acc: 0.9646\n",
      "Epoch 19/100\n",
      "Avg loss: 0.0949 -- Train acc: 0.9740 -- Val acc: 0.9658\n",
      "Epoch 20/100\n",
      "Avg loss: 0.0904 -- Train acc: 0.9761 -- Val acc: 0.9657\n",
      "Epoch 21/100\n",
      "Avg loss: 0.0862 -- Train acc: 0.9761 -- Val acc: 0.9666\n",
      "Epoch 22/100\n",
      "Avg loss: 0.0824 -- Train acc: 0.9783 -- Val acc: 0.9671\n",
      "Epoch 23/100\n",
      "Avg loss: 0.0790 -- Train acc: 0.9792 -- Val acc: 0.9675\n",
      "Epoch 24/100\n",
      "Avg loss: 0.0754 -- Train acc: 0.9790 -- Val acc: 0.9674\n",
      "Epoch 25/100\n",
      "Avg loss: 0.0722 -- Train acc: 0.9812 -- Val acc: 0.9679\n",
      "Epoch 26/100\n",
      "Avg loss: 0.0689 -- Train acc: 0.9818 -- Val acc: 0.9688\n",
      "Epoch 27/100\n",
      "Avg loss: 0.0664 -- Train acc: 0.9816 -- Val acc: 0.9686\n",
      "Epoch 28/100\n",
      "Avg loss: 0.0635 -- Train acc: 0.9835 -- Val acc: 0.9694\n",
      "Epoch 29/100\n",
      "Avg loss: 0.0608 -- Train acc: 0.9848 -- Val acc: 0.9700\n",
      "Epoch 30/100\n",
      "Avg loss: 0.0584 -- Train acc: 0.9852 -- Val acc: 0.9702\n",
      "Epoch 31/100\n",
      "Avg loss: 0.0560 -- Train acc: 0.9859 -- Val acc: 0.9698\n",
      "Epoch 32/100\n",
      "Avg loss: 0.0539 -- Train acc: 0.9866 -- Val acc: 0.9712\n",
      "Epoch 33/100\n",
      "Avg loss: 0.0517 -- Train acc: 0.9870 -- Val acc: 0.9706\n",
      "Epoch 34/100\n",
      "Avg loss: 0.0498 -- Train acc: 0.9877 -- Val acc: 0.9702\n",
      "Epoch 35/100\n",
      "Avg loss: 0.0477 -- Train acc: 0.9884 -- Val acc: 0.9718\n",
      "Epoch 36/100\n",
      "Avg loss: 0.0461 -- Train acc: 0.9886 -- Val acc: 0.9710\n",
      "Epoch 37/100\n",
      "Avg loss: 0.0445 -- Train acc: 0.9886 -- Val acc: 0.9711\n",
      "Epoch 38/100\n",
      "Avg loss: 0.0428 -- Train acc: 0.9898 -- Val acc: 0.9717\n",
      "Epoch 39/100\n",
      "Avg loss: 0.0411 -- Train acc: 0.9905 -- Val acc: 0.9718\n",
      "Epoch 40/100\n",
      "Avg loss: 0.0395 -- Train acc: 0.9906 -- Val acc: 0.9733\n",
      "Epoch 41/100\n",
      "Avg loss: 0.0383 -- Train acc: 0.9911 -- Val acc: 0.9728\n",
      "Epoch 42/100\n",
      "Avg loss: 0.0368 -- Train acc: 0.9916 -- Val acc: 0.9721\n",
      "Epoch 43/100\n",
      "Avg loss: 0.0357 -- Train acc: 0.9914 -- Val acc: 0.9721\n",
      "Epoch 44/100\n",
      "Avg loss: 0.0343 -- Train acc: 0.9926 -- Val acc: 0.9736\n",
      "Epoch 45/100\n",
      "Avg loss: 0.0330 -- Train acc: 0.9927 -- Val acc: 0.9739\n",
      "Epoch 46/100\n",
      "Avg loss: 0.0319 -- Train acc: 0.9933 -- Val acc: 0.9738\n",
      "Epoch 47/100\n",
      "Avg loss: 0.0308 -- Train acc: 0.9938 -- Val acc: 0.9738\n",
      "Epoch 48/100\n",
      "Avg loss: 0.0297 -- Train acc: 0.9936 -- Val acc: 0.9738\n",
      "Epoch 49/100\n",
      "Avg loss: 0.0287 -- Train acc: 0.9940 -- Val acc: 0.9740\n",
      "Epoch 50/100\n",
      "Avg loss: 0.0278 -- Train acc: 0.9943 -- Val acc: 0.9735\n",
      "Epoch 51/100\n",
      "Avg loss: 0.0268 -- Train acc: 0.9946 -- Val acc: 0.9740\n",
      "Epoch 52/100\n",
      "Avg loss: 0.0259 -- Train acc: 0.9948 -- Val acc: 0.9747\n",
      "Epoch 53/100\n",
      "Avg loss: 0.0250 -- Train acc: 0.9954 -- Val acc: 0.9747\n",
      "Epoch 54/100\n",
      "Avg loss: 0.0242 -- Train acc: 0.9950 -- Val acc: 0.9746\n",
      "Epoch 55/100\n",
      "Avg loss: 0.0234 -- Train acc: 0.9957 -- Val acc: 0.9739\n",
      "Epoch 56/100\n",
      "Avg loss: 0.0226 -- Train acc: 0.9957 -- Val acc: 0.9751\n",
      "Epoch 57/100\n",
      "Avg loss: 0.0220 -- Train acc: 0.9962 -- Val acc: 0.9747\n",
      "Epoch 58/100\n",
      "Avg loss: 0.0213 -- Train acc: 0.9963 -- Val acc: 0.9742\n",
      "Epoch 59/100\n",
      "Avg loss: 0.0205 -- Train acc: 0.9962 -- Val acc: 0.9739\n",
      "Epoch 60/100\n",
      "Avg loss: 0.0199 -- Train acc: 0.9964 -- Val acc: 0.9754\n",
      "Epoch 61/100\n",
      "Avg loss: 0.0193 -- Train acc: 0.9964 -- Val acc: 0.9741\n",
      "Epoch 62/100\n",
      "Avg loss: 0.0187 -- Train acc: 0.9965 -- Val acc: 0.9747\n",
      "Epoch 63/100\n",
      "Avg loss: 0.0181 -- Train acc: 0.9970 -- Val acc: 0.9746\n",
      "Epoch 64/100\n",
      "Avg loss: 0.0176 -- Train acc: 0.9965 -- Val acc: 0.9740\n",
      "Epoch 65/100\n",
      "Avg loss: 0.0171 -- Train acc: 0.9972 -- Val acc: 0.9750\n",
      "Epoch 66/100\n",
      "Avg loss: 0.0165 -- Train acc: 0.9973 -- Val acc: 0.9748\n",
      "Epoch 67/100\n",
      "Avg loss: 0.0160 -- Train acc: 0.9974 -- Val acc: 0.9748\n",
      "Epoch 68/100\n",
      "Avg loss: 0.0155 -- Train acc: 0.9975 -- Val acc: 0.9745\n",
      "Epoch 69/100\n",
      "Avg loss: 0.0151 -- Train acc: 0.9975 -- Val acc: 0.9755\n",
      "Epoch 70/100\n",
      "Avg loss: 0.0147 -- Train acc: 0.9976 -- Val acc: 0.9747\n",
      "Epoch 71/100\n",
      "Avg loss: 0.0143 -- Train acc: 0.9977 -- Val acc: 0.9751\n",
      "Epoch 72/100\n",
      "Avg loss: 0.0139 -- Train acc: 0.9978 -- Val acc: 0.9749\n",
      "Epoch 73/100\n",
      "Avg loss: 0.0135 -- Train acc: 0.9977 -- Val acc: 0.9753\n",
      "Epoch 74/100\n",
      "Avg loss: 0.0130 -- Train acc: 0.9979 -- Val acc: 0.9749\n",
      "Epoch 75/100\n",
      "Avg loss: 0.0127 -- Train acc: 0.9979 -- Val acc: 0.9751\n",
      "Epoch 76/100\n",
      "Avg loss: 0.0124 -- Train acc: 0.9979 -- Val acc: 0.9748\n",
      "Epoch 77/100\n",
      "Avg loss: 0.0120 -- Train acc: 0.9980 -- Val acc: 0.9749\n",
      "Epoch 78/100\n",
      "Avg loss: 0.0118 -- Train acc: 0.9982 -- Val acc: 0.9753\n",
      "Epoch 79/100\n",
      "Avg loss: 0.0114 -- Train acc: 0.9981 -- Val acc: 0.9753\n",
      "Epoch 80/100\n",
      "Avg loss: 0.0111 -- Train acc: 0.9981 -- Val acc: 0.9749\n",
      "Epoch 81/100\n",
      "Avg loss: 0.0109 -- Train acc: 0.9984 -- Val acc: 0.9755\n",
      "Epoch 82/100\n",
      "Avg loss: 0.0106 -- Train acc: 0.9985 -- Val acc: 0.9755\n",
      "Epoch 83/100\n",
      "Avg loss: 0.0102 -- Train acc: 0.9983 -- Val acc: 0.9750\n",
      "Epoch 84/100\n",
      "Avg loss: 0.0100 -- Train acc: 0.9983 -- Val acc: 0.9751\n",
      "Epoch 85/100\n",
      "Avg loss: 0.0098 -- Train acc: 0.9984 -- Val acc: 0.9755\n",
      "Epoch 86/100\n",
      "Avg loss: 0.0095 -- Train acc: 0.9984 -- Val acc: 0.9751\n",
      "Epoch 87/100\n",
      "Avg loss: 0.0093 -- Train acc: 0.9985 -- Val acc: 0.9753\n",
      "Epoch 88/100\n",
      "Avg loss: 0.0090 -- Train acc: 0.9986 -- Val acc: 0.9756\n",
      "Epoch 89/100\n",
      "Avg loss: 0.0089 -- Train acc: 0.9986 -- Val acc: 0.9757\n",
      "Epoch 90/100\n",
      "Avg loss: 0.0087 -- Train acc: 0.9986 -- Val acc: 0.9754\n",
      "Epoch 91/100\n",
      "Avg loss: 0.0085 -- Train acc: 0.9987 -- Val acc: 0.9757\n",
      "Epoch 92/100\n",
      "Avg loss: 0.0082 -- Train acc: 0.9987 -- Val acc: 0.9754\n",
      "Epoch 93/100\n",
      "Avg loss: 0.0080 -- Train acc: 0.9987 -- Val acc: 0.9756\n",
      "Epoch 94/100\n",
      "Avg loss: 0.0079 -- Train acc: 0.9987 -- Val acc: 0.9756\n",
      "Epoch 95/100\n",
      "Avg loss: 0.0077 -- Train acc: 0.9987 -- Val acc: 0.9756\n",
      "Epoch 96/100\n",
      "Avg loss: 0.0075 -- Train acc: 0.9987 -- Val acc: 0.9751\n",
      "Epoch 97/100\n",
      "Avg loss: 0.0074 -- Train acc: 0.9987 -- Val acc: 0.9751\n",
      "Epoch 98/100\n",
      "Avg loss: 0.0072 -- Train acc: 0.9987 -- Val acc: 0.9757\n",
      "Epoch 99/100\n",
      "Avg loss: 0.0071 -- Train acc: 0.9987 -- Val acc: 0.9759\n",
      "Epoch 100/100\n",
      "Avg loss: 0.0069 -- Train acc: 0.9987 -- Val acc: 0.9755\n",
      "Training done! Elapsed time: 0:04:15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "layers_2 = [784, 2*512, 512, 10]\n",
    "mlp_2 = MNIST(layers_2, learning_rate, \"glorot\")\n",
    "_, train_acc_2, valid_acc_2, _ = mlp_2.train(100, train_loader, valid_loader, [], len(train_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f091c1e5210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and validation accuracy / epoch\n",
    "%matplotlib inline\n",
    "plots_per_epoch([train_acc_2, valid_acc_2], [\"Train\", \"Valid\"], \"Accuracy\", \"Accuracy per epoch (doubled capacity)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find absolutely no difference between the initial model and the double capacity network. This seems to be evidence for the fact that neural networks don't overfit. We would have assumed that doubling the capacity of the network would have increased the variance, and hence increased the chance of overfitting. But both models achieve the same validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training Set Size, Generalization Gap, and Standard Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each ratio $a \\in \\{0.01, 0.02, 0.05, 0.1, 1.0\\}$, we reduce the training set to $N_a = aN$ samples, where $N= 50\\,000$. We then train using this new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "a = 0.01, Na = 500\n",
      "------------------------------\n",
      "Iter 1\n",
      "Epoch 1/100\n",
      "Avg loss: 2.3415 -- Train acc: 0.1523 -- Val acc: 0.1544 -- Test acc: 0.1625 -- Gen gap -0.0102\n",
      "Epoch 2/100\n",
      "Avg loss: 2.2622 -- Train acc: 0.2656 -- Val acc: 0.2472 -- Test acc: 0.2548 -- Gen gap 0.0108\n",
      "Epoch 3/100\n",
      "Avg loss: 2.1935 -- Train acc: 0.4004 -- Val acc: 0.3335 -- Test acc: 0.3392 -- Gen gap 0.0612\n",
      "Epoch 4/100\n",
      "Avg loss: 2.1291 -- Train acc: 0.4941 -- Val acc: 0.4179 -- Test acc: 0.4168 -- Gen gap 0.0773\n",
      "Epoch 5/100\n",
      "Avg loss: 2.0678 -- Train acc: 0.5664 -- Val acc: 0.4997 -- Test acc: 0.4950 -- Gen gap 0.0714\n",
      "Epoch 6/100\n",
      "Avg loss: 2.0076 -- Train acc: 0.6035 -- Val acc: 0.5491 -- Test acc: 0.5462 -- Gen gap 0.0573\n",
      "Epoch 7/100\n",
      "Avg loss: 1.9493 -- Train acc: 0.6465 -- Val acc: 0.5905 -- Test acc: 0.5818 -- Gen gap 0.0647\n",
      "Epoch 8/100\n",
      "Avg loss: 1.8891 -- Train acc: 0.6816 -- Val acc: 0.6197 -- Test acc: 0.6121 -- Gen gap 0.0696\n",
      "Epoch 9/100\n",
      "Avg loss: 1.8319 -- Train acc: 0.7109 -- Val acc: 0.6456 -- Test acc: 0.6358 -- Gen gap 0.0751\n",
      "Epoch 10/100\n",
      "Avg loss: 1.7704 -- Train acc: 0.7246 -- Val acc: 0.6607 -- Test acc: 0.6477 -- Gen gap 0.0769\n",
      "Epoch 11/100\n",
      "Avg loss: 1.7070 -- Train acc: 0.7383 -- Val acc: 0.6792 -- Test acc: 0.6676 -- Gen gap 0.0707\n",
      "Epoch 12/100\n",
      "Avg loss: 1.6484 -- Train acc: 0.7578 -- Val acc: 0.6930 -- Test acc: 0.6828 -- Gen gap 0.0750\n",
      "Epoch 13/100\n",
      "Avg loss: 1.5882 -- Train acc: 0.7598 -- Val acc: 0.7041 -- Test acc: 0.6938 -- Gen gap 0.0660\n",
      "Epoch 14/100\n",
      "Avg loss: 1.5267 -- Train acc: 0.7754 -- Val acc: 0.7165 -- Test acc: 0.7076 -- Gen gap 0.0678\n",
      "Epoch 15/100\n",
      "Avg loss: 1.4698 -- Train acc: 0.7891 -- Val acc: 0.7273 -- Test acc: 0.7162 -- Gen gap 0.0729\n",
      "Epoch 16/100\n",
      "Avg loss: 1.4101 -- Train acc: 0.7969 -- Val acc: 0.7388 -- Test acc: 0.7276 -- Gen gap 0.0693\n",
      "Epoch 17/100\n",
      "Avg loss: 1.3516 -- Train acc: 0.8008 -- Val acc: 0.7450 -- Test acc: 0.7333 -- Gen gap 0.0675\n",
      "Epoch 18/100\n",
      "Avg loss: 1.2963 -- Train acc: 0.8027 -- Val acc: 0.7519 -- Test acc: 0.7387 -- Gen gap 0.0641\n",
      "Epoch 19/100\n",
      "Avg loss: 1.2440 -- Train acc: 0.8047 -- Val acc: 0.7596 -- Test acc: 0.7473 -- Gen gap 0.0574\n",
      "Epoch 20/100\n",
      "Avg loss: 1.1960 -- Train acc: 0.8066 -- Val acc: 0.7669 -- Test acc: 0.7529 -- Gen gap 0.0538\n",
      "Epoch 21/100\n",
      "Avg loss: 1.1441 -- Train acc: 0.8242 -- Val acc: 0.7771 -- Test acc: 0.7626 -- Gen gap 0.0616\n",
      "Epoch 22/100\n",
      "Avg loss: 1.1015 -- Train acc: 0.8242 -- Val acc: 0.7789 -- Test acc: 0.7641 -- Gen gap 0.0601\n",
      "Epoch 23/100\n",
      "Avg loss: 1.0545 -- Train acc: 0.8320 -- Val acc: 0.7848 -- Test acc: 0.7713 -- Gen gap 0.0607\n",
      "Epoch 24/100\n",
      "Avg loss: 1.0139 -- Train acc: 0.8301 -- Val acc: 0.7847 -- Test acc: 0.7709 -- Gen gap 0.0592\n",
      "Epoch 25/100\n",
      "Avg loss: 0.9769 -- Train acc: 0.8359 -- Val acc: 0.7911 -- Test acc: 0.7791 -- Gen gap 0.0569\n",
      "Epoch 26/100\n",
      "Avg loss: 0.9386 -- Train acc: 0.8379 -- Val acc: 0.7940 -- Test acc: 0.7818 -- Gen gap 0.0560\n",
      "Epoch 27/100\n",
      "Avg loss: 0.9075 -- Train acc: 0.8477 -- Val acc: 0.7994 -- Test acc: 0.7860 -- Gen gap 0.0616\n",
      "Epoch 28/100\n",
      "Avg loss: 0.8745 -- Train acc: 0.8516 -- Val acc: 0.8033 -- Test acc: 0.7896 -- Gen gap 0.0620\n",
      "Epoch 29/100\n",
      "Avg loss: 0.8424 -- Train acc: 0.8555 -- Val acc: 0.8065 -- Test acc: 0.7925 -- Gen gap 0.0630\n",
      "Epoch 30/100\n",
      "Avg loss: 0.8147 -- Train acc: 0.8535 -- Val acc: 0.8057 -- Test acc: 0.7933 -- Gen gap 0.0602\n",
      "Epoch 31/100\n",
      "Avg loss: 0.7867 -- Train acc: 0.8613 -- Val acc: 0.8100 -- Test acc: 0.7977 -- Gen gap 0.0637\n",
      "Epoch 32/100\n",
      "Avg loss: 0.7656 -- Train acc: 0.8633 -- Val acc: 0.8112 -- Test acc: 0.7984 -- Gen gap 0.0649\n",
      "Epoch 33/100\n",
      "Avg loss: 0.7393 -- Train acc: 0.8672 -- Val acc: 0.8122 -- Test acc: 0.8006 -- Gen gap 0.0666\n",
      "Epoch 34/100\n",
      "Avg loss: 0.7223 -- Train acc: 0.8711 -- Val acc: 0.8134 -- Test acc: 0.8018 -- Gen gap 0.0693\n",
      "Epoch 35/100\n",
      "Avg loss: 0.6969 -- Train acc: 0.8730 -- Val acc: 0.8178 -- Test acc: 0.8053 -- Gen gap 0.0677\n",
      "Epoch 36/100\n",
      "Avg loss: 0.6769 -- Train acc: 0.8711 -- Val acc: 0.8180 -- Test acc: 0.8055 -- Gen gap 0.0656\n",
      "Epoch 37/100\n",
      "Avg loss: 0.6592 -- Train acc: 0.8750 -- Val acc: 0.8179 -- Test acc: 0.8070 -- Gen gap 0.0680\n",
      "Epoch 38/100\n",
      "Avg loss: 0.6423 -- Train acc: 0.8750 -- Val acc: 0.8199 -- Test acc: 0.8091 -- Gen gap 0.0659\n",
      "Epoch 39/100\n",
      "Avg loss: 0.6245 -- Train acc: 0.8789 -- Val acc: 0.8231 -- Test acc: 0.8118 -- Gen gap 0.0671\n",
      "Epoch 40/100\n",
      "Avg loss: 0.6103 -- Train acc: 0.8770 -- Val acc: 0.8265 -- Test acc: 0.8138 -- Gen gap 0.0632\n",
      "Epoch 41/100\n",
      "Avg loss: 0.5965 -- Train acc: 0.8789 -- Val acc: 0.8220 -- Test acc: 0.8110 -- Gen gap 0.0679\n",
      "Epoch 42/100\n",
      "Avg loss: 0.5841 -- Train acc: 0.8848 -- Val acc: 0.8277 -- Test acc: 0.8151 -- Gen gap 0.0697\n",
      "Epoch 43/100\n",
      "Avg loss: 0.5697 -- Train acc: 0.8828 -- Val acc: 0.8289 -- Test acc: 0.8175 -- Gen gap 0.0653\n",
      "Epoch 44/100\n",
      "Avg loss: 0.5539 -- Train acc: 0.8906 -- Val acc: 0.8298 -- Test acc: 0.8199 -- Gen gap 0.0708\n",
      "Epoch 45/100\n",
      "Avg loss: 0.5427 -- Train acc: 0.8887 -- Val acc: 0.8333 -- Test acc: 0.8224 -- Gen gap 0.0663\n",
      "Epoch 46/100\n",
      "Avg loss: 0.5297 -- Train acc: 0.8926 -- Val acc: 0.8318 -- Test acc: 0.8214 -- Gen gap 0.0712\n",
      "Epoch 47/100\n",
      "Avg loss: 0.5202 -- Train acc: 0.8926 -- Val acc: 0.8339 -- Test acc: 0.8235 -- Gen gap 0.0690\n",
      "Epoch 48/100\n",
      "Avg loss: 0.5117 -- Train acc: 0.8926 -- Val acc: 0.8340 -- Test acc: 0.8249 -- Gen gap 0.0676\n",
      "Epoch 49/100\n",
      "Avg loss: 0.4955 -- Train acc: 0.8906 -- Val acc: 0.8371 -- Test acc: 0.8273 -- Gen gap 0.0633\n",
      "Epoch 50/100\n",
      "Avg loss: 0.4906 -- Train acc: 0.8965 -- Val acc: 0.8346 -- Test acc: 0.8260 -- Gen gap 0.0704\n",
      "Epoch 51/100\n",
      "Avg loss: 0.4791 -- Train acc: 0.8926 -- Val acc: 0.8373 -- Test acc: 0.8290 -- Gen gap 0.0636\n",
      "Epoch 52/100\n",
      "Avg loss: 0.4718 -- Train acc: 0.8945 -- Val acc: 0.8386 -- Test acc: 0.8304 -- Gen gap 0.0641\n",
      "Epoch 53/100\n",
      "Avg loss: 0.4601 -- Train acc: 0.8945 -- Val acc: 0.8385 -- Test acc: 0.8308 -- Gen gap 0.0637\n",
      "Epoch 54/100\n",
      "Avg loss: 0.4537 -- Train acc: 0.8965 -- Val acc: 0.8413 -- Test acc: 0.8347 -- Gen gap 0.0618\n",
      "Epoch 55/100\n",
      "Avg loss: 0.4429 -- Train acc: 0.8965 -- Val acc: 0.8386 -- Test acc: 0.8319 -- Gen gap 0.0646\n",
      "Epoch 56/100\n",
      "Avg loss: 0.4354 -- Train acc: 0.8984 -- Val acc: 0.8392 -- Test acc: 0.8328 -- Gen gap 0.0656\n",
      "Epoch 57/100\n",
      "Avg loss: 0.4297 -- Train acc: 0.8945 -- Val acc: 0.8399 -- Test acc: 0.8330 -- Gen gap 0.0615\n",
      "Epoch 58/100\n",
      "Avg loss: 0.4196 -- Train acc: 0.9004 -- Val acc: 0.8438 -- Test acc: 0.8364 -- Gen gap 0.0640\n",
      "Epoch 59/100\n",
      "Avg loss: 0.4138 -- Train acc: 0.9023 -- Val acc: 0.8432 -- Test acc: 0.8368 -- Gen gap 0.0656\n",
      "Epoch 60/100\n",
      "Avg loss: 0.4078 -- Train acc: 0.9023 -- Val acc: 0.8439 -- Test acc: 0.8383 -- Gen gap 0.0641\n",
      "Epoch 61/100\n",
      "Avg loss: 0.3987 -- Train acc: 0.9023 -- Val acc: 0.8445 -- Test acc: 0.8389 -- Gen gap 0.0635\n",
      "Epoch 62/100\n",
      "Avg loss: 0.3955 -- Train acc: 0.9043 -- Val acc: 0.8448 -- Test acc: 0.8396 -- Gen gap 0.0647\n",
      "Epoch 63/100\n",
      "Avg loss: 0.3881 -- Train acc: 0.9043 -- Val acc: 0.8462 -- Test acc: 0.8401 -- Gen gap 0.0642\n",
      "Epoch 64/100\n",
      "Avg loss: 0.3829 -- Train acc: 0.9043 -- Val acc: 0.8491 -- Test acc: 0.8429 -- Gen gap 0.0614\n",
      "Epoch 65/100\n",
      "Avg loss: 0.3770 -- Train acc: 0.9043 -- Val acc: 0.8492 -- Test acc: 0.8435 -- Gen gap 0.0608\n",
      "Epoch 66/100\n",
      "Avg loss: 0.3682 -- Train acc: 0.9062 -- Val acc: 0.8497 -- Test acc: 0.8428 -- Gen gap 0.0635\n",
      "Epoch 67/100\n",
      "Avg loss: 0.3605 -- Train acc: 0.9062 -- Val acc: 0.8501 -- Test acc: 0.8437 -- Gen gap 0.0626\n",
      "Epoch 68/100\n",
      "Avg loss: 0.3586 -- Train acc: 0.9062 -- Val acc: 0.8519 -- Test acc: 0.8449 -- Gen gap 0.0613\n",
      "Epoch 69/100\n",
      "Avg loss: 0.3529 -- Train acc: 0.9082 -- Val acc: 0.8534 -- Test acc: 0.8458 -- Gen gap 0.0624\n",
      "Epoch 70/100\n",
      "Avg loss: 0.3465 -- Train acc: 0.9082 -- Val acc: 0.8532 -- Test acc: 0.8467 -- Gen gap 0.0615\n",
      "Epoch 71/100\n",
      "Avg loss: 0.3407 -- Train acc: 0.9082 -- Val acc: 0.8534 -- Test acc: 0.8469 -- Gen gap 0.0613\n",
      "Epoch 72/100\n",
      "Avg loss: 0.3373 -- Train acc: 0.9121 -- Val acc: 0.8549 -- Test acc: 0.8482 -- Gen gap 0.0639\n",
      "Epoch 73/100\n",
      "Avg loss: 0.3309 -- Train acc: 0.9121 -- Val acc: 0.8552 -- Test acc: 0.8474 -- Gen gap 0.0647\n",
      "Epoch 74/100\n",
      "Avg loss: 0.3275 -- Train acc: 0.9121 -- Val acc: 0.8537 -- Test acc: 0.8480 -- Gen gap 0.0641\n",
      "Epoch 75/100\n",
      "Avg loss: 0.3218 -- Train acc: 0.9121 -- Val acc: 0.8538 -- Test acc: 0.8490 -- Gen gap 0.0631\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.3196 -- Train acc: 0.9180 -- Val acc: 0.8564 -- Test acc: 0.8497 -- Gen gap 0.0682\n",
      "Epoch 77/100\n",
      "Avg loss: 0.3158 -- Train acc: 0.9180 -- Val acc: 0.8570 -- Test acc: 0.8510 -- Gen gap 0.0670\n",
      "Epoch 78/100\n",
      "Avg loss: 0.3083 -- Train acc: 0.9180 -- Val acc: 0.8566 -- Test acc: 0.8508 -- Gen gap 0.0672\n",
      "Epoch 79/100\n",
      "Avg loss: 0.3070 -- Train acc: 0.9180 -- Val acc: 0.8571 -- Test acc: 0.8513 -- Gen gap 0.0667\n",
      "Epoch 80/100\n",
      "Avg loss: 0.3038 -- Train acc: 0.9219 -- Val acc: 0.8585 -- Test acc: 0.8532 -- Gen gap 0.0687\n",
      "Epoch 81/100\n",
      "Avg loss: 0.2975 -- Train acc: 0.9219 -- Val acc: 0.8578 -- Test acc: 0.8525 -- Gen gap 0.0694\n",
      "Epoch 82/100\n",
      "Avg loss: 0.2948 -- Train acc: 0.9238 -- Val acc: 0.8567 -- Test acc: 0.8515 -- Gen gap 0.0723\n",
      "Epoch 83/100\n",
      "Avg loss: 0.2893 -- Train acc: 0.9238 -- Val acc: 0.8597 -- Test acc: 0.8543 -- Gen gap 0.0695\n",
      "Epoch 84/100\n",
      "Avg loss: 0.2859 -- Train acc: 0.9199 -- Val acc: 0.8595 -- Test acc: 0.8539 -- Gen gap 0.0660\n",
      "Epoch 85/100\n",
      "Avg loss: 0.2842 -- Train acc: 0.9219 -- Val acc: 0.8598 -- Test acc: 0.8534 -- Gen gap 0.0685\n",
      "Epoch 86/100\n",
      "Avg loss: 0.2770 -- Train acc: 0.9297 -- Val acc: 0.8594 -- Test acc: 0.8543 -- Gen gap 0.0754\n",
      "Epoch 87/100\n",
      "Avg loss: 0.2757 -- Train acc: 0.9277 -- Val acc: 0.8604 -- Test acc: 0.8553 -- Gen gap 0.0724\n",
      "Epoch 88/100\n",
      "Avg loss: 0.2694 -- Train acc: 0.9316 -- Val acc: 0.8608 -- Test acc: 0.8556 -- Gen gap 0.0760\n",
      "Epoch 89/100\n",
      "Avg loss: 0.2664 -- Train acc: 0.9277 -- Val acc: 0.8605 -- Test acc: 0.8548 -- Gen gap 0.0729\n",
      "Epoch 90/100\n",
      "Avg loss: 0.2625 -- Train acc: 0.9297 -- Val acc: 0.8603 -- Test acc: 0.8552 -- Gen gap 0.0745\n",
      "Epoch 91/100\n",
      "Avg loss: 0.2599 -- Train acc: 0.9316 -- Val acc: 0.8605 -- Test acc: 0.8554 -- Gen gap 0.0762\n",
      "Epoch 92/100\n",
      "Avg loss: 0.2571 -- Train acc: 0.9355 -- Val acc: 0.8609 -- Test acc: 0.8553 -- Gen gap 0.0803\n",
      "Epoch 93/100\n",
      "Avg loss: 0.2540 -- Train acc: 0.9316 -- Val acc: 0.8615 -- Test acc: 0.8556 -- Gen gap 0.0760\n",
      "Epoch 94/100\n",
      "Avg loss: 0.2527 -- Train acc: 0.9375 -- Val acc: 0.8612 -- Test acc: 0.8561 -- Gen gap 0.0814\n",
      "Epoch 95/100\n",
      "Avg loss: 0.2457 -- Train acc: 0.9375 -- Val acc: 0.8612 -- Test acc: 0.8555 -- Gen gap 0.0820\n",
      "Epoch 96/100\n",
      "Avg loss: 0.2451 -- Train acc: 0.9375 -- Val acc: 0.8620 -- Test acc: 0.8559 -- Gen gap 0.0816\n",
      "Epoch 97/100\n",
      "Avg loss: 0.2404 -- Train acc: 0.9375 -- Val acc: 0.8622 -- Test acc: 0.8570 -- Gen gap 0.0805\n",
      "Epoch 98/100\n",
      "Avg loss: 0.2396 -- Train acc: 0.9375 -- Val acc: 0.8631 -- Test acc: 0.8568 -- Gen gap 0.0807\n",
      "Epoch 99/100\n",
      "Avg loss: 0.2358 -- Train acc: 0.9395 -- Val acc: 0.8627 -- Test acc: 0.8570 -- Gen gap 0.0825\n",
      "Epoch 100/100\n",
      "Avg loss: 0.2336 -- Train acc: 0.9395 -- Val acc: 0.8627 -- Test acc: 0.8570 -- Gen gap 0.0825\n",
      "Training done! Elapsed time: 0:00:15\n",
      "\n",
      "Iter 2\n",
      "Epoch 1/100\n",
      "Avg loss: 0.4437 -- Train acc: 0.8535 -- Val acc: 0.8646 -- Test acc: 0.8615 -- Gen gap -0.0079\n",
      "Epoch 2/100\n",
      "Avg loss: 0.4312 -- Train acc: 0.8594 -- Val acc: 0.8660 -- Test acc: 0.8629 -- Gen gap -0.0035\n",
      "Epoch 3/100\n",
      "Avg loss: 0.4227 -- Train acc: 0.8711 -- Val acc: 0.8688 -- Test acc: 0.8640 -- Gen gap 0.0071\n",
      "Epoch 4/100\n",
      "Avg loss: 0.4095 -- Train acc: 0.8789 -- Val acc: 0.8695 -- Test acc: 0.8655 -- Gen gap 0.0134\n",
      "Epoch 5/100\n",
      "Avg loss: 0.3985 -- Train acc: 0.8789 -- Val acc: 0.8703 -- Test acc: 0.8673 -- Gen gap 0.0116\n",
      "Epoch 6/100\n",
      "Avg loss: 0.3920 -- Train acc: 0.8828 -- Val acc: 0.8705 -- Test acc: 0.8678 -- Gen gap 0.0150\n",
      "Epoch 7/100\n",
      "Avg loss: 0.3824 -- Train acc: 0.8867 -- Val acc: 0.8710 -- Test acc: 0.8686 -- Gen gap 0.0181\n",
      "Epoch 8/100\n",
      "Avg loss: 0.3717 -- Train acc: 0.8848 -- Val acc: 0.8742 -- Test acc: 0.8700 -- Gen gap 0.0147\n",
      "Epoch 9/100\n",
      "Avg loss: 0.3634 -- Train acc: 0.8887 -- Val acc: 0.8730 -- Test acc: 0.8687 -- Gen gap 0.0199\n",
      "Epoch 10/100\n",
      "Avg loss: 0.3556 -- Train acc: 0.8887 -- Val acc: 0.8747 -- Test acc: 0.8697 -- Gen gap 0.0189\n",
      "Epoch 11/100\n",
      "Avg loss: 0.3539 -- Train acc: 0.8926 -- Val acc: 0.8749 -- Test acc: 0.8699 -- Gen gap 0.0227\n",
      "Epoch 12/100\n",
      "Avg loss: 0.3441 -- Train acc: 0.8906 -- Val acc: 0.8767 -- Test acc: 0.8720 -- Gen gap 0.0186\n",
      "Epoch 13/100\n",
      "Avg loss: 0.3385 -- Train acc: 0.8984 -- Val acc: 0.8760 -- Test acc: 0.8703 -- Gen gap 0.0281\n",
      "Epoch 14/100\n",
      "Avg loss: 0.3339 -- Train acc: 0.9023 -- Val acc: 0.8768 -- Test acc: 0.8719 -- Gen gap 0.0304\n",
      "Epoch 15/100\n",
      "Avg loss: 0.3246 -- Train acc: 0.9043 -- Val acc: 0.8758 -- Test acc: 0.8709 -- Gen gap 0.0334\n",
      "Epoch 16/100\n",
      "Avg loss: 0.3183 -- Train acc: 0.9043 -- Val acc: 0.8778 -- Test acc: 0.8732 -- Gen gap 0.0311\n",
      "Epoch 17/100\n",
      "Avg loss: 0.3111 -- Train acc: 0.9043 -- Val acc: 0.8780 -- Test acc: 0.8742 -- Gen gap 0.0301\n",
      "Epoch 18/100\n",
      "Avg loss: 0.3092 -- Train acc: 0.9082 -- Val acc: 0.8775 -- Test acc: 0.8736 -- Gen gap 0.0346\n",
      "Epoch 19/100\n",
      "Avg loss: 0.3026 -- Train acc: 0.9141 -- Val acc: 0.8776 -- Test acc: 0.8711 -- Gen gap 0.0429\n",
      "Epoch 20/100\n",
      "Avg loss: 0.2991 -- Train acc: 0.9160 -- Val acc: 0.8773 -- Test acc: 0.8733 -- Gen gap 0.0427\n",
      "Epoch 21/100\n",
      "Avg loss: 0.2924 -- Train acc: 0.9160 -- Val acc: 0.8783 -- Test acc: 0.8755 -- Gen gap 0.0405\n",
      "Epoch 22/100\n",
      "Avg loss: 0.2883 -- Train acc: 0.9160 -- Val acc: 0.8772 -- Test acc: 0.8742 -- Gen gap 0.0418\n",
      "Epoch 23/100\n",
      "Avg loss: 0.2811 -- Train acc: 0.9199 -- Val acc: 0.8785 -- Test acc: 0.8741 -- Gen gap 0.0458\n",
      "Epoch 24/100\n",
      "Avg loss: 0.2784 -- Train acc: 0.9180 -- Val acc: 0.8789 -- Test acc: 0.8742 -- Gen gap 0.0438\n",
      "Epoch 25/100\n",
      "Avg loss: 0.2726 -- Train acc: 0.9238 -- Val acc: 0.8786 -- Test acc: 0.8754 -- Gen gap 0.0484\n",
      "Epoch 26/100\n",
      "Avg loss: 0.2676 -- Train acc: 0.9238 -- Val acc: 0.8786 -- Test acc: 0.8754 -- Gen gap 0.0484\n",
      "Epoch 27/100\n",
      "Avg loss: 0.2667 -- Train acc: 0.9258 -- Val acc: 0.8791 -- Test acc: 0.8743 -- Gen gap 0.0515\n",
      "Epoch 28/100\n",
      "Avg loss: 0.2596 -- Train acc: 0.9258 -- Val acc: 0.8792 -- Test acc: 0.8744 -- Gen gap 0.0514\n",
      "Epoch 29/100\n",
      "Avg loss: 0.2563 -- Train acc: 0.9297 -- Val acc: 0.8797 -- Test acc: 0.8754 -- Gen gap 0.0543\n",
      "Epoch 30/100\n",
      "Avg loss: 0.2528 -- Train acc: 0.9297 -- Val acc: 0.8789 -- Test acc: 0.8752 -- Gen gap 0.0545\n",
      "Epoch 31/100\n",
      "Avg loss: 0.2515 -- Train acc: 0.9297 -- Val acc: 0.8800 -- Test acc: 0.8762 -- Gen gap 0.0535\n",
      "Epoch 32/100\n",
      "Avg loss: 0.2444 -- Train acc: 0.9297 -- Val acc: 0.8799 -- Test acc: 0.8747 -- Gen gap 0.0550\n",
      "Epoch 33/100\n",
      "Avg loss: 0.2418 -- Train acc: 0.9316 -- Val acc: 0.8790 -- Test acc: 0.8747 -- Gen gap 0.0569\n",
      "Epoch 34/100\n",
      "Avg loss: 0.2368 -- Train acc: 0.9297 -- Val acc: 0.8800 -- Test acc: 0.8753 -- Gen gap 0.0544\n",
      "Epoch 35/100\n",
      "Avg loss: 0.2334 -- Train acc: 0.9336 -- Val acc: 0.8793 -- Test acc: 0.8750 -- Gen gap 0.0586\n",
      "Epoch 36/100\n",
      "Avg loss: 0.2320 -- Train acc: 0.9316 -- Val acc: 0.8798 -- Test acc: 0.8750 -- Gen gap 0.0566\n",
      "Epoch 37/100\n",
      "Avg loss: 0.2264 -- Train acc: 0.9316 -- Val acc: 0.8798 -- Test acc: 0.8754 -- Gen gap 0.0562\n",
      "Epoch 38/100\n",
      "Avg loss: 0.2242 -- Train acc: 0.9355 -- Val acc: 0.8811 -- Test acc: 0.8757 -- Gen gap 0.0599\n",
      "Epoch 39/100\n",
      "Avg loss: 0.2208 -- Train acc: 0.9395 -- Val acc: 0.8807 -- Test acc: 0.8755 -- Gen gap 0.0640\n",
      "Epoch 40/100\n",
      "Avg loss: 0.2175 -- Train acc: 0.9375 -- Val acc: 0.8799 -- Test acc: 0.8752 -- Gen gap 0.0623\n",
      "Epoch 41/100\n",
      "Avg loss: 0.2150 -- Train acc: 0.9395 -- Val acc: 0.8787 -- Test acc: 0.8746 -- Gen gap 0.0649\n",
      "Epoch 42/100\n",
      "Avg loss: 0.2130 -- Train acc: 0.9414 -- Val acc: 0.8799 -- Test acc: 0.8751 -- Gen gap 0.0663\n",
      "Epoch 43/100\n",
      "Avg loss: 0.2072 -- Train acc: 0.9414 -- Val acc: 0.8799 -- Test acc: 0.8752 -- Gen gap 0.0662\n",
      "Epoch 44/100\n",
      "Avg loss: 0.2055 -- Train acc: 0.9414 -- Val acc: 0.8792 -- Test acc: 0.8745 -- Gen gap 0.0669\n",
      "Epoch 45/100\n",
      "Avg loss: 0.2041 -- Train acc: 0.9414 -- Val acc: 0.8800 -- Test acc: 0.8751 -- Gen gap 0.0663\n",
      "Epoch 46/100\n",
      "Avg loss: 0.2008 -- Train acc: 0.9434 -- Val acc: 0.8798 -- Test acc: 0.8750 -- Gen gap 0.0684\n",
      "Epoch 47/100\n",
      "Avg loss: 0.1986 -- Train acc: 0.9414 -- Val acc: 0.8802 -- Test acc: 0.8759 -- Gen gap 0.0655\n",
      "Epoch 48/100\n",
      "Avg loss: 0.1941 -- Train acc: 0.9453 -- Val acc: 0.8796 -- Test acc: 0.8753 -- Gen gap 0.0700\n",
      "Epoch 49/100\n",
      "Avg loss: 0.1918 -- Train acc: 0.9492 -- Val acc: 0.8794 -- Test acc: 0.8748 -- Gen gap 0.0744\n",
      "Epoch 50/100\n",
      "Avg loss: 0.1895 -- Train acc: 0.9473 -- Val acc: 0.8802 -- Test acc: 0.8748 -- Gen gap 0.0725\n",
      "Epoch 51/100\n",
      "Avg loss: 0.1873 -- Train acc: 0.9473 -- Val acc: 0.8803 -- Test acc: 0.8749 -- Gen gap 0.0724\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.1843 -- Train acc: 0.9473 -- Val acc: 0.8810 -- Test acc: 0.8754 -- Gen gap 0.0719\n",
      "Epoch 53/100\n",
      "Avg loss: 0.1829 -- Train acc: 0.9512 -- Val acc: 0.8811 -- Test acc: 0.8755 -- Gen gap 0.0757\n",
      "Epoch 54/100\n",
      "Avg loss: 0.1801 -- Train acc: 0.9492 -- Val acc: 0.8797 -- Test acc: 0.8747 -- Gen gap 0.0745\n",
      "Epoch 55/100\n",
      "Avg loss: 0.1767 -- Train acc: 0.9551 -- Val acc: 0.8793 -- Test acc: 0.8747 -- Gen gap 0.0804\n",
      "Epoch 56/100\n",
      "Avg loss: 0.1758 -- Train acc: 0.9531 -- Val acc: 0.8792 -- Test acc: 0.8738 -- Gen gap 0.0793\n",
      "Epoch 57/100\n",
      "Avg loss: 0.1721 -- Train acc: 0.9570 -- Val acc: 0.8808 -- Test acc: 0.8756 -- Gen gap 0.0814\n",
      "Epoch 58/100\n",
      "Avg loss: 0.1704 -- Train acc: 0.9590 -- Val acc: 0.8796 -- Test acc: 0.8754 -- Gen gap 0.0836\n",
      "Epoch 59/100\n",
      "Avg loss: 0.1674 -- Train acc: 0.9590 -- Val acc: 0.8801 -- Test acc: 0.8760 -- Gen gap 0.0830\n",
      "Epoch 60/100\n",
      "Avg loss: 0.1657 -- Train acc: 0.9609 -- Val acc: 0.8814 -- Test acc: 0.8755 -- Gen gap 0.0854\n",
      "Epoch 61/100\n",
      "Avg loss: 0.1644 -- Train acc: 0.9609 -- Val acc: 0.8805 -- Test acc: 0.8752 -- Gen gap 0.0857\n",
      "Epoch 62/100\n",
      "Avg loss: 0.1614 -- Train acc: 0.9609 -- Val acc: 0.8809 -- Test acc: 0.8755 -- Gen gap 0.0854\n",
      "Epoch 63/100\n",
      "Avg loss: 0.1597 -- Train acc: 0.9629 -- Val acc: 0.8808 -- Test acc: 0.8756 -- Gen gap 0.0873\n",
      "Epoch 64/100\n",
      "Avg loss: 0.1610 -- Train acc: 0.9609 -- Val acc: 0.8794 -- Test acc: 0.8753 -- Gen gap 0.0856\n",
      "Epoch 65/100\n",
      "Avg loss: 0.1557 -- Train acc: 0.9629 -- Val acc: 0.8799 -- Test acc: 0.8757 -- Gen gap 0.0872\n",
      "Epoch 66/100\n",
      "Avg loss: 0.1535 -- Train acc: 0.9609 -- Val acc: 0.8800 -- Test acc: 0.8757 -- Gen gap 0.0852\n",
      "Epoch 67/100\n",
      "Avg loss: 0.1505 -- Train acc: 0.9609 -- Val acc: 0.8790 -- Test acc: 0.8754 -- Gen gap 0.0855\n",
      "Epoch 68/100\n",
      "Avg loss: 0.1515 -- Train acc: 0.9648 -- Val acc: 0.8809 -- Test acc: 0.8764 -- Gen gap 0.0885\n",
      "Epoch 69/100\n",
      "Avg loss: 0.1471 -- Train acc: 0.9648 -- Val acc: 0.8808 -- Test acc: 0.8766 -- Gen gap 0.0883\n",
      "Epoch 70/100\n",
      "Avg loss: 0.1481 -- Train acc: 0.9668 -- Val acc: 0.8806 -- Test acc: 0.8753 -- Gen gap 0.0915\n",
      "Epoch 71/100\n",
      "Avg loss: 0.1442 -- Train acc: 0.9648 -- Val acc: 0.8797 -- Test acc: 0.8755 -- Gen gap 0.0893\n",
      "Epoch 72/100\n",
      "Avg loss: 0.1437 -- Train acc: 0.9668 -- Val acc: 0.8784 -- Test acc: 0.8754 -- Gen gap 0.0914\n",
      "Epoch 73/100\n",
      "Avg loss: 0.1414 -- Train acc: 0.9668 -- Val acc: 0.8799 -- Test acc: 0.8755 -- Gen gap 0.0913\n",
      "Epoch 74/100\n",
      "Avg loss: 0.1397 -- Train acc: 0.9668 -- Val acc: 0.8799 -- Test acc: 0.8757 -- Gen gap 0.0911\n",
      "Epoch 75/100\n",
      "Avg loss: 0.1377 -- Train acc: 0.9668 -- Val acc: 0.8793 -- Test acc: 0.8751 -- Gen gap 0.0917\n",
      "Epoch 76/100\n",
      "Avg loss: 0.1360 -- Train acc: 0.9668 -- Val acc: 0.8791 -- Test acc: 0.8753 -- Gen gap 0.0915\n",
      "Epoch 77/100\n",
      "Avg loss: 0.1347 -- Train acc: 0.9668 -- Val acc: 0.8793 -- Test acc: 0.8755 -- Gen gap 0.0913\n",
      "Epoch 78/100\n",
      "Avg loss: 0.1323 -- Train acc: 0.9668 -- Val acc: 0.8795 -- Test acc: 0.8754 -- Gen gap 0.0914\n",
      "Epoch 79/100\n",
      "Avg loss: 0.1315 -- Train acc: 0.9668 -- Val acc: 0.8792 -- Test acc: 0.8749 -- Gen gap 0.0919\n",
      "Epoch 80/100\n",
      "Avg loss: 0.1298 -- Train acc: 0.9668 -- Val acc: 0.8798 -- Test acc: 0.8750 -- Gen gap 0.0918\n",
      "Epoch 81/100\n",
      "Avg loss: 0.1286 -- Train acc: 0.9668 -- Val acc: 0.8790 -- Test acc: 0.8743 -- Gen gap 0.0925\n",
      "Epoch 82/100\n",
      "Avg loss: 0.1267 -- Train acc: 0.9668 -- Val acc: 0.8793 -- Test acc: 0.8748 -- Gen gap 0.0920\n",
      "Epoch 83/100\n",
      "Avg loss: 0.1244 -- Train acc: 0.9668 -- Val acc: 0.8805 -- Test acc: 0.8746 -- Gen gap 0.0922\n",
      "Epoch 84/100\n",
      "Avg loss: 0.1244 -- Train acc: 0.9688 -- Val acc: 0.8798 -- Test acc: 0.8746 -- Gen gap 0.0941\n",
      "Epoch 85/100\n",
      "Avg loss: 0.1217 -- Train acc: 0.9688 -- Val acc: 0.8797 -- Test acc: 0.8743 -- Gen gap 0.0944\n",
      "Epoch 86/100\n",
      "Avg loss: 0.1209 -- Train acc: 0.9688 -- Val acc: 0.8804 -- Test acc: 0.8739 -- Gen gap 0.0948\n",
      "Epoch 87/100\n",
      "Avg loss: 0.1196 -- Train acc: 0.9688 -- Val acc: 0.8805 -- Test acc: 0.8741 -- Gen gap 0.0946\n",
      "Epoch 88/100\n",
      "Avg loss: 0.1176 -- Train acc: 0.9688 -- Val acc: 0.8810 -- Test acc: 0.8746 -- Gen gap 0.0941\n",
      "Epoch 89/100\n",
      "Avg loss: 0.1181 -- Train acc: 0.9688 -- Val acc: 0.8799 -- Test acc: 0.8740 -- Gen gap 0.0947\n",
      "Epoch 90/100\n",
      "Avg loss: 0.1157 -- Train acc: 0.9688 -- Val acc: 0.8797 -- Test acc: 0.8743 -- Gen gap 0.0944\n",
      "Epoch 91/100\n",
      "Avg loss: 0.1137 -- Train acc: 0.9688 -- Val acc: 0.8801 -- Test acc: 0.8738 -- Gen gap 0.0949\n",
      "Epoch 92/100\n",
      "Avg loss: 0.1119 -- Train acc: 0.9688 -- Val acc: 0.8807 -- Test acc: 0.8739 -- Gen gap 0.0948\n",
      "Epoch 93/100\n",
      "Avg loss: 0.1128 -- Train acc: 0.9688 -- Val acc: 0.8800 -- Test acc: 0.8741 -- Gen gap 0.0946\n",
      "Epoch 94/100\n",
      "Avg loss: 0.1103 -- Train acc: 0.9688 -- Val acc: 0.8802 -- Test acc: 0.8746 -- Gen gap 0.0941\n",
      "Epoch 95/100\n",
      "Avg loss: 0.1096 -- Train acc: 0.9688 -- Val acc: 0.8804 -- Test acc: 0.8739 -- Gen gap 0.0948\n",
      "Epoch 96/100\n",
      "Avg loss: 0.1091 -- Train acc: 0.9688 -- Val acc: 0.8803 -- Test acc: 0.8737 -- Gen gap 0.0950\n",
      "Epoch 97/100\n",
      "Avg loss: 0.1079 -- Train acc: 0.9688 -- Val acc: 0.8800 -- Test acc: 0.8747 -- Gen gap 0.0940\n",
      "Epoch 98/100\n",
      "Avg loss: 0.1057 -- Train acc: 0.9688 -- Val acc: 0.8796 -- Test acc: 0.8743 -- Gen gap 0.0944\n",
      "Epoch 99/100\n",
      "Avg loss: 0.1068 -- Train acc: 0.9688 -- Val acc: 0.8796 -- Test acc: 0.8747 -- Gen gap 0.0940\n",
      "Epoch 100/100\n",
      "Avg loss: 0.1032 -- Train acc: 0.9707 -- Val acc: 0.8798 -- Test acc: 0.8741 -- Gen gap 0.0966\n",
      "Training done! Elapsed time: 0:00:16\n",
      "\n",
      "Iter 3\n",
      "Epoch 1/100\n",
      "Avg loss: 0.4227 -- Train acc: 0.8750 -- Val acc: 0.8833 -- Test acc: 0.8788 -- Gen gap -0.0038\n",
      "Epoch 2/100\n",
      "Avg loss: 0.4049 -- Train acc: 0.8770 -- Val acc: 0.8835 -- Test acc: 0.8775 -- Gen gap -0.0005\n",
      "Epoch 3/100\n",
      "Avg loss: 0.3916 -- Train acc: 0.8789 -- Val acc: 0.8807 -- Test acc: 0.8753 -- Gen gap 0.0036\n",
      "Epoch 4/100\n",
      "Avg loss: 0.3781 -- Train acc: 0.8848 -- Val acc: 0.8833 -- Test acc: 0.8778 -- Gen gap 0.0070\n",
      "Epoch 5/100\n",
      "Avg loss: 0.3622 -- Train acc: 0.8887 -- Val acc: 0.8840 -- Test acc: 0.8789 -- Gen gap 0.0098\n",
      "Epoch 6/100\n",
      "Avg loss: 0.3480 -- Train acc: 0.8945 -- Val acc: 0.8840 -- Test acc: 0.8796 -- Gen gap 0.0150\n",
      "Epoch 7/100\n",
      "Avg loss: 0.3398 -- Train acc: 0.8926 -- Val acc: 0.8859 -- Test acc: 0.8806 -- Gen gap 0.0120\n",
      "Epoch 8/100\n",
      "Avg loss: 0.3379 -- Train acc: 0.8965 -- Val acc: 0.8854 -- Test acc: 0.8825 -- Gen gap 0.0140\n",
      "Epoch 9/100\n",
      "Avg loss: 0.3231 -- Train acc: 0.8965 -- Val acc: 0.8841 -- Test acc: 0.8823 -- Gen gap 0.0142\n",
      "Epoch 10/100\n",
      "Avg loss: 0.3132 -- Train acc: 0.8984 -- Val acc: 0.8861 -- Test acc: 0.8841 -- Gen gap 0.0144\n",
      "Epoch 11/100\n",
      "Avg loss: 0.3065 -- Train acc: 0.8984 -- Val acc: 0.8855 -- Test acc: 0.8828 -- Gen gap 0.0157\n",
      "Epoch 12/100\n",
      "Avg loss: 0.3008 -- Train acc: 0.8984 -- Val acc: 0.8846 -- Test acc: 0.8835 -- Gen gap 0.0150\n",
      "Epoch 13/100\n",
      "Avg loss: 0.2917 -- Train acc: 0.8984 -- Val acc: 0.8857 -- Test acc: 0.8840 -- Gen gap 0.0145\n",
      "Epoch 14/100\n",
      "Avg loss: 0.2856 -- Train acc: 0.9004 -- Val acc: 0.8855 -- Test acc: 0.8842 -- Gen gap 0.0162\n",
      "Epoch 15/100\n",
      "Avg loss: 0.2773 -- Train acc: 0.9023 -- Val acc: 0.8866 -- Test acc: 0.8834 -- Gen gap 0.0190\n",
      "Epoch 16/100\n",
      "Avg loss: 0.2751 -- Train acc: 0.9043 -- Val acc: 0.8860 -- Test acc: 0.8838 -- Gen gap 0.0205\n",
      "Epoch 17/100\n",
      "Avg loss: 0.2679 -- Train acc: 0.9023 -- Val acc: 0.8847 -- Test acc: 0.8839 -- Gen gap 0.0185\n",
      "Epoch 18/100\n",
      "Avg loss: 0.2665 -- Train acc: 0.9062 -- Val acc: 0.8866 -- Test acc: 0.8839 -- Gen gap 0.0224\n",
      "Epoch 19/100\n",
      "Avg loss: 0.2582 -- Train acc: 0.9082 -- Val acc: 0.8865 -- Test acc: 0.8849 -- Gen gap 0.0234\n",
      "Epoch 20/100\n",
      "Avg loss: 0.2552 -- Train acc: 0.9082 -- Val acc: 0.8849 -- Test acc: 0.8838 -- Gen gap 0.0244\n",
      "Epoch 21/100\n",
      "Avg loss: 0.2476 -- Train acc: 0.9102 -- Val acc: 0.8861 -- Test acc: 0.8847 -- Gen gap 0.0255\n",
      "Epoch 22/100\n",
      "Avg loss: 0.2438 -- Train acc: 0.9121 -- Val acc: 0.8854 -- Test acc: 0.8846 -- Gen gap 0.0276\n",
      "Epoch 23/100\n",
      "Avg loss: 0.2440 -- Train acc: 0.9160 -- Val acc: 0.8864 -- Test acc: 0.8860 -- Gen gap 0.0300\n",
      "Epoch 24/100\n",
      "Avg loss: 0.2343 -- Train acc: 0.9160 -- Val acc: 0.8859 -- Test acc: 0.8861 -- Gen gap 0.0299\n",
      "Epoch 25/100\n",
      "Avg loss: 0.2302 -- Train acc: 0.9141 -- Val acc: 0.8857 -- Test acc: 0.8850 -- Gen gap 0.0291\n",
      "Epoch 26/100\n",
      "Avg loss: 0.2248 -- Train acc: 0.9238 -- Val acc: 0.8869 -- Test acc: 0.8851 -- Gen gap 0.0388\n",
      "Epoch 27/100\n",
      "Avg loss: 0.2195 -- Train acc: 0.9238 -- Val acc: 0.8871 -- Test acc: 0.8849 -- Gen gap 0.0390\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.2143 -- Train acc: 0.9258 -- Val acc: 0.8856 -- Test acc: 0.8850 -- Gen gap 0.0408\n",
      "Epoch 29/100\n",
      "Avg loss: 0.2168 -- Train acc: 0.9238 -- Val acc: 0.8866 -- Test acc: 0.8855 -- Gen gap 0.0383\n",
      "Epoch 30/100\n",
      "Avg loss: 0.2125 -- Train acc: 0.9355 -- Val acc: 0.8876 -- Test acc: 0.8860 -- Gen gap 0.0495\n",
      "Epoch 31/100\n",
      "Avg loss: 0.2078 -- Train acc: 0.9336 -- Val acc: 0.8882 -- Test acc: 0.8858 -- Gen gap 0.0477\n",
      "Epoch 32/100\n",
      "Avg loss: 0.2077 -- Train acc: 0.9375 -- Val acc: 0.8880 -- Test acc: 0.8867 -- Gen gap 0.0508\n",
      "Epoch 33/100\n",
      "Avg loss: 0.1993 -- Train acc: 0.9375 -- Val acc: 0.8876 -- Test acc: 0.8861 -- Gen gap 0.0514\n",
      "Epoch 34/100\n",
      "Avg loss: 0.1976 -- Train acc: 0.9395 -- Val acc: 0.8879 -- Test acc: 0.8857 -- Gen gap 0.0537\n",
      "Epoch 35/100\n",
      "Avg loss: 0.1928 -- Train acc: 0.9395 -- Val acc: 0.8872 -- Test acc: 0.8859 -- Gen gap 0.0535\n",
      "Epoch 36/100\n",
      "Avg loss: 0.1918 -- Train acc: 0.9395 -- Val acc: 0.8874 -- Test acc: 0.8864 -- Gen gap 0.0530\n",
      "Epoch 37/100\n",
      "Avg loss: 0.1892 -- Train acc: 0.9414 -- Val acc: 0.8869 -- Test acc: 0.8855 -- Gen gap 0.0559\n",
      "Epoch 38/100\n",
      "Avg loss: 0.1844 -- Train acc: 0.9453 -- Val acc: 0.8879 -- Test acc: 0.8860 -- Gen gap 0.0593\n",
      "Epoch 39/100\n",
      "Avg loss: 0.1822 -- Train acc: 0.9434 -- Val acc: 0.8891 -- Test acc: 0.8861 -- Gen gap 0.0572\n",
      "Epoch 40/100\n",
      "Avg loss: 0.1805 -- Train acc: 0.9453 -- Val acc: 0.8877 -- Test acc: 0.8865 -- Gen gap 0.0588\n",
      "Epoch 41/100\n",
      "Avg loss: 0.1761 -- Train acc: 0.9512 -- Val acc: 0.8879 -- Test acc: 0.8868 -- Gen gap 0.0643\n",
      "Epoch 42/100\n",
      "Avg loss: 0.1739 -- Train acc: 0.9512 -- Val acc: 0.8875 -- Test acc: 0.8865 -- Gen gap 0.0646\n",
      "Epoch 43/100\n",
      "Avg loss: 0.1708 -- Train acc: 0.9512 -- Val acc: 0.8879 -- Test acc: 0.8857 -- Gen gap 0.0654\n",
      "Epoch 44/100\n",
      "Avg loss: 0.1705 -- Train acc: 0.9531 -- Val acc: 0.8884 -- Test acc: 0.8876 -- Gen gap 0.0655\n",
      "Epoch 45/100\n",
      "Avg loss: 0.1663 -- Train acc: 0.9531 -- Val acc: 0.8886 -- Test acc: 0.8880 -- Gen gap 0.0651\n",
      "Epoch 46/100\n",
      "Avg loss: 0.1632 -- Train acc: 0.9531 -- Val acc: 0.8887 -- Test acc: 0.8870 -- Gen gap 0.0661\n",
      "Epoch 47/100\n",
      "Avg loss: 0.1614 -- Train acc: 0.9551 -- Val acc: 0.8882 -- Test acc: 0.8870 -- Gen gap 0.0680\n",
      "Epoch 48/100\n",
      "Avg loss: 0.1593 -- Train acc: 0.9570 -- Val acc: 0.8884 -- Test acc: 0.8876 -- Gen gap 0.0694\n",
      "Epoch 49/100\n",
      "Avg loss: 0.1562 -- Train acc: 0.9551 -- Val acc: 0.8878 -- Test acc: 0.8865 -- Gen gap 0.0685\n",
      "Epoch 50/100\n",
      "Avg loss: 0.1550 -- Train acc: 0.9551 -- Val acc: 0.8880 -- Test acc: 0.8870 -- Gen gap 0.0680\n",
      "Epoch 51/100\n",
      "Avg loss: 0.1513 -- Train acc: 0.9570 -- Val acc: 0.8880 -- Test acc: 0.8875 -- Gen gap 0.0695\n",
      "Epoch 52/100\n",
      "Avg loss: 0.1499 -- Train acc: 0.9570 -- Val acc: 0.8881 -- Test acc: 0.8874 -- Gen gap 0.0696\n",
      "Epoch 53/100\n",
      "Avg loss: 0.1482 -- Train acc: 0.9570 -- Val acc: 0.8879 -- Test acc: 0.8865 -- Gen gap 0.0705\n",
      "Epoch 54/100\n",
      "Avg loss: 0.1459 -- Train acc: 0.9590 -- Val acc: 0.8874 -- Test acc: 0.8868 -- Gen gap 0.0721\n",
      "Epoch 55/100\n",
      "Avg loss: 0.1444 -- Train acc: 0.9570 -- Val acc: 0.8876 -- Test acc: 0.8867 -- Gen gap 0.0703\n",
      "Epoch 56/100\n",
      "Avg loss: 0.1424 -- Train acc: 0.9590 -- Val acc: 0.8879 -- Test acc: 0.8871 -- Gen gap 0.0718\n",
      "Epoch 57/100\n",
      "Avg loss: 0.1403 -- Train acc: 0.9590 -- Val acc: 0.8874 -- Test acc: 0.8873 -- Gen gap 0.0716\n",
      "Epoch 58/100\n",
      "Avg loss: 0.1411 -- Train acc: 0.9590 -- Val acc: 0.8873 -- Test acc: 0.8867 -- Gen gap 0.0722\n",
      "Epoch 59/100\n",
      "Avg loss: 0.1370 -- Train acc: 0.9590 -- Val acc: 0.8878 -- Test acc: 0.8872 -- Gen gap 0.0717\n",
      "Epoch 60/100\n",
      "Avg loss: 0.1357 -- Train acc: 0.9590 -- Val acc: 0.8880 -- Test acc: 0.8866 -- Gen gap 0.0723\n",
      "Epoch 61/100\n",
      "Avg loss: 0.1333 -- Train acc: 0.9609 -- Val acc: 0.8875 -- Test acc: 0.8874 -- Gen gap 0.0735\n",
      "Epoch 62/100\n",
      "Avg loss: 0.1307 -- Train acc: 0.9609 -- Val acc: 0.8881 -- Test acc: 0.8868 -- Gen gap 0.0741\n",
      "Epoch 63/100\n",
      "Avg loss: 0.1295 -- Train acc: 0.9590 -- Val acc: 0.8875 -- Test acc: 0.8867 -- Gen gap 0.0722\n",
      "Epoch 64/100\n",
      "Avg loss: 0.1299 -- Train acc: 0.9609 -- Val acc: 0.8880 -- Test acc: 0.8863 -- Gen gap 0.0746\n",
      "Epoch 65/100\n",
      "Avg loss: 0.1272 -- Train acc: 0.9629 -- Val acc: 0.8874 -- Test acc: 0.8864 -- Gen gap 0.0764\n",
      "Epoch 66/100\n",
      "Avg loss: 0.1273 -- Train acc: 0.9629 -- Val acc: 0.8882 -- Test acc: 0.8864 -- Gen gap 0.0764\n",
      "Epoch 67/100\n",
      "Avg loss: 0.1222 -- Train acc: 0.9629 -- Val acc: 0.8880 -- Test acc: 0.8858 -- Gen gap 0.0770\n",
      "Epoch 68/100\n",
      "Avg loss: 0.1228 -- Train acc: 0.9629 -- Val acc: 0.8875 -- Test acc: 0.8867 -- Gen gap 0.0761\n",
      "Epoch 69/100\n",
      "Avg loss: 0.1204 -- Train acc: 0.9648 -- Val acc: 0.8872 -- Test acc: 0.8860 -- Gen gap 0.0788\n",
      "Epoch 70/100\n",
      "Avg loss: 0.1201 -- Train acc: 0.9668 -- Val acc: 0.8884 -- Test acc: 0.8866 -- Gen gap 0.0802\n",
      "Epoch 71/100\n",
      "Avg loss: 0.1186 -- Train acc: 0.9648 -- Val acc: 0.8876 -- Test acc: 0.8864 -- Gen gap 0.0784\n",
      "Epoch 72/100\n",
      "Avg loss: 0.1164 -- Train acc: 0.9668 -- Val acc: 0.8878 -- Test acc: 0.8863 -- Gen gap 0.0805\n",
      "Epoch 73/100\n",
      "Avg loss: 0.1141 -- Train acc: 0.9668 -- Val acc: 0.8890 -- Test acc: 0.8862 -- Gen gap 0.0806\n",
      "Epoch 74/100\n",
      "Avg loss: 0.1144 -- Train acc: 0.9668 -- Val acc: 0.8876 -- Test acc: 0.8858 -- Gen gap 0.0809\n",
      "Epoch 75/100\n",
      "Avg loss: 0.1135 -- Train acc: 0.9688 -- Val acc: 0.8882 -- Test acc: 0.8864 -- Gen gap 0.0823\n",
      "Epoch 76/100\n",
      "Avg loss: 0.1109 -- Train acc: 0.9688 -- Val acc: 0.8883 -- Test acc: 0.8868 -- Gen gap 0.0819\n",
      "Epoch 77/100\n",
      "Avg loss: 0.1101 -- Train acc: 0.9688 -- Val acc: 0.8885 -- Test acc: 0.8863 -- Gen gap 0.0824\n",
      "Epoch 78/100\n",
      "Avg loss: 0.1076 -- Train acc: 0.9707 -- Val acc: 0.8877 -- Test acc: 0.8866 -- Gen gap 0.0841\n",
      "Epoch 79/100\n",
      "Avg loss: 0.1062 -- Train acc: 0.9707 -- Val acc: 0.8872 -- Test acc: 0.8866 -- Gen gap 0.0841\n",
      "Epoch 80/100\n",
      "Avg loss: 0.1058 -- Train acc: 0.9688 -- Val acc: 0.8882 -- Test acc: 0.8866 -- Gen gap 0.0821\n",
      "Epoch 81/100\n",
      "Avg loss: 0.1047 -- Train acc: 0.9707 -- Val acc: 0.8878 -- Test acc: 0.8861 -- Gen gap 0.0846\n",
      "Epoch 82/100\n",
      "Avg loss: 0.1036 -- Train acc: 0.9707 -- Val acc: 0.8881 -- Test acc: 0.8862 -- Gen gap 0.0845\n",
      "Epoch 83/100\n",
      "Avg loss: 0.1012 -- Train acc: 0.9707 -- Val acc: 0.8878 -- Test acc: 0.8859 -- Gen gap 0.0848\n",
      "Epoch 84/100\n",
      "Avg loss: 0.1024 -- Train acc: 0.9707 -- Val acc: 0.8882 -- Test acc: 0.8861 -- Gen gap 0.0846\n",
      "Epoch 85/100\n",
      "Avg loss: 0.0996 -- Train acc: 0.9707 -- Val acc: 0.8879 -- Test acc: 0.8854 -- Gen gap 0.0854\n",
      "Epoch 86/100\n",
      "Avg loss: 0.0990 -- Train acc: 0.9707 -- Val acc: 0.8888 -- Test acc: 0.8863 -- Gen gap 0.0844\n",
      "Epoch 87/100\n",
      "Avg loss: 0.0969 -- Train acc: 0.9707 -- Val acc: 0.8881 -- Test acc: 0.8870 -- Gen gap 0.0837\n",
      "Epoch 88/100\n",
      "Avg loss: 0.0964 -- Train acc: 0.9707 -- Val acc: 0.8887 -- Test acc: 0.8868 -- Gen gap 0.0839\n",
      "Epoch 89/100\n",
      "Avg loss: 0.0976 -- Train acc: 0.9707 -- Val acc: 0.8885 -- Test acc: 0.8864 -- Gen gap 0.0843\n",
      "Epoch 90/100\n",
      "Avg loss: 0.0949 -- Train acc: 0.9707 -- Val acc: 0.8885 -- Test acc: 0.8866 -- Gen gap 0.0841\n",
      "Epoch 91/100\n",
      "Avg loss: 0.0944 -- Train acc: 0.9707 -- Val acc: 0.8880 -- Test acc: 0.8858 -- Gen gap 0.0849\n",
      "Epoch 92/100\n",
      "Avg loss: 0.0923 -- Train acc: 0.9707 -- Val acc: 0.8884 -- Test acc: 0.8866 -- Gen gap 0.0841\n",
      "Epoch 93/100\n",
      "Avg loss: 0.0909 -- Train acc: 0.9707 -- Val acc: 0.8885 -- Test acc: 0.8864 -- Gen gap 0.0843\n",
      "Epoch 94/100\n",
      "Avg loss: 0.0917 -- Train acc: 0.9707 -- Val acc: 0.8877 -- Test acc: 0.8857 -- Gen gap 0.0850\n",
      "Epoch 95/100\n",
      "Avg loss: 0.0897 -- Train acc: 0.9707 -- Val acc: 0.8874 -- Test acc: 0.8854 -- Gen gap 0.0854\n",
      "Epoch 96/100\n",
      "Avg loss: 0.0883 -- Train acc: 0.9707 -- Val acc: 0.8879 -- Test acc: 0.8855 -- Gen gap 0.0852\n",
      "Epoch 97/100\n",
      "Avg loss: 0.0877 -- Train acc: 0.9707 -- Val acc: 0.8882 -- Test acc: 0.8845 -- Gen gap 0.0862\n",
      "Epoch 98/100\n",
      "Avg loss: 0.0878 -- Train acc: 0.9707 -- Val acc: 0.8881 -- Test acc: 0.8853 -- Gen gap 0.0855\n",
      "Epoch 99/100\n",
      "Avg loss: 0.0854 -- Train acc: 0.9707 -- Val acc: 0.8880 -- Test acc: 0.8851 -- Gen gap 0.0857\n",
      "Epoch 100/100\n",
      "Avg loss: 0.0853 -- Train acc: 0.9707 -- Val acc: 0.8892 -- Test acc: 0.8854 -- Gen gap 0.0853\n",
      "Training done! Elapsed time: 0:00:14\n",
      "\n",
      "==============================\n",
      "a = 0.02, Na = 1000\n",
      "------------------------------\n",
      "Iter 1\n",
      "Epoch 1/100\n",
      "Avg loss: 0.3878 -- Train acc: 0.8760 -- Val acc: 0.8900 -- Test acc: 0.8888 -- Gen gap -0.0129\n",
      "Epoch 2/100\n",
      "Avg loss: 0.3659 -- Train acc: 0.8828 -- Val acc: 0.8948 -- Test acc: 0.8923 -- Gen gap -0.0095\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.3424 -- Train acc: 0.8848 -- Val acc: 0.8954 -- Test acc: 0.8925 -- Gen gap -0.0078\n",
      "Epoch 4/100\n",
      "Avg loss: 0.3295 -- Train acc: 0.8838 -- Val acc: 0.8956 -- Test acc: 0.8939 -- Gen gap -0.0101\n",
      "Epoch 5/100\n",
      "Avg loss: 0.3200 -- Train acc: 0.8906 -- Val acc: 0.8985 -- Test acc: 0.8947 -- Gen gap -0.0041\n",
      "Epoch 6/100\n",
      "Avg loss: 0.3012 -- Train acc: 0.8955 -- Val acc: 0.8986 -- Test acc: 0.8953 -- Gen gap 0.0002\n",
      "Epoch 7/100\n",
      "Avg loss: 0.3041 -- Train acc: 0.8936 -- Val acc: 0.8974 -- Test acc: 0.8950 -- Gen gap -0.0014\n",
      "Epoch 8/100\n",
      "Avg loss: 0.2852 -- Train acc: 0.8984 -- Val acc: 0.9008 -- Test acc: 0.8983 -- Gen gap 0.0001\n",
      "Epoch 9/100\n",
      "Avg loss: 0.2808 -- Train acc: 0.9043 -- Val acc: 0.9006 -- Test acc: 0.8976 -- Gen gap 0.0067\n",
      "Epoch 10/100\n",
      "Avg loss: 0.2709 -- Train acc: 0.9082 -- Val acc: 0.9014 -- Test acc: 0.8960 -- Gen gap 0.0122\n",
      "Epoch 11/100\n",
      "Avg loss: 0.2639 -- Train acc: 0.9082 -- Val acc: 0.9022 -- Test acc: 0.8987 -- Gen gap 0.0095\n",
      "Epoch 12/100\n",
      "Avg loss: 0.2644 -- Train acc: 0.9092 -- Val acc: 0.9006 -- Test acc: 0.8973 -- Gen gap 0.0119\n",
      "Epoch 13/100\n",
      "Avg loss: 0.2516 -- Train acc: 0.9111 -- Val acc: 0.9024 -- Test acc: 0.8994 -- Gen gap 0.0117\n",
      "Epoch 14/100\n",
      "Avg loss: 0.2509 -- Train acc: 0.9150 -- Val acc: 0.9026 -- Test acc: 0.9004 -- Gen gap 0.0147\n",
      "Epoch 15/100\n",
      "Avg loss: 0.2380 -- Train acc: 0.9199 -- Val acc: 0.9038 -- Test acc: 0.8994 -- Gen gap 0.0205\n",
      "Epoch 16/100\n",
      "Avg loss: 0.2347 -- Train acc: 0.9199 -- Val acc: 0.9033 -- Test acc: 0.9009 -- Gen gap 0.0190\n",
      "Epoch 17/100\n",
      "Avg loss: 0.2316 -- Train acc: 0.9189 -- Val acc: 0.9043 -- Test acc: 0.9010 -- Gen gap 0.0180\n",
      "Epoch 18/100\n",
      "Avg loss: 0.2244 -- Train acc: 0.9199 -- Val acc: 0.9038 -- Test acc: 0.9006 -- Gen gap 0.0193\n",
      "Epoch 19/100\n",
      "Avg loss: 0.2189 -- Train acc: 0.9258 -- Val acc: 0.9049 -- Test acc: 0.8998 -- Gen gap 0.0260\n",
      "Epoch 20/100\n",
      "Avg loss: 0.2171 -- Train acc: 0.9268 -- Val acc: 0.9044 -- Test acc: 0.9004 -- Gen gap 0.0264\n",
      "Epoch 21/100\n",
      "Avg loss: 0.2124 -- Train acc: 0.9297 -- Val acc: 0.9042 -- Test acc: 0.9000 -- Gen gap 0.0297\n",
      "Epoch 22/100\n",
      "Avg loss: 0.2089 -- Train acc: 0.9297 -- Val acc: 0.9043 -- Test acc: 0.8998 -- Gen gap 0.0299\n",
      "Epoch 23/100\n",
      "Avg loss: 0.2062 -- Train acc: 0.9336 -- Val acc: 0.9037 -- Test acc: 0.9010 -- Gen gap 0.0326\n",
      "Epoch 24/100\n",
      "Avg loss: 0.1977 -- Train acc: 0.9346 -- Val acc: 0.9041 -- Test acc: 0.8998 -- Gen gap 0.0348\n",
      "Epoch 25/100\n",
      "Avg loss: 0.1968 -- Train acc: 0.9346 -- Val acc: 0.9032 -- Test acc: 0.9001 -- Gen gap 0.0345\n",
      "Epoch 26/100\n",
      "Avg loss: 0.1938 -- Train acc: 0.9414 -- Val acc: 0.9045 -- Test acc: 0.9000 -- Gen gap 0.0414\n",
      "Epoch 27/100\n",
      "Avg loss: 0.1895 -- Train acc: 0.9424 -- Val acc: 0.9049 -- Test acc: 0.9007 -- Gen gap 0.0417\n",
      "Epoch 28/100\n",
      "Avg loss: 0.1865 -- Train acc: 0.9424 -- Val acc: 0.9051 -- Test acc: 0.9006 -- Gen gap 0.0418\n",
      "Epoch 29/100\n",
      "Avg loss: 0.1799 -- Train acc: 0.9453 -- Val acc: 0.9053 -- Test acc: 0.9013 -- Gen gap 0.0440\n",
      "Epoch 30/100\n",
      "Avg loss: 0.1808 -- Train acc: 0.9473 -- Val acc: 0.9041 -- Test acc: 0.8994 -- Gen gap 0.0479\n",
      "Epoch 31/100\n",
      "Avg loss: 0.1779 -- Train acc: 0.9453 -- Val acc: 0.9047 -- Test acc: 0.9008 -- Gen gap 0.0445\n",
      "Epoch 32/100\n",
      "Avg loss: 0.1725 -- Train acc: 0.9502 -- Val acc: 0.9041 -- Test acc: 0.9001 -- Gen gap 0.0501\n",
      "Epoch 33/100\n",
      "Avg loss: 0.1667 -- Train acc: 0.9512 -- Val acc: 0.9034 -- Test acc: 0.9005 -- Gen gap 0.0507\n",
      "Epoch 34/100\n",
      "Avg loss: 0.1667 -- Train acc: 0.9512 -- Val acc: 0.9053 -- Test acc: 0.9001 -- Gen gap 0.0511\n",
      "Epoch 35/100\n",
      "Avg loss: 0.1666 -- Train acc: 0.9531 -- Val acc: 0.9034 -- Test acc: 0.9006 -- Gen gap 0.0525\n",
      "Epoch 36/100\n",
      "Avg loss: 0.1641 -- Train acc: 0.9521 -- Val acc: 0.9039 -- Test acc: 0.9008 -- Gen gap 0.0514\n",
      "Epoch 37/100\n",
      "Avg loss: 0.1566 -- Train acc: 0.9531 -- Val acc: 0.9045 -- Test acc: 0.9008 -- Gen gap 0.0523\n",
      "Epoch 38/100\n",
      "Avg loss: 0.1577 -- Train acc: 0.9541 -- Val acc: 0.9057 -- Test acc: 0.9003 -- Gen gap 0.0538\n",
      "Epoch 39/100\n",
      "Avg loss: 0.1531 -- Train acc: 0.9561 -- Val acc: 0.9063 -- Test acc: 0.9012 -- Gen gap 0.0549\n",
      "Epoch 40/100\n",
      "Avg loss: 0.1495 -- Train acc: 0.9531 -- Val acc: 0.9055 -- Test acc: 0.9002 -- Gen gap 0.0529\n",
      "Epoch 41/100\n",
      "Avg loss: 0.1483 -- Train acc: 0.9561 -- Val acc: 0.9061 -- Test acc: 0.9011 -- Gen gap 0.0550\n",
      "Epoch 42/100\n",
      "Avg loss: 0.1486 -- Train acc: 0.9551 -- Val acc: 0.9051 -- Test acc: 0.9012 -- Gen gap 0.0539\n",
      "Epoch 43/100\n",
      "Avg loss: 0.1432 -- Train acc: 0.9580 -- Val acc: 0.9056 -- Test acc: 0.9010 -- Gen gap 0.0570\n",
      "Epoch 44/100\n",
      "Avg loss: 0.1426 -- Train acc: 0.9570 -- Val acc: 0.9065 -- Test acc: 0.9013 -- Gen gap 0.0558\n",
      "Epoch 45/100\n",
      "Avg loss: 0.1394 -- Train acc: 0.9580 -- Val acc: 0.9059 -- Test acc: 0.9012 -- Gen gap 0.0568\n",
      "Epoch 46/100\n",
      "Avg loss: 0.1398 -- Train acc: 0.9580 -- Val acc: 0.9058 -- Test acc: 0.9012 -- Gen gap 0.0568\n",
      "Epoch 47/100\n",
      "Avg loss: 0.1344 -- Train acc: 0.9580 -- Val acc: 0.9062 -- Test acc: 0.9020 -- Gen gap 0.0560\n",
      "Epoch 48/100\n",
      "Avg loss: 0.1340 -- Train acc: 0.9570 -- Val acc: 0.9058 -- Test acc: 0.9016 -- Gen gap 0.0555\n",
      "Epoch 49/100\n",
      "Avg loss: 0.1304 -- Train acc: 0.9570 -- Val acc: 0.9071 -- Test acc: 0.9007 -- Gen gap 0.0564\n",
      "Epoch 50/100\n",
      "Avg loss: 0.1284 -- Train acc: 0.9580 -- Val acc: 0.9062 -- Test acc: 0.9014 -- Gen gap 0.0566\n",
      "Epoch 51/100\n",
      "Avg loss: 0.1292 -- Train acc: 0.9580 -- Val acc: 0.9070 -- Test acc: 0.9020 -- Gen gap 0.0560\n",
      "Epoch 52/100\n",
      "Avg loss: 0.1268 -- Train acc: 0.9580 -- Val acc: 0.9060 -- Test acc: 0.9021 -- Gen gap 0.0559\n",
      "Epoch 53/100\n",
      "Avg loss: 0.1226 -- Train acc: 0.9600 -- Val acc: 0.9062 -- Test acc: 0.9018 -- Gen gap 0.0582\n",
      "Epoch 54/100\n",
      "Avg loss: 0.1216 -- Train acc: 0.9600 -- Val acc: 0.9067 -- Test acc: 0.9010 -- Gen gap 0.0590\n",
      "Epoch 55/100\n",
      "Avg loss: 0.1190 -- Train acc: 0.9600 -- Val acc: 0.9064 -- Test acc: 0.9015 -- Gen gap 0.0585\n",
      "Epoch 56/100\n",
      "Avg loss: 0.1173 -- Train acc: 0.9609 -- Val acc: 0.9063 -- Test acc: 0.9014 -- Gen gap 0.0596\n",
      "Epoch 57/100\n",
      "Avg loss: 0.1161 -- Train acc: 0.9629 -- Val acc: 0.9076 -- Test acc: 0.9023 -- Gen gap 0.0606\n",
      "Epoch 58/100\n",
      "Avg loss: 0.1139 -- Train acc: 0.9619 -- Val acc: 0.9062 -- Test acc: 0.9012 -- Gen gap 0.0607\n",
      "Epoch 59/100\n",
      "Avg loss: 0.1157 -- Train acc: 0.9619 -- Val acc: 0.9062 -- Test acc: 0.9017 -- Gen gap 0.0602\n",
      "Epoch 60/100\n",
      "Avg loss: 0.1101 -- Train acc: 0.9619 -- Val acc: 0.9070 -- Test acc: 0.9020 -- Gen gap 0.0599\n",
      "Epoch 61/100\n",
      "Avg loss: 0.1095 -- Train acc: 0.9639 -- Val acc: 0.9079 -- Test acc: 0.9013 -- Gen gap 0.0626\n",
      "Epoch 62/100\n",
      "Avg loss: 0.1067 -- Train acc: 0.9639 -- Val acc: 0.9074 -- Test acc: 0.9015 -- Gen gap 0.0624\n",
      "Epoch 63/100\n",
      "Avg loss: 0.1050 -- Train acc: 0.9639 -- Val acc: 0.9073 -- Test acc: 0.9024 -- Gen gap 0.0615\n",
      "Epoch 64/100\n",
      "Avg loss: 0.1055 -- Train acc: 0.9629 -- Val acc: 0.9069 -- Test acc: 0.9017 -- Gen gap 0.0612\n",
      "Epoch 65/100\n",
      "Avg loss: 0.1045 -- Train acc: 0.9639 -- Val acc: 0.9076 -- Test acc: 0.9009 -- Gen gap 0.0630\n",
      "Epoch 66/100\n",
      "Avg loss: 0.1024 -- Train acc: 0.9639 -- Val acc: 0.9089 -- Test acc: 0.9010 -- Gen gap 0.0629\n",
      "Epoch 67/100\n",
      "Avg loss: 0.1008 -- Train acc: 0.9658 -- Val acc: 0.9069 -- Test acc: 0.9019 -- Gen gap 0.0639\n",
      "Epoch 68/100\n",
      "Avg loss: 0.0984 -- Train acc: 0.9648 -- Val acc: 0.9080 -- Test acc: 0.9026 -- Gen gap 0.0623\n",
      "Epoch 69/100\n",
      "Avg loss: 0.0978 -- Train acc: 0.9658 -- Val acc: 0.9072 -- Test acc: 0.9018 -- Gen gap 0.0640\n",
      "Epoch 70/100\n",
      "Avg loss: 0.0966 -- Train acc: 0.9648 -- Val acc: 0.9077 -- Test acc: 0.9024 -- Gen gap 0.0625\n",
      "Epoch 71/100\n",
      "Avg loss: 0.0940 -- Train acc: 0.9648 -- Val acc: 0.9071 -- Test acc: 0.9014 -- Gen gap 0.0635\n",
      "Epoch 72/100\n",
      "Avg loss: 0.0933 -- Train acc: 0.9648 -- Val acc: 0.9085 -- Test acc: 0.9013 -- Gen gap 0.0636\n",
      "Epoch 73/100\n",
      "Avg loss: 0.0927 -- Train acc: 0.9658 -- Val acc: 0.9076 -- Test acc: 0.9017 -- Gen gap 0.0641\n",
      "Epoch 74/100\n",
      "Avg loss: 0.0905 -- Train acc: 0.9658 -- Val acc: 0.9077 -- Test acc: 0.9010 -- Gen gap 0.0648\n",
      "Epoch 75/100\n",
      "Avg loss: 0.0901 -- Train acc: 0.9678 -- Val acc: 0.9071 -- Test acc: 0.9022 -- Gen gap 0.0656\n",
      "Epoch 76/100\n",
      "Avg loss: 0.0911 -- Train acc: 0.9678 -- Val acc: 0.9067 -- Test acc: 0.9005 -- Gen gap 0.0673\n",
      "Epoch 77/100\n",
      "Avg loss: 0.0871 -- Train acc: 0.9658 -- Val acc: 0.9072 -- Test acc: 0.9013 -- Gen gap 0.0645\n",
      "Epoch 78/100\n",
      "Avg loss: 0.0854 -- Train acc: 0.9688 -- Val acc: 0.9076 -- Test acc: 0.9016 -- Gen gap 0.0672\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.0871 -- Train acc: 0.9668 -- Val acc: 0.9065 -- Test acc: 0.9012 -- Gen gap 0.0656\n",
      "Epoch 80/100\n",
      "Avg loss: 0.0830 -- Train acc: 0.9697 -- Val acc: 0.9078 -- Test acc: 0.9023 -- Gen gap 0.0675\n",
      "Epoch 81/100\n",
      "Avg loss: 0.0827 -- Train acc: 0.9697 -- Val acc: 0.9077 -- Test acc: 0.9021 -- Gen gap 0.0677\n",
      "Epoch 82/100\n",
      "Avg loss: 0.0818 -- Train acc: 0.9697 -- Val acc: 0.9084 -- Test acc: 0.9025 -- Gen gap 0.0673\n",
      "Epoch 83/100\n",
      "Avg loss: 0.0812 -- Train acc: 0.9697 -- Val acc: 0.9085 -- Test acc: 0.9019 -- Gen gap 0.0679\n",
      "Epoch 84/100\n",
      "Avg loss: 0.0800 -- Train acc: 0.9697 -- Val acc: 0.9088 -- Test acc: 0.9014 -- Gen gap 0.0684\n",
      "Epoch 85/100\n",
      "Avg loss: 0.0786 -- Train acc: 0.9697 -- Val acc: 0.9074 -- Test acc: 0.9011 -- Gen gap 0.0687\n",
      "Epoch 86/100\n",
      "Avg loss: 0.0777 -- Train acc: 0.9697 -- Val acc: 0.9080 -- Test acc: 0.9018 -- Gen gap 0.0680\n",
      "Epoch 87/100\n",
      "Avg loss: 0.0762 -- Train acc: 0.9697 -- Val acc: 0.9074 -- Test acc: 0.9024 -- Gen gap 0.0674\n",
      "Epoch 88/100\n",
      "Avg loss: 0.0752 -- Train acc: 0.9697 -- Val acc: 0.9078 -- Test acc: 0.9014 -- Gen gap 0.0684\n",
      "Epoch 89/100\n",
      "Avg loss: 0.0750 -- Train acc: 0.9697 -- Val acc: 0.9082 -- Test acc: 0.9013 -- Gen gap 0.0685\n",
      "Epoch 90/100\n",
      "Avg loss: 0.0732 -- Train acc: 0.9697 -- Val acc: 0.9082 -- Test acc: 0.9013 -- Gen gap 0.0685\n",
      "Epoch 91/100\n",
      "Avg loss: 0.0721 -- Train acc: 0.9717 -- Val acc: 0.9077 -- Test acc: 0.9008 -- Gen gap 0.0709\n",
      "Epoch 92/100\n",
      "Avg loss: 0.0724 -- Train acc: 0.9697 -- Val acc: 0.9086 -- Test acc: 0.9013 -- Gen gap 0.0685\n",
      "Epoch 93/100\n",
      "Avg loss: 0.0713 -- Train acc: 0.9717 -- Val acc: 0.9085 -- Test acc: 0.9014 -- Gen gap 0.0703\n",
      "Epoch 94/100\n",
      "Avg loss: 0.0709 -- Train acc: 0.9727 -- Val acc: 0.9074 -- Test acc: 0.9010 -- Gen gap 0.0717\n",
      "Epoch 95/100\n",
      "Avg loss: 0.0691 -- Train acc: 0.9727 -- Val acc: 0.9080 -- Test acc: 0.9016 -- Gen gap 0.0711\n",
      "Epoch 96/100\n",
      "Avg loss: 0.0686 -- Train acc: 0.9736 -- Val acc: 0.9080 -- Test acc: 0.9008 -- Gen gap 0.0729\n",
      "Epoch 97/100\n",
      "Avg loss: 0.0678 -- Train acc: 0.9736 -- Val acc: 0.9076 -- Test acc: 0.9006 -- Gen gap 0.0731\n",
      "Epoch 98/100\n",
      "Avg loss: 0.0665 -- Train acc: 0.9736 -- Val acc: 0.9086 -- Test acc: 0.9015 -- Gen gap 0.0722\n",
      "Epoch 99/100\n",
      "Avg loss: 0.0668 -- Train acc: 0.9736 -- Val acc: 0.9082 -- Test acc: 0.9013 -- Gen gap 0.0724\n",
      "Epoch 100/100\n",
      "Avg loss: 0.0654 -- Train acc: 0.9736 -- Val acc: 0.9087 -- Test acc: 0.9016 -- Gen gap 0.0721\n",
      "Training done! Elapsed time: 0:00:17\n",
      "\n",
      "Iter 2\n",
      "Epoch 1/100\n",
      "Avg loss: 0.3153 -- Train acc: 0.8896 -- Val acc: 0.9083 -- Test acc: 0.9012 -- Gen gap -0.0115\n",
      "Epoch 2/100\n",
      "Avg loss: 0.2972 -- Train acc: 0.8955 -- Val acc: 0.9085 -- Test acc: 0.9044 -- Gen gap -0.0089\n",
      "Epoch 3/100\n",
      "Avg loss: 0.2889 -- Train acc: 0.8955 -- Val acc: 0.9086 -- Test acc: 0.9025 -- Gen gap -0.0070\n",
      "Epoch 4/100\n",
      "Avg loss: 0.2712 -- Train acc: 0.8975 -- Val acc: 0.9111 -- Test acc: 0.9062 -- Gen gap -0.0088\n",
      "Epoch 5/100\n",
      "Avg loss: 0.2650 -- Train acc: 0.9072 -- Val acc: 0.9097 -- Test acc: 0.9048 -- Gen gap 0.0025\n",
      "Epoch 6/100\n",
      "Avg loss: 0.2572 -- Train acc: 0.9062 -- Val acc: 0.9109 -- Test acc: 0.9078 -- Gen gap -0.0016\n",
      "Epoch 7/100\n",
      "Avg loss: 0.2445 -- Train acc: 0.9121 -- Val acc: 0.9120 -- Test acc: 0.9086 -- Gen gap 0.0035\n",
      "Epoch 8/100\n",
      "Avg loss: 0.2354 -- Train acc: 0.9150 -- Val acc: 0.9099 -- Test acc: 0.9062 -- Gen gap 0.0089\n",
      "Epoch 9/100\n",
      "Avg loss: 0.2317 -- Train acc: 0.9150 -- Val acc: 0.9098 -- Test acc: 0.9072 -- Gen gap 0.0078\n",
      "Epoch 10/100\n",
      "Avg loss: 0.2245 -- Train acc: 0.9170 -- Val acc: 0.9098 -- Test acc: 0.9076 -- Gen gap 0.0093\n",
      "Epoch 11/100\n",
      "Avg loss: 0.2163 -- Train acc: 0.9219 -- Val acc: 0.9113 -- Test acc: 0.9084 -- Gen gap 0.0134\n",
      "Epoch 12/100\n",
      "Avg loss: 0.2187 -- Train acc: 0.9248 -- Val acc: 0.9119 -- Test acc: 0.9092 -- Gen gap 0.0156\n",
      "Epoch 13/100\n",
      "Avg loss: 0.2096 -- Train acc: 0.9238 -- Val acc: 0.9099 -- Test acc: 0.9081 -- Gen gap 0.0157\n",
      "Epoch 14/100\n",
      "Avg loss: 0.2001 -- Train acc: 0.9248 -- Val acc: 0.9108 -- Test acc: 0.9072 -- Gen gap 0.0176\n",
      "Epoch 15/100\n",
      "Avg loss: 0.1966 -- Train acc: 0.9248 -- Val acc: 0.9096 -- Test acc: 0.9071 -- Gen gap 0.0177\n",
      "Epoch 16/100\n",
      "Avg loss: 0.1872 -- Train acc: 0.9277 -- Val acc: 0.9106 -- Test acc: 0.9081 -- Gen gap 0.0196\n",
      "Epoch 17/100\n",
      "Avg loss: 0.1874 -- Train acc: 0.9287 -- Val acc: 0.9111 -- Test acc: 0.9081 -- Gen gap 0.0206\n",
      "Epoch 18/100\n",
      "Avg loss: 0.1796 -- Train acc: 0.9297 -- Val acc: 0.9112 -- Test acc: 0.9085 -- Gen gap 0.0211\n",
      "Epoch 19/100\n",
      "Avg loss: 0.1751 -- Train acc: 0.9316 -- Val acc: 0.9106 -- Test acc: 0.9077 -- Gen gap 0.0239\n",
      "Epoch 20/100\n",
      "Avg loss: 0.1739 -- Train acc: 0.9297 -- Val acc: 0.9100 -- Test acc: 0.9086 -- Gen gap 0.0210\n",
      "Epoch 21/100\n",
      "Avg loss: 0.1696 -- Train acc: 0.9326 -- Val acc: 0.9107 -- Test acc: 0.9084 -- Gen gap 0.0242\n",
      "Epoch 22/100\n",
      "Avg loss: 0.1641 -- Train acc: 0.9336 -- Val acc: 0.9115 -- Test acc: 0.9093 -- Gen gap 0.0243\n",
      "Epoch 23/100\n",
      "Avg loss: 0.1622 -- Train acc: 0.9355 -- Val acc: 0.9114 -- Test acc: 0.9095 -- Gen gap 0.0260\n",
      "Epoch 24/100\n",
      "Avg loss: 0.1565 -- Train acc: 0.9375 -- Val acc: 0.9119 -- Test acc: 0.9094 -- Gen gap 0.0281\n",
      "Epoch 25/100\n",
      "Avg loss: 0.1541 -- Train acc: 0.9414 -- Val acc: 0.9100 -- Test acc: 0.9090 -- Gen gap 0.0324\n",
      "Epoch 26/100\n",
      "Avg loss: 0.1531 -- Train acc: 0.9443 -- Val acc: 0.9108 -- Test acc: 0.9087 -- Gen gap 0.0356\n",
      "Epoch 27/100\n",
      "Avg loss: 0.1500 -- Train acc: 0.9443 -- Val acc: 0.9109 -- Test acc: 0.9086 -- Gen gap 0.0357\n",
      "Epoch 28/100\n",
      "Avg loss: 0.1426 -- Train acc: 0.9473 -- Val acc: 0.9121 -- Test acc: 0.9087 -- Gen gap 0.0385\n",
      "Epoch 29/100\n",
      "Avg loss: 0.1420 -- Train acc: 0.9482 -- Val acc: 0.9114 -- Test acc: 0.9092 -- Gen gap 0.0390\n",
      "Epoch 30/100\n",
      "Avg loss: 0.1360 -- Train acc: 0.9492 -- Val acc: 0.9115 -- Test acc: 0.9100 -- Gen gap 0.0392\n",
      "Epoch 31/100\n",
      "Avg loss: 0.1353 -- Train acc: 0.9521 -- Val acc: 0.9111 -- Test acc: 0.9094 -- Gen gap 0.0427\n",
      "Epoch 32/100\n",
      "Avg loss: 0.1334 -- Train acc: 0.9521 -- Val acc: 0.9115 -- Test acc: 0.9097 -- Gen gap 0.0424\n",
      "Epoch 33/100\n",
      "Avg loss: 0.1305 -- Train acc: 0.9502 -- Val acc: 0.9123 -- Test acc: 0.9097 -- Gen gap 0.0405\n",
      "Epoch 34/100\n",
      "Avg loss: 0.1296 -- Train acc: 0.9521 -- Val acc: 0.9106 -- Test acc: 0.9086 -- Gen gap 0.0435\n",
      "Epoch 35/100\n",
      "Avg loss: 0.1248 -- Train acc: 0.9570 -- Val acc: 0.9115 -- Test acc: 0.9096 -- Gen gap 0.0474\n",
      "Epoch 36/100\n",
      "Avg loss: 0.1228 -- Train acc: 0.9580 -- Val acc: 0.9115 -- Test acc: 0.9097 -- Gen gap 0.0483\n",
      "Epoch 37/100\n",
      "Avg loss: 0.1203 -- Train acc: 0.9561 -- Val acc: 0.9115 -- Test acc: 0.9099 -- Gen gap 0.0461\n",
      "Epoch 38/100\n",
      "Avg loss: 0.1194 -- Train acc: 0.9551 -- Val acc: 0.9114 -- Test acc: 0.9110 -- Gen gap 0.0441\n",
      "Epoch 39/100\n",
      "Avg loss: 0.1166 -- Train acc: 0.9580 -- Val acc: 0.9114 -- Test acc: 0.9103 -- Gen gap 0.0477\n",
      "Epoch 40/100\n",
      "Avg loss: 0.1144 -- Train acc: 0.9590 -- Val acc: 0.9109 -- Test acc: 0.9096 -- Gen gap 0.0494\n",
      "Epoch 41/100\n",
      "Avg loss: 0.1112 -- Train acc: 0.9590 -- Val acc: 0.9108 -- Test acc: 0.9090 -- Gen gap 0.0499\n",
      "Epoch 42/100\n",
      "Avg loss: 0.1110 -- Train acc: 0.9600 -- Val acc: 0.9109 -- Test acc: 0.9108 -- Gen gap 0.0491\n",
      "Epoch 43/100\n",
      "Avg loss: 0.1081 -- Train acc: 0.9600 -- Val acc: 0.9104 -- Test acc: 0.9096 -- Gen gap 0.0503\n",
      "Epoch 44/100\n",
      "Avg loss: 0.1060 -- Train acc: 0.9600 -- Val acc: 0.9116 -- Test acc: 0.9105 -- Gen gap 0.0494\n",
      "Epoch 45/100\n",
      "Avg loss: 0.1064 -- Train acc: 0.9600 -- Val acc: 0.9101 -- Test acc: 0.9093 -- Gen gap 0.0506\n",
      "Epoch 46/100\n",
      "Avg loss: 0.1049 -- Train acc: 0.9619 -- Val acc: 0.9097 -- Test acc: 0.9090 -- Gen gap 0.0529\n",
      "Epoch 47/100\n",
      "Avg loss: 0.1020 -- Train acc: 0.9609 -- Val acc: 0.9114 -- Test acc: 0.9098 -- Gen gap 0.0511\n",
      "Epoch 48/100\n",
      "Avg loss: 0.0992 -- Train acc: 0.9619 -- Val acc: 0.9110 -- Test acc: 0.9098 -- Gen gap 0.0521\n",
      "Epoch 49/100\n",
      "Avg loss: 0.0976 -- Train acc: 0.9619 -- Val acc: 0.9117 -- Test acc: 0.9102 -- Gen gap 0.0517\n",
      "Epoch 50/100\n",
      "Avg loss: 0.0962 -- Train acc: 0.9619 -- Val acc: 0.9116 -- Test acc: 0.9111 -- Gen gap 0.0508\n",
      "Epoch 51/100\n",
      "Avg loss: 0.0965 -- Train acc: 0.9619 -- Val acc: 0.9111 -- Test acc: 0.9105 -- Gen gap 0.0514\n",
      "Epoch 52/100\n",
      "Avg loss: 0.0945 -- Train acc: 0.9629 -- Val acc: 0.9111 -- Test acc: 0.9111 -- Gen gap 0.0518\n",
      "Epoch 53/100\n",
      "Avg loss: 0.0912 -- Train acc: 0.9609 -- Val acc: 0.9104 -- Test acc: 0.9099 -- Gen gap 0.0510\n",
      "Epoch 54/100\n",
      "Avg loss: 0.0918 -- Train acc: 0.9619 -- Val acc: 0.9117 -- Test acc: 0.9095 -- Gen gap 0.0524\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.0890 -- Train acc: 0.9629 -- Val acc: 0.9116 -- Test acc: 0.9102 -- Gen gap 0.0527\n",
      "Epoch 56/100\n",
      "Avg loss: 0.0892 -- Train acc: 0.9658 -- Val acc: 0.9114 -- Test acc: 0.9094 -- Gen gap 0.0564\n",
      "Epoch 57/100\n",
      "Avg loss: 0.0870 -- Train acc: 0.9639 -- Val acc: 0.9109 -- Test acc: 0.9093 -- Gen gap 0.0545\n",
      "Epoch 58/100\n",
      "Avg loss: 0.0858 -- Train acc: 0.9648 -- Val acc: 0.9103 -- Test acc: 0.9097 -- Gen gap 0.0551\n",
      "Epoch 59/100\n",
      "Avg loss: 0.0835 -- Train acc: 0.9658 -- Val acc: 0.9109 -- Test acc: 0.9100 -- Gen gap 0.0558\n",
      "Epoch 60/100\n",
      "Avg loss: 0.0820 -- Train acc: 0.9658 -- Val acc: 0.9107 -- Test acc: 0.9095 -- Gen gap 0.0563\n",
      "Epoch 61/100\n",
      "Avg loss: 0.0811 -- Train acc: 0.9658 -- Val acc: 0.9102 -- Test acc: 0.9097 -- Gen gap 0.0561\n",
      "Epoch 62/100\n",
      "Avg loss: 0.0798 -- Train acc: 0.9688 -- Val acc: 0.9094 -- Test acc: 0.9096 -- Gen gap 0.0591\n",
      "Epoch 63/100\n",
      "Avg loss: 0.0777 -- Train acc: 0.9688 -- Val acc: 0.9100 -- Test acc: 0.9092 -- Gen gap 0.0595\n",
      "Epoch 64/100\n",
      "Avg loss: 0.0791 -- Train acc: 0.9668 -- Val acc: 0.9097 -- Test acc: 0.9105 -- Gen gap 0.0563\n",
      "Epoch 65/100\n",
      "Avg loss: 0.0767 -- Train acc: 0.9688 -- Val acc: 0.9095 -- Test acc: 0.9100 -- Gen gap 0.0587\n",
      "Epoch 66/100\n",
      "Avg loss: 0.0759 -- Train acc: 0.9688 -- Val acc: 0.9106 -- Test acc: 0.9097 -- Gen gap 0.0590\n",
      "Epoch 67/100\n",
      "Avg loss: 0.0739 -- Train acc: 0.9688 -- Val acc: 0.9113 -- Test acc: 0.9104 -- Gen gap 0.0583\n",
      "Epoch 68/100\n",
      "Avg loss: 0.0738 -- Train acc: 0.9688 -- Val acc: 0.9111 -- Test acc: 0.9106 -- Gen gap 0.0581\n",
      "Epoch 69/100\n",
      "Avg loss: 0.0726 -- Train acc: 0.9697 -- Val acc: 0.9113 -- Test acc: 0.9106 -- Gen gap 0.0591\n",
      "Epoch 70/100\n",
      "Avg loss: 0.0707 -- Train acc: 0.9707 -- Val acc: 0.9100 -- Test acc: 0.9106 -- Gen gap 0.0601\n",
      "Epoch 71/100\n",
      "Avg loss: 0.0710 -- Train acc: 0.9697 -- Val acc: 0.9108 -- Test acc: 0.9108 -- Gen gap 0.0589\n",
      "Epoch 72/100\n",
      "Avg loss: 0.0692 -- Train acc: 0.9707 -- Val acc: 0.9102 -- Test acc: 0.9101 -- Gen gap 0.0606\n",
      "Epoch 73/100\n",
      "Avg loss: 0.0679 -- Train acc: 0.9717 -- Val acc: 0.9101 -- Test acc: 0.9100 -- Gen gap 0.0616\n",
      "Epoch 74/100\n",
      "Avg loss: 0.0672 -- Train acc: 0.9717 -- Val acc: 0.9102 -- Test acc: 0.9102 -- Gen gap 0.0614\n",
      "Epoch 75/100\n",
      "Avg loss: 0.0666 -- Train acc: 0.9717 -- Val acc: 0.9096 -- Test acc: 0.9099 -- Gen gap 0.0617\n",
      "Epoch 76/100\n",
      "Avg loss: 0.0668 -- Train acc: 0.9717 -- Val acc: 0.9095 -- Test acc: 0.9092 -- Gen gap 0.0624\n",
      "Epoch 77/100\n",
      "Avg loss: 0.0644 -- Train acc: 0.9736 -- Val acc: 0.9090 -- Test acc: 0.9097 -- Gen gap 0.0639\n",
      "Epoch 78/100\n",
      "Avg loss: 0.0642 -- Train acc: 0.9727 -- Val acc: 0.9111 -- Test acc: 0.9109 -- Gen gap 0.0617\n",
      "Epoch 79/100\n",
      "Avg loss: 0.0623 -- Train acc: 0.9736 -- Val acc: 0.9109 -- Test acc: 0.9110 -- Gen gap 0.0626\n",
      "Epoch 80/100\n",
      "Avg loss: 0.0629 -- Train acc: 0.9746 -- Val acc: 0.9106 -- Test acc: 0.9101 -- Gen gap 0.0645\n",
      "Epoch 81/100\n",
      "Avg loss: 0.0621 -- Train acc: 0.9756 -- Val acc: 0.9096 -- Test acc: 0.9099 -- Gen gap 0.0657\n",
      "Epoch 82/100\n",
      "Avg loss: 0.0618 -- Train acc: 0.9756 -- Val acc: 0.9098 -- Test acc: 0.9098 -- Gen gap 0.0658\n",
      "Epoch 83/100\n",
      "Avg loss: 0.0608 -- Train acc: 0.9756 -- Val acc: 0.9097 -- Test acc: 0.9097 -- Gen gap 0.0659\n",
      "Epoch 84/100\n",
      "Avg loss: 0.0599 -- Train acc: 0.9756 -- Val acc: 0.9099 -- Test acc: 0.9098 -- Gen gap 0.0658\n",
      "Epoch 85/100\n",
      "Avg loss: 0.0580 -- Train acc: 0.9756 -- Val acc: 0.9104 -- Test acc: 0.9105 -- Gen gap 0.0651\n",
      "Epoch 86/100\n",
      "Avg loss: 0.0589 -- Train acc: 0.9756 -- Val acc: 0.9093 -- Test acc: 0.9102 -- Gen gap 0.0654\n",
      "Epoch 87/100\n",
      "Avg loss: 0.0565 -- Train acc: 0.9756 -- Val acc: 0.9097 -- Test acc: 0.9099 -- Gen gap 0.0657\n",
      "Epoch 88/100\n",
      "Avg loss: 0.0566 -- Train acc: 0.9756 -- Val acc: 0.9097 -- Test acc: 0.9098 -- Gen gap 0.0658\n",
      "Epoch 89/100\n",
      "Avg loss: 0.0557 -- Train acc: 0.9756 -- Val acc: 0.9100 -- Test acc: 0.9098 -- Gen gap 0.0658\n",
      "Epoch 90/100\n",
      "Avg loss: 0.0553 -- Train acc: 0.9756 -- Val acc: 0.9097 -- Test acc: 0.9093 -- Gen gap 0.0663\n",
      "Epoch 91/100\n",
      "Avg loss: 0.0539 -- Train acc: 0.9756 -- Val acc: 0.9100 -- Test acc: 0.9090 -- Gen gap 0.0665\n",
      "Epoch 92/100\n",
      "Avg loss: 0.0535 -- Train acc: 0.9756 -- Val acc: 0.9094 -- Test acc: 0.9092 -- Gen gap 0.0664\n",
      "Epoch 93/100\n",
      "Avg loss: 0.0531 -- Train acc: 0.9756 -- Val acc: 0.9093 -- Test acc: 0.9094 -- Gen gap 0.0662\n",
      "Epoch 94/100\n",
      "Avg loss: 0.0536 -- Train acc: 0.9756 -- Val acc: 0.9081 -- Test acc: 0.9085 -- Gen gap 0.0670\n",
      "Epoch 95/100\n",
      "Avg loss: 0.0521 -- Train acc: 0.9756 -- Val acc: 0.9098 -- Test acc: 0.9097 -- Gen gap 0.0659\n",
      "Epoch 96/100\n",
      "Avg loss: 0.0511 -- Train acc: 0.9756 -- Val acc: 0.9097 -- Test acc: 0.9106 -- Gen gap 0.0650\n",
      "Epoch 97/100\n",
      "Avg loss: 0.0505 -- Train acc: 0.9756 -- Val acc: 0.9098 -- Test acc: 0.9103 -- Gen gap 0.0653\n",
      "Epoch 98/100\n",
      "Avg loss: 0.0500 -- Train acc: 0.9756 -- Val acc: 0.9091 -- Test acc: 0.9100 -- Gen gap 0.0656\n",
      "Epoch 99/100\n",
      "Avg loss: 0.0491 -- Train acc: 0.9756 -- Val acc: 0.9097 -- Test acc: 0.9099 -- Gen gap 0.0657\n",
      "Epoch 100/100\n",
      "Avg loss: 0.0490 -- Train acc: 0.9756 -- Val acc: 0.9106 -- Test acc: 0.9103 -- Gen gap 0.0653\n",
      "Training done! Elapsed time: 0:00:17\n",
      "\n",
      "Iter 3\n",
      "Epoch 1/100\n",
      "Avg loss: 0.2884 -- Train acc: 0.9141 -- Val acc: 0.9105 -- Test acc: 0.9108 -- Gen gap 0.0032\n",
      "Epoch 2/100\n",
      "Avg loss: 0.2659 -- Train acc: 0.9199 -- Val acc: 0.9125 -- Test acc: 0.9108 -- Gen gap 0.0091\n",
      "Epoch 3/100\n",
      "Avg loss: 0.2580 -- Train acc: 0.9189 -- Val acc: 0.9147 -- Test acc: 0.9121 -- Gen gap 0.0068\n",
      "Epoch 4/100\n",
      "Avg loss: 0.2450 -- Train acc: 0.9209 -- Val acc: 0.9153 -- Test acc: 0.9118 -- Gen gap 0.0091\n",
      "Epoch 5/100\n",
      "Avg loss: 0.2346 -- Train acc: 0.9229 -- Val acc: 0.9166 -- Test acc: 0.9134 -- Gen gap 0.0094\n",
      "Epoch 6/100\n",
      "Avg loss: 0.2195 -- Train acc: 0.9258 -- Val acc: 0.9166 -- Test acc: 0.9137 -- Gen gap 0.0121\n",
      "Epoch 7/100\n",
      "Avg loss: 0.2151 -- Train acc: 0.9277 -- Val acc: 0.9164 -- Test acc: 0.9132 -- Gen gap 0.0145\n",
      "Epoch 8/100\n",
      "Avg loss: 0.2027 -- Train acc: 0.9297 -- Val acc: 0.9172 -- Test acc: 0.9150 -- Gen gap 0.0147\n",
      "Epoch 9/100\n",
      "Avg loss: 0.2011 -- Train acc: 0.9336 -- Val acc: 0.9163 -- Test acc: 0.9142 -- Gen gap 0.0194\n",
      "Epoch 10/100\n",
      "Avg loss: 0.1871 -- Train acc: 0.9326 -- Val acc: 0.9178 -- Test acc: 0.9153 -- Gen gap 0.0173\n",
      "Epoch 11/100\n",
      "Avg loss: 0.1885 -- Train acc: 0.9375 -- Val acc: 0.9170 -- Test acc: 0.9152 -- Gen gap 0.0223\n",
      "Epoch 12/100\n",
      "Avg loss: 0.1799 -- Train acc: 0.9395 -- Val acc: 0.9156 -- Test acc: 0.9133 -- Gen gap 0.0261\n",
      "Epoch 13/100\n",
      "Avg loss: 0.1733 -- Train acc: 0.9463 -- Val acc: 0.9176 -- Test acc: 0.9150 -- Gen gap 0.0313\n",
      "Epoch 14/100\n",
      "Avg loss: 0.1713 -- Train acc: 0.9424 -- Val acc: 0.9186 -- Test acc: 0.9153 -- Gen gap 0.0271\n",
      "Epoch 15/100\n",
      "Avg loss: 0.1629 -- Train acc: 0.9434 -- Val acc: 0.9177 -- Test acc: 0.9155 -- Gen gap 0.0279\n",
      "Epoch 16/100\n",
      "Avg loss: 0.1642 -- Train acc: 0.9492 -- Val acc: 0.9179 -- Test acc: 0.9154 -- Gen gap 0.0338\n",
      "Epoch 17/100\n",
      "Avg loss: 0.1552 -- Train acc: 0.9512 -- Val acc: 0.9175 -- Test acc: 0.9156 -- Gen gap 0.0356\n",
      "Epoch 18/100\n",
      "Avg loss: 0.1495 -- Train acc: 0.9541 -- Val acc: 0.9182 -- Test acc: 0.9150 -- Gen gap 0.0391\n",
      "Epoch 19/100\n",
      "Avg loss: 0.1485 -- Train acc: 0.9531 -- Val acc: 0.9175 -- Test acc: 0.9143 -- Gen gap 0.0388\n",
      "Epoch 20/100\n",
      "Avg loss: 0.1430 -- Train acc: 0.9570 -- Val acc: 0.9190 -- Test acc: 0.9148 -- Gen gap 0.0422\n",
      "Epoch 21/100\n",
      "Avg loss: 0.1418 -- Train acc: 0.9561 -- Val acc: 0.9194 -- Test acc: 0.9155 -- Gen gap 0.0405\n",
      "Epoch 22/100\n",
      "Avg loss: 0.1367 -- Train acc: 0.9551 -- Val acc: 0.9174 -- Test acc: 0.9147 -- Gen gap 0.0404\n",
      "Epoch 23/100\n",
      "Avg loss: 0.1344 -- Train acc: 0.9541 -- Val acc: 0.9194 -- Test acc: 0.9148 -- Gen gap 0.0393\n",
      "Epoch 24/100\n",
      "Avg loss: 0.1331 -- Train acc: 0.9561 -- Val acc: 0.9173 -- Test acc: 0.9150 -- Gen gap 0.0410\n",
      "Epoch 25/100\n",
      "Avg loss: 0.1285 -- Train acc: 0.9580 -- Val acc: 0.9193 -- Test acc: 0.9152 -- Gen gap 0.0428\n",
      "Epoch 26/100\n",
      "Avg loss: 0.1257 -- Train acc: 0.9570 -- Val acc: 0.9180 -- Test acc: 0.9150 -- Gen gap 0.0420\n",
      "Epoch 27/100\n",
      "Avg loss: 0.1239 -- Train acc: 0.9580 -- Val acc: 0.9184 -- Test acc: 0.9149 -- Gen gap 0.0431\n",
      "Epoch 28/100\n",
      "Avg loss: 0.1186 -- Train acc: 0.9580 -- Val acc: 0.9189 -- Test acc: 0.9147 -- Gen gap 0.0433\n",
      "Epoch 29/100\n",
      "Avg loss: 0.1192 -- Train acc: 0.9600 -- Val acc: 0.9180 -- Test acc: 0.9141 -- Gen gap 0.0458\n",
      "Epoch 30/100\n",
      "Avg loss: 0.1188 -- Train acc: 0.9600 -- Val acc: 0.9184 -- Test acc: 0.9141 -- Gen gap 0.0458\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.1121 -- Train acc: 0.9590 -- Val acc: 0.9188 -- Test acc: 0.9154 -- Gen gap 0.0436\n",
      "Epoch 32/100\n",
      "Avg loss: 0.1102 -- Train acc: 0.9609 -- Val acc: 0.9187 -- Test acc: 0.9154 -- Gen gap 0.0455\n",
      "Epoch 33/100\n",
      "Avg loss: 0.1107 -- Train acc: 0.9619 -- Val acc: 0.9188 -- Test acc: 0.9145 -- Gen gap 0.0474\n",
      "Epoch 34/100\n",
      "Avg loss: 0.1058 -- Train acc: 0.9639 -- Val acc: 0.9188 -- Test acc: 0.9148 -- Gen gap 0.0491\n",
      "Epoch 35/100\n",
      "Avg loss: 0.1034 -- Train acc: 0.9629 -- Val acc: 0.9187 -- Test acc: 0.9144 -- Gen gap 0.0485\n",
      "Epoch 36/100\n",
      "Avg loss: 0.1041 -- Train acc: 0.9639 -- Val acc: 0.9167 -- Test acc: 0.9145 -- Gen gap 0.0494\n",
      "Epoch 37/100\n",
      "Avg loss: 0.0989 -- Train acc: 0.9648 -- Val acc: 0.9191 -- Test acc: 0.9156 -- Gen gap 0.0492\n",
      "Epoch 38/100\n",
      "Avg loss: 0.0987 -- Train acc: 0.9639 -- Val acc: 0.9184 -- Test acc: 0.9157 -- Gen gap 0.0482\n",
      "Epoch 39/100\n",
      "Avg loss: 0.0958 -- Train acc: 0.9648 -- Val acc: 0.9185 -- Test acc: 0.9155 -- Gen gap 0.0493\n",
      "Epoch 40/100\n",
      "Avg loss: 0.0935 -- Train acc: 0.9639 -- Val acc: 0.9187 -- Test acc: 0.9141 -- Gen gap 0.0498\n",
      "Epoch 41/100\n",
      "Avg loss: 0.0915 -- Train acc: 0.9648 -- Val acc: 0.9199 -- Test acc: 0.9144 -- Gen gap 0.0504\n",
      "Epoch 42/100\n",
      "Avg loss: 0.0905 -- Train acc: 0.9648 -- Val acc: 0.9191 -- Test acc: 0.9151 -- Gen gap 0.0497\n",
      "Epoch 43/100\n",
      "Avg loss: 0.0885 -- Train acc: 0.9648 -- Val acc: 0.9185 -- Test acc: 0.9150 -- Gen gap 0.0498\n",
      "Epoch 44/100\n",
      "Avg loss: 0.0865 -- Train acc: 0.9648 -- Val acc: 0.9188 -- Test acc: 0.9151 -- Gen gap 0.0497\n",
      "Epoch 45/100\n",
      "Avg loss: 0.0854 -- Train acc: 0.9648 -- Val acc: 0.9185 -- Test acc: 0.9141 -- Gen gap 0.0507\n",
      "Epoch 46/100\n",
      "Avg loss: 0.0837 -- Train acc: 0.9648 -- Val acc: 0.9192 -- Test acc: 0.9145 -- Gen gap 0.0503\n",
      "Epoch 47/100\n",
      "Avg loss: 0.0822 -- Train acc: 0.9658 -- Val acc: 0.9188 -- Test acc: 0.9147 -- Gen gap 0.0511\n",
      "Epoch 48/100\n",
      "Avg loss: 0.0802 -- Train acc: 0.9658 -- Val acc: 0.9189 -- Test acc: 0.9150 -- Gen gap 0.0508\n",
      "Epoch 49/100\n",
      "Avg loss: 0.0782 -- Train acc: 0.9668 -- Val acc: 0.9199 -- Test acc: 0.9144 -- Gen gap 0.0524\n",
      "Epoch 50/100\n",
      "Avg loss: 0.0770 -- Train acc: 0.9668 -- Val acc: 0.9198 -- Test acc: 0.9143 -- Gen gap 0.0525\n",
      "Epoch 51/100\n",
      "Avg loss: 0.0764 -- Train acc: 0.9668 -- Val acc: 0.9182 -- Test acc: 0.9150 -- Gen gap 0.0518\n",
      "Epoch 52/100\n",
      "Avg loss: 0.0747 -- Train acc: 0.9668 -- Val acc: 0.9198 -- Test acc: 0.9144 -- Gen gap 0.0524\n",
      "Epoch 53/100\n",
      "Avg loss: 0.0738 -- Train acc: 0.9678 -- Val acc: 0.9190 -- Test acc: 0.9139 -- Gen gap 0.0539\n",
      "Epoch 54/100\n",
      "Avg loss: 0.0718 -- Train acc: 0.9678 -- Val acc: 0.9193 -- Test acc: 0.9146 -- Gen gap 0.0532\n",
      "Epoch 55/100\n",
      "Avg loss: 0.0717 -- Train acc: 0.9688 -- Val acc: 0.9186 -- Test acc: 0.9139 -- Gen gap 0.0548\n",
      "Epoch 56/100\n",
      "Avg loss: 0.0700 -- Train acc: 0.9688 -- Val acc: 0.9199 -- Test acc: 0.9141 -- Gen gap 0.0546\n",
      "Epoch 57/100\n",
      "Avg loss: 0.0688 -- Train acc: 0.9697 -- Val acc: 0.9189 -- Test acc: 0.9141 -- Gen gap 0.0556\n",
      "Epoch 58/100\n",
      "Avg loss: 0.0674 -- Train acc: 0.9688 -- Val acc: 0.9183 -- Test acc: 0.9136 -- Gen gap 0.0551\n",
      "Epoch 59/100\n",
      "Avg loss: 0.0667 -- Train acc: 0.9688 -- Val acc: 0.9192 -- Test acc: 0.9139 -- Gen gap 0.0548\n",
      "Epoch 60/100\n",
      "Avg loss: 0.0657 -- Train acc: 0.9688 -- Val acc: 0.9185 -- Test acc: 0.9143 -- Gen gap 0.0544\n",
      "Epoch 61/100\n",
      "Avg loss: 0.0640 -- Train acc: 0.9697 -- Val acc: 0.9192 -- Test acc: 0.9139 -- Gen gap 0.0558\n",
      "Epoch 62/100\n",
      "Avg loss: 0.0622 -- Train acc: 0.9697 -- Val acc: 0.9191 -- Test acc: 0.9138 -- Gen gap 0.0559\n",
      "Epoch 63/100\n",
      "Avg loss: 0.0626 -- Train acc: 0.9697 -- Val acc: 0.9183 -- Test acc: 0.9138 -- Gen gap 0.0559\n",
      "Epoch 64/100\n",
      "Avg loss: 0.0605 -- Train acc: 0.9707 -- Val acc: 0.9181 -- Test acc: 0.9136 -- Gen gap 0.0571\n",
      "Epoch 65/100\n",
      "Avg loss: 0.0602 -- Train acc: 0.9707 -- Val acc: 0.9179 -- Test acc: 0.9138 -- Gen gap 0.0569\n",
      "Epoch 66/100\n",
      "Avg loss: 0.0584 -- Train acc: 0.9707 -- Val acc: 0.9189 -- Test acc: 0.9139 -- Gen gap 0.0568\n",
      "Epoch 67/100\n",
      "Avg loss: 0.0585 -- Train acc: 0.9717 -- Val acc: 0.9191 -- Test acc: 0.9134 -- Gen gap 0.0583\n",
      "Epoch 68/100\n",
      "Avg loss: 0.0577 -- Train acc: 0.9707 -- Val acc: 0.9186 -- Test acc: 0.9140 -- Gen gap 0.0567\n",
      "Epoch 69/100\n",
      "Avg loss: 0.0556 -- Train acc: 0.9707 -- Val acc: 0.9193 -- Test acc: 0.9135 -- Gen gap 0.0572\n",
      "Epoch 70/100\n",
      "Avg loss: 0.0564 -- Train acc: 0.9707 -- Val acc: 0.9180 -- Test acc: 0.9137 -- Gen gap 0.0570\n",
      "Epoch 71/100\n",
      "Avg loss: 0.0538 -- Train acc: 0.9707 -- Val acc: 0.9188 -- Test acc: 0.9142 -- Gen gap 0.0565\n",
      "Epoch 72/100\n",
      "Avg loss: 0.0544 -- Train acc: 0.9717 -- Val acc: 0.9185 -- Test acc: 0.9136 -- Gen gap 0.0581\n",
      "Epoch 73/100\n",
      "Avg loss: 0.0529 -- Train acc: 0.9717 -- Val acc: 0.9175 -- Test acc: 0.9134 -- Gen gap 0.0583\n",
      "Epoch 74/100\n",
      "Avg loss: 0.0528 -- Train acc: 0.9736 -- Val acc: 0.9173 -- Test acc: 0.9131 -- Gen gap 0.0605\n",
      "Epoch 75/100\n",
      "Avg loss: 0.0507 -- Train acc: 0.9727 -- Val acc: 0.9190 -- Test acc: 0.9138 -- Gen gap 0.0588\n",
      "Epoch 76/100\n",
      "Avg loss: 0.0508 -- Train acc: 0.9736 -- Val acc: 0.9180 -- Test acc: 0.9136 -- Gen gap 0.0600\n",
      "Epoch 77/100\n",
      "Avg loss: 0.0494 -- Train acc: 0.9736 -- Val acc: 0.9187 -- Test acc: 0.9135 -- Gen gap 0.0601\n",
      "Epoch 78/100\n",
      "Avg loss: 0.0494 -- Train acc: 0.9736 -- Val acc: 0.9193 -- Test acc: 0.9133 -- Gen gap 0.0603\n",
      "Epoch 79/100\n",
      "Avg loss: 0.0481 -- Train acc: 0.9736 -- Val acc: 0.9186 -- Test acc: 0.9130 -- Gen gap 0.0606\n",
      "Epoch 80/100\n",
      "Avg loss: 0.0475 -- Train acc: 0.9727 -- Val acc: 0.9196 -- Test acc: 0.9138 -- Gen gap 0.0588\n",
      "Epoch 81/100\n",
      "Avg loss: 0.0486 -- Train acc: 0.9746 -- Val acc: 0.9184 -- Test acc: 0.9135 -- Gen gap 0.0611\n",
      "Epoch 82/100\n",
      "Avg loss: 0.0469 -- Train acc: 0.9746 -- Val acc: 0.9180 -- Test acc: 0.9127 -- Gen gap 0.0619\n",
      "Epoch 83/100\n",
      "Avg loss: 0.0453 -- Train acc: 0.9746 -- Val acc: 0.9189 -- Test acc: 0.9129 -- Gen gap 0.0617\n",
      "Epoch 84/100\n",
      "Avg loss: 0.0453 -- Train acc: 0.9746 -- Val acc: 0.9195 -- Test acc: 0.9135 -- Gen gap 0.0611\n",
      "Epoch 85/100\n",
      "Avg loss: 0.0440 -- Train acc: 0.9746 -- Val acc: 0.9190 -- Test acc: 0.9134 -- Gen gap 0.0612\n",
      "Epoch 86/100\n",
      "Avg loss: 0.0443 -- Train acc: 0.9746 -- Val acc: 0.9176 -- Test acc: 0.9136 -- Gen gap 0.0610\n",
      "Epoch 87/100\n",
      "Avg loss: 0.0435 -- Train acc: 0.9746 -- Val acc: 0.9197 -- Test acc: 0.9136 -- Gen gap 0.0610\n",
      "Epoch 88/100\n",
      "Avg loss: 0.0429 -- Train acc: 0.9746 -- Val acc: 0.9201 -- Test acc: 0.9143 -- Gen gap 0.0603\n",
      "Epoch 89/100\n",
      "Avg loss: 0.0419 -- Train acc: 0.9746 -- Val acc: 0.9196 -- Test acc: 0.9143 -- Gen gap 0.0603\n",
      "Epoch 90/100\n",
      "Avg loss: 0.0422 -- Train acc: 0.9746 -- Val acc: 0.9193 -- Test acc: 0.9138 -- Gen gap 0.0608\n",
      "Epoch 91/100\n",
      "Avg loss: 0.0407 -- Train acc: 0.9746 -- Val acc: 0.9190 -- Test acc: 0.9136 -- Gen gap 0.0610\n",
      "Epoch 92/100\n",
      "Avg loss: 0.0404 -- Train acc: 0.9756 -- Val acc: 0.9196 -- Test acc: 0.9137 -- Gen gap 0.0619\n",
      "Epoch 93/100\n",
      "Avg loss: 0.0397 -- Train acc: 0.9756 -- Val acc: 0.9196 -- Test acc: 0.9138 -- Gen gap 0.0618\n",
      "Epoch 94/100\n",
      "Avg loss: 0.0393 -- Train acc: 0.9756 -- Val acc: 0.9190 -- Test acc: 0.9133 -- Gen gap 0.0623\n",
      "Epoch 95/100\n",
      "Avg loss: 0.0393 -- Train acc: 0.9756 -- Val acc: 0.9200 -- Test acc: 0.9143 -- Gen gap 0.0613\n",
      "Epoch 96/100\n",
      "Avg loss: 0.0386 -- Train acc: 0.9756 -- Val acc: 0.9195 -- Test acc: 0.9137 -- Gen gap 0.0619\n",
      "Epoch 97/100\n",
      "Avg loss: 0.0379 -- Train acc: 0.9756 -- Val acc: 0.9189 -- Test acc: 0.9132 -- Gen gap 0.0624\n",
      "Epoch 98/100\n",
      "Avg loss: 0.0380 -- Train acc: 0.9756 -- Val acc: 0.9192 -- Test acc: 0.9132 -- Gen gap 0.0624\n",
      "Epoch 99/100\n",
      "Avg loss: 0.0375 -- Train acc: 0.9766 -- Val acc: 0.9191 -- Test acc: 0.9134 -- Gen gap 0.0631\n",
      "Epoch 100/100\n",
      "Avg loss: 0.0374 -- Train acc: 0.9756 -- Val acc: 0.9192 -- Test acc: 0.9145 -- Gen gap 0.0611\n",
      "Training done! Elapsed time: 0:00:17\n",
      "\n",
      "==============================\n",
      "a = 0.05, Na = 2500\n",
      "------------------------------\n",
      "Iter 1\n",
      "Epoch 1/100\n",
      "Avg loss: 0.2710 -- Train acc: 0.9051 -- Val acc: 0.9215 -- Test acc: 0.9165 -- Gen gap -0.0114\n",
      "Epoch 2/100\n",
      "Avg loss: 0.2569 -- Train acc: 0.9102 -- Val acc: 0.9259 -- Test acc: 0.9201 -- Gen gap -0.0099\n",
      "Epoch 3/100\n",
      "Avg loss: 0.2315 -- Train acc: 0.9141 -- Val acc: 0.9285 -- Test acc: 0.9232 -- Gen gap -0.0091\n",
      "Epoch 4/100\n",
      "Avg loss: 0.2220 -- Train acc: 0.9047 -- Val acc: 0.9162 -- Test acc: 0.9098 -- Gen gap -0.0051\n",
      "Epoch 5/100\n",
      "Avg loss: 0.2127 -- Train acc: 0.9203 -- Val acc: 0.9288 -- Test acc: 0.9235 -- Gen gap -0.0032\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.1943 -- Train acc: 0.9211 -- Val acc: 0.9271 -- Test acc: 0.9213 -- Gen gap -0.0002\n",
      "Epoch 7/100\n",
      "Avg loss: 0.1843 -- Train acc: 0.9273 -- Val acc: 0.9306 -- Test acc: 0.9264 -- Gen gap 0.0010\n",
      "Epoch 8/100\n",
      "Avg loss: 0.1767 -- Train acc: 0.9309 -- Val acc: 0.9318 -- Test acc: 0.9259 -- Gen gap 0.0050\n",
      "Epoch 9/100\n",
      "Avg loss: 0.1704 -- Train acc: 0.9320 -- Val acc: 0.9303 -- Test acc: 0.9259 -- Gen gap 0.0062\n",
      "Epoch 10/100\n",
      "Avg loss: 0.1646 -- Train acc: 0.9355 -- Val acc: 0.9326 -- Test acc: 0.9271 -- Gen gap 0.0084\n",
      "Epoch 11/100\n",
      "Avg loss: 0.1625 -- Train acc: 0.9352 -- Val acc: 0.9315 -- Test acc: 0.9274 -- Gen gap 0.0077\n",
      "Epoch 12/100\n",
      "Avg loss: 0.1532 -- Train acc: 0.9402 -- Val acc: 0.9332 -- Test acc: 0.9279 -- Gen gap 0.0123\n",
      "Epoch 13/100\n",
      "Avg loss: 0.1472 -- Train acc: 0.9414 -- Val acc: 0.9318 -- Test acc: 0.9280 -- Gen gap 0.0134\n",
      "Epoch 14/100\n",
      "Avg loss: 0.1430 -- Train acc: 0.9410 -- Val acc: 0.9322 -- Test acc: 0.9278 -- Gen gap 0.0132\n",
      "Epoch 15/100\n",
      "Avg loss: 0.1457 -- Train acc: 0.9332 -- Val acc: 0.9256 -- Test acc: 0.9218 -- Gen gap 0.0114\n",
      "Epoch 16/100\n",
      "Avg loss: 0.1359 -- Train acc: 0.9465 -- Val acc: 0.9340 -- Test acc: 0.9296 -- Gen gap 0.0168\n",
      "Epoch 17/100\n",
      "Avg loss: 0.1308 -- Train acc: 0.9453 -- Val acc: 0.9332 -- Test acc: 0.9292 -- Gen gap 0.0161\n",
      "Epoch 18/100\n",
      "Avg loss: 0.1272 -- Train acc: 0.9477 -- Val acc: 0.9341 -- Test acc: 0.9296 -- Gen gap 0.0180\n",
      "Epoch 19/100\n",
      "Avg loss: 0.1272 -- Train acc: 0.9484 -- Val acc: 0.9314 -- Test acc: 0.9291 -- Gen gap 0.0193\n",
      "Epoch 20/100\n",
      "Avg loss: 0.1220 -- Train acc: 0.9469 -- Val acc: 0.9322 -- Test acc: 0.9283 -- Gen gap 0.0185\n",
      "Epoch 21/100\n",
      "Avg loss: 0.1217 -- Train acc: 0.9473 -- Val acc: 0.9316 -- Test acc: 0.9279 -- Gen gap 0.0193\n",
      "Epoch 22/100\n",
      "Avg loss: 0.1201 -- Train acc: 0.9414 -- Val acc: 0.9314 -- Test acc: 0.9278 -- Gen gap 0.0136\n",
      "Epoch 23/100\n",
      "Avg loss: 0.1166 -- Train acc: 0.9527 -- Val acc: 0.9349 -- Test acc: 0.9313 -- Gen gap 0.0214\n",
      "Epoch 24/100\n",
      "Avg loss: 0.1110 -- Train acc: 0.9523 -- Val acc: 0.9335 -- Test acc: 0.9315 -- Gen gap 0.0208\n",
      "Epoch 25/100\n",
      "Avg loss: 0.1063 -- Train acc: 0.9539 -- Val acc: 0.9340 -- Test acc: 0.9310 -- Gen gap 0.0229\n",
      "Epoch 26/100\n",
      "Avg loss: 0.1040 -- Train acc: 0.9543 -- Val acc: 0.9344 -- Test acc: 0.9318 -- Gen gap 0.0225\n",
      "Epoch 27/100\n",
      "Avg loss: 0.1055 -- Train acc: 0.9531 -- Val acc: 0.9326 -- Test acc: 0.9268 -- Gen gap 0.0264\n",
      "Epoch 28/100\n",
      "Avg loss: 0.1015 -- Train acc: 0.9539 -- Val acc: 0.9327 -- Test acc: 0.9294 -- Gen gap 0.0245\n",
      "Epoch 29/100\n",
      "Avg loss: 0.0973 -- Train acc: 0.9570 -- Val acc: 0.9347 -- Test acc: 0.9313 -- Gen gap 0.0257\n",
      "Epoch 30/100\n",
      "Avg loss: 0.0948 -- Train acc: 0.9578 -- Val acc: 0.9341 -- Test acc: 0.9306 -- Gen gap 0.0272\n",
      "Epoch 31/100\n",
      "Avg loss: 0.0923 -- Train acc: 0.9582 -- Val acc: 0.9352 -- Test acc: 0.9304 -- Gen gap 0.0278\n",
      "Epoch 32/100\n",
      "Avg loss: 0.0901 -- Train acc: 0.9586 -- Val acc: 0.9336 -- Test acc: 0.9309 -- Gen gap 0.0277\n",
      "Epoch 33/100\n",
      "Avg loss: 0.0888 -- Train acc: 0.9586 -- Val acc: 0.9336 -- Test acc: 0.9309 -- Gen gap 0.0277\n",
      "Epoch 34/100\n",
      "Avg loss: 0.0871 -- Train acc: 0.9605 -- Val acc: 0.9340 -- Test acc: 0.9315 -- Gen gap 0.0290\n",
      "Epoch 35/100\n",
      "Avg loss: 0.0860 -- Train acc: 0.9605 -- Val acc: 0.9346 -- Test acc: 0.9311 -- Gen gap 0.0294\n",
      "Epoch 36/100\n",
      "Avg loss: 0.0836 -- Train acc: 0.9617 -- Val acc: 0.9346 -- Test acc: 0.9309 -- Gen gap 0.0308\n",
      "Epoch 37/100\n",
      "Avg loss: 0.0818 -- Train acc: 0.9617 -- Val acc: 0.9333 -- Test acc: 0.9319 -- Gen gap 0.0298\n",
      "Epoch 38/100\n",
      "Avg loss: 0.0810 -- Train acc: 0.9625 -- Val acc: 0.9353 -- Test acc: 0.9316 -- Gen gap 0.0309\n",
      "Epoch 39/100\n",
      "Avg loss: 0.0794 -- Train acc: 0.9625 -- Val acc: 0.9354 -- Test acc: 0.9317 -- Gen gap 0.0308\n",
      "Epoch 40/100\n",
      "Avg loss: 0.0795 -- Train acc: 0.9609 -- Val acc: 0.9328 -- Test acc: 0.9292 -- Gen gap 0.0317\n",
      "Epoch 41/100\n",
      "Avg loss: 0.0783 -- Train acc: 0.9645 -- Val acc: 0.9356 -- Test acc: 0.9310 -- Gen gap 0.0334\n",
      "Epoch 42/100\n",
      "Avg loss: 0.0754 -- Train acc: 0.9652 -- Val acc: 0.9357 -- Test acc: 0.9319 -- Gen gap 0.0333\n",
      "Epoch 43/100\n",
      "Avg loss: 0.0738 -- Train acc: 0.9652 -- Val acc: 0.9352 -- Test acc: 0.9320 -- Gen gap 0.0332\n",
      "Epoch 44/100\n",
      "Avg loss: 0.0717 -- Train acc: 0.9660 -- Val acc: 0.9344 -- Test acc: 0.9319 -- Gen gap 0.0341\n",
      "Epoch 45/100\n",
      "Avg loss: 0.0701 -- Train acc: 0.9668 -- Val acc: 0.9354 -- Test acc: 0.9307 -- Gen gap 0.0361\n",
      "Epoch 46/100\n",
      "Avg loss: 0.0695 -- Train acc: 0.9680 -- Val acc: 0.9357 -- Test acc: 0.9312 -- Gen gap 0.0367\n",
      "Epoch 47/100\n",
      "Avg loss: 0.0681 -- Train acc: 0.9684 -- Val acc: 0.9347 -- Test acc: 0.9307 -- Gen gap 0.0376\n",
      "Epoch 48/100\n",
      "Avg loss: 0.0669 -- Train acc: 0.9684 -- Val acc: 0.9360 -- Test acc: 0.9315 -- Gen gap 0.0368\n",
      "Epoch 49/100\n",
      "Avg loss: 0.0654 -- Train acc: 0.9684 -- Val acc: 0.9352 -- Test acc: 0.9319 -- Gen gap 0.0364\n",
      "Epoch 50/100\n",
      "Avg loss: 0.0669 -- Train acc: 0.9668 -- Val acc: 0.9343 -- Test acc: 0.9316 -- Gen gap 0.0352\n",
      "Epoch 51/100\n",
      "Avg loss: 0.0632 -- Train acc: 0.9680 -- Val acc: 0.9357 -- Test acc: 0.9314 -- Gen gap 0.0365\n",
      "Epoch 52/100\n",
      "Avg loss: 0.0628 -- Train acc: 0.9699 -- Val acc: 0.9354 -- Test acc: 0.9309 -- Gen gap 0.0390\n",
      "Epoch 53/100\n",
      "Avg loss: 0.0611 -- Train acc: 0.9691 -- Val acc: 0.9351 -- Test acc: 0.9325 -- Gen gap 0.0366\n",
      "Epoch 54/100\n",
      "Avg loss: 0.0609 -- Train acc: 0.9695 -- Val acc: 0.9331 -- Test acc: 0.9322 -- Gen gap 0.0373\n",
      "Epoch 55/100\n",
      "Avg loss: 0.0607 -- Train acc: 0.9691 -- Val acc: 0.9351 -- Test acc: 0.9323 -- Gen gap 0.0368\n",
      "Epoch 56/100\n",
      "Avg loss: 0.0667 -- Train acc: 0.9602 -- Val acc: 0.9305 -- Test acc: 0.9271 -- Gen gap 0.0330\n",
      "Epoch 57/100\n",
      "Avg loss: 0.0622 -- Train acc: 0.9703 -- Val acc: 0.9341 -- Test acc: 0.9306 -- Gen gap 0.0397\n",
      "Epoch 58/100\n",
      "Avg loss: 0.0570 -- Train acc: 0.9707 -- Val acc: 0.9352 -- Test acc: 0.9306 -- Gen gap 0.0401\n",
      "Epoch 59/100\n",
      "Avg loss: 0.0555 -- Train acc: 0.9707 -- Val acc: 0.9348 -- Test acc: 0.9319 -- Gen gap 0.0388\n",
      "Epoch 60/100\n",
      "Avg loss: 0.0549 -- Train acc: 0.9707 -- Val acc: 0.9360 -- Test acc: 0.9315 -- Gen gap 0.0392\n",
      "Epoch 61/100\n",
      "Avg loss: 0.0538 -- Train acc: 0.9711 -- Val acc: 0.9350 -- Test acc: 0.9311 -- Gen gap 0.0400\n",
      "Epoch 62/100\n",
      "Avg loss: 0.0548 -- Train acc: 0.9711 -- Val acc: 0.9346 -- Test acc: 0.9303 -- Gen gap 0.0408\n",
      "Epoch 63/100\n",
      "Avg loss: 0.0534 -- Train acc: 0.9723 -- Val acc: 0.9349 -- Test acc: 0.9315 -- Gen gap 0.0407\n",
      "Epoch 64/100\n",
      "Avg loss: 0.0532 -- Train acc: 0.9691 -- Val acc: 0.9325 -- Test acc: 0.9302 -- Gen gap 0.0389\n",
      "Epoch 65/100\n",
      "Avg loss: 0.0513 -- Train acc: 0.9719 -- Val acc: 0.9361 -- Test acc: 0.9312 -- Gen gap 0.0406\n",
      "Epoch 66/100\n",
      "Avg loss: 0.0522 -- Train acc: 0.9691 -- Val acc: 0.9335 -- Test acc: 0.9312 -- Gen gap 0.0379\n",
      "Epoch 67/100\n",
      "Avg loss: 0.0501 -- Train acc: 0.9719 -- Val acc: 0.9359 -- Test acc: 0.9318 -- Gen gap 0.0400\n",
      "Epoch 68/100\n",
      "Avg loss: 0.0488 -- Train acc: 0.9719 -- Val acc: 0.9349 -- Test acc: 0.9317 -- Gen gap 0.0401\n",
      "Epoch 69/100\n",
      "Avg loss: 0.0487 -- Train acc: 0.9723 -- Val acc: 0.9354 -- Test acc: 0.9322 -- Gen gap 0.0400\n",
      "Epoch 70/100\n",
      "Avg loss: 0.0477 -- Train acc: 0.9734 -- Val acc: 0.9366 -- Test acc: 0.9315 -- Gen gap 0.0419\n",
      "Epoch 71/100\n",
      "Avg loss: 0.0472 -- Train acc: 0.9727 -- Val acc: 0.9364 -- Test acc: 0.9316 -- Gen gap 0.0410\n",
      "Epoch 72/100\n",
      "Avg loss: 0.0457 -- Train acc: 0.9730 -- Val acc: 0.9364 -- Test acc: 0.9322 -- Gen gap 0.0408\n",
      "Epoch 73/100\n",
      "Avg loss: 0.0472 -- Train acc: 0.9734 -- Val acc: 0.9361 -- Test acc: 0.9311 -- Gen gap 0.0423\n",
      "Epoch 74/100\n",
      "Avg loss: 0.0445 -- Train acc: 0.9730 -- Val acc: 0.9360 -- Test acc: 0.9313 -- Gen gap 0.0417\n",
      "Epoch 75/100\n",
      "Avg loss: 0.0436 -- Train acc: 0.9730 -- Val acc: 0.9357 -- Test acc: 0.9317 -- Gen gap 0.0413\n",
      "Epoch 76/100\n",
      "Avg loss: 0.0438 -- Train acc: 0.9738 -- Val acc: 0.9367 -- Test acc: 0.9314 -- Gen gap 0.0424\n",
      "Epoch 77/100\n",
      "Avg loss: 0.0426 -- Train acc: 0.9734 -- Val acc: 0.9368 -- Test acc: 0.9318 -- Gen gap 0.0416\n",
      "Epoch 78/100\n",
      "Avg loss: 0.0432 -- Train acc: 0.9734 -- Val acc: 0.9367 -- Test acc: 0.9324 -- Gen gap 0.0410\n",
      "Epoch 79/100\n",
      "Avg loss: 0.0418 -- Train acc: 0.9738 -- Val acc: 0.9351 -- Test acc: 0.9322 -- Gen gap 0.0416\n",
      "Epoch 80/100\n",
      "Avg loss: 0.0407 -- Train acc: 0.9738 -- Val acc: 0.9363 -- Test acc: 0.9314 -- Gen gap 0.0424\n",
      "Epoch 81/100\n",
      "Avg loss: 0.0408 -- Train acc: 0.9734 -- Val acc: 0.9360 -- Test acc: 0.9319 -- Gen gap 0.0415\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.0400 -- Train acc: 0.9734 -- Val acc: 0.9364 -- Test acc: 0.9318 -- Gen gap 0.0416\n",
      "Epoch 83/100\n",
      "Avg loss: 0.0398 -- Train acc: 0.9738 -- Val acc: 0.9359 -- Test acc: 0.9317 -- Gen gap 0.0421\n",
      "Epoch 84/100\n",
      "Avg loss: 0.0399 -- Train acc: 0.9738 -- Val acc: 0.9353 -- Test acc: 0.9321 -- Gen gap 0.0417\n",
      "Epoch 85/100\n",
      "Avg loss: 0.0388 -- Train acc: 0.9738 -- Val acc: 0.9365 -- Test acc: 0.9319 -- Gen gap 0.0419\n",
      "Epoch 86/100\n",
      "Avg loss: 0.0379 -- Train acc: 0.9738 -- Val acc: 0.9359 -- Test acc: 0.9322 -- Gen gap 0.0416\n",
      "Epoch 87/100\n",
      "Avg loss: 0.0373 -- Train acc: 0.9738 -- Val acc: 0.9367 -- Test acc: 0.9319 -- Gen gap 0.0419\n",
      "Epoch 88/100\n",
      "Avg loss: 0.0369 -- Train acc: 0.9738 -- Val acc: 0.9364 -- Test acc: 0.9313 -- Gen gap 0.0425\n",
      "Epoch 89/100\n",
      "Avg loss: 0.0367 -- Train acc: 0.9734 -- Val acc: 0.9353 -- Test acc: 0.9315 -- Gen gap 0.0419\n",
      "Epoch 90/100\n",
      "Avg loss: 0.0365 -- Train acc: 0.9730 -- Val acc: 0.9351 -- Test acc: 0.9310 -- Gen gap 0.0420\n",
      "Epoch 91/100\n",
      "Avg loss: 0.0357 -- Train acc: 0.9742 -- Val acc: 0.9365 -- Test acc: 0.9312 -- Gen gap 0.0430\n",
      "Epoch 92/100\n",
      "Avg loss: 0.0361 -- Train acc: 0.9734 -- Val acc: 0.9337 -- Test acc: 0.9299 -- Gen gap 0.0435\n",
      "Epoch 93/100\n",
      "Avg loss: 0.0349 -- Train acc: 0.9746 -- Val acc: 0.9363 -- Test acc: 0.9321 -- Gen gap 0.0425\n",
      "Epoch 94/100\n",
      "Avg loss: 0.0357 -- Train acc: 0.9742 -- Val acc: 0.9370 -- Test acc: 0.9317 -- Gen gap 0.0425\n",
      "Epoch 95/100\n",
      "Avg loss: 0.0340 -- Train acc: 0.9750 -- Val acc: 0.9362 -- Test acc: 0.9318 -- Gen gap 0.0432\n",
      "Epoch 96/100\n",
      "Avg loss: 0.0341 -- Train acc: 0.9750 -- Val acc: 0.9360 -- Test acc: 0.9310 -- Gen gap 0.0440\n",
      "Epoch 97/100\n",
      "Avg loss: 0.0328 -- Train acc: 0.9750 -- Val acc: 0.9369 -- Test acc: 0.9318 -- Gen gap 0.0432\n",
      "Epoch 98/100\n",
      "Avg loss: 0.0339 -- Train acc: 0.9746 -- Val acc: 0.9349 -- Test acc: 0.9318 -- Gen gap 0.0428\n",
      "Epoch 99/100\n",
      "Avg loss: 0.0322 -- Train acc: 0.9750 -- Val acc: 0.9368 -- Test acc: 0.9317 -- Gen gap 0.0433\n",
      "Epoch 100/100\n",
      "Avg loss: 0.0336 -- Train acc: 0.9750 -- Val acc: 0.9353 -- Test acc: 0.9305 -- Gen gap 0.0445\n",
      "Training done! Elapsed time: 0:00:22\n",
      "\n",
      "Iter 2\n",
      "Epoch 1/100\n",
      "Avg loss: 0.2040 -- Train acc: 0.9250 -- Val acc: 0.9367 -- Test acc: 0.9334 -- Gen gap -0.0084\n",
      "Epoch 2/100\n",
      "Avg loss: 0.2278 -- Train acc: 0.9059 -- Val acc: 0.9175 -- Test acc: 0.9148 -- Gen gap -0.0089\n",
      "Epoch 3/100\n",
      "Avg loss: 0.1770 -- Train acc: 0.9348 -- Val acc: 0.9372 -- Test acc: 0.9332 -- Gen gap 0.0015\n",
      "Epoch 4/100\n",
      "Avg loss: 0.1585 -- Train acc: 0.9359 -- Val acc: 0.9381 -- Test acc: 0.9351 -- Gen gap 0.0008\n",
      "Epoch 5/100\n",
      "Avg loss: 0.1496 -- Train acc: 0.9383 -- Val acc: 0.9365 -- Test acc: 0.9350 -- Gen gap 0.0033\n",
      "Epoch 6/100\n",
      "Avg loss: 0.1395 -- Train acc: 0.9410 -- Val acc: 0.9381 -- Test acc: 0.9372 -- Gen gap 0.0038\n",
      "Epoch 7/100\n",
      "Avg loss: 0.1318 -- Train acc: 0.9441 -- Val acc: 0.9378 -- Test acc: 0.9366 -- Gen gap 0.0075\n",
      "Epoch 8/100\n",
      "Avg loss: 0.1263 -- Train acc: 0.9469 -- Val acc: 0.9383 -- Test acc: 0.9361 -- Gen gap 0.0108\n",
      "Epoch 9/100\n",
      "Avg loss: 0.1196 -- Train acc: 0.9465 -- Val acc: 0.9374 -- Test acc: 0.9361 -- Gen gap 0.0104\n",
      "Epoch 10/100\n",
      "Avg loss: 0.1133 -- Train acc: 0.9516 -- Val acc: 0.9398 -- Test acc: 0.9374 -- Gen gap 0.0142\n",
      "Epoch 11/100\n",
      "Avg loss: 0.1104 -- Train acc: 0.9523 -- Val acc: 0.9387 -- Test acc: 0.9371 -- Gen gap 0.0152\n",
      "Epoch 12/100\n",
      "Avg loss: 0.1052 -- Train acc: 0.9547 -- Val acc: 0.9381 -- Test acc: 0.9361 -- Gen gap 0.0186\n",
      "Epoch 13/100\n",
      "Avg loss: 0.1047 -- Train acc: 0.9543 -- Val acc: 0.9375 -- Test acc: 0.9353 -- Gen gap 0.0190\n",
      "Epoch 14/100\n",
      "Avg loss: 0.0977 -- Train acc: 0.9570 -- Val acc: 0.9382 -- Test acc: 0.9368 -- Gen gap 0.0202\n",
      "Epoch 15/100\n",
      "Avg loss: 0.1040 -- Train acc: 0.9465 -- Val acc: 0.9361 -- Test acc: 0.9343 -- Gen gap 0.0122\n",
      "Epoch 16/100\n",
      "Avg loss: 0.0968 -- Train acc: 0.9535 -- Val acc: 0.9363 -- Test acc: 0.9348 -- Gen gap 0.0187\n",
      "Epoch 17/100\n",
      "Avg loss: 0.0889 -- Train acc: 0.9574 -- Val acc: 0.9387 -- Test acc: 0.9381 -- Gen gap 0.0193\n",
      "Epoch 18/100\n",
      "Avg loss: 0.0850 -- Train acc: 0.9570 -- Val acc: 0.9392 -- Test acc: 0.9353 -- Gen gap 0.0217\n",
      "Epoch 19/100\n",
      "Avg loss: 0.0823 -- Train acc: 0.9602 -- Val acc: 0.9380 -- Test acc: 0.9369 -- Gen gap 0.0233\n",
      "Epoch 20/100\n",
      "Avg loss: 0.0795 -- Train acc: 0.9613 -- Val acc: 0.9384 -- Test acc: 0.9374 -- Gen gap 0.0239\n",
      "Epoch 21/100\n",
      "Avg loss: 0.0813 -- Train acc: 0.9563 -- Val acc: 0.9363 -- Test acc: 0.9314 -- Gen gap 0.0248\n",
      "Epoch 22/100\n",
      "Avg loss: 0.0787 -- Train acc: 0.9621 -- Val acc: 0.9388 -- Test acc: 0.9375 -- Gen gap 0.0246\n",
      "Epoch 23/100\n",
      "Avg loss: 0.0734 -- Train acc: 0.9621 -- Val acc: 0.9394 -- Test acc: 0.9362 -- Gen gap 0.0259\n",
      "Epoch 24/100\n",
      "Avg loss: 0.0711 -- Train acc: 0.9641 -- Val acc: 0.9386 -- Test acc: 0.9369 -- Gen gap 0.0272\n",
      "Epoch 25/100\n",
      "Avg loss: 0.0692 -- Train acc: 0.9637 -- Val acc: 0.9386 -- Test acc: 0.9366 -- Gen gap 0.0271\n",
      "Epoch 26/100\n",
      "Avg loss: 0.0673 -- Train acc: 0.9648 -- Val acc: 0.9386 -- Test acc: 0.9366 -- Gen gap 0.0282\n",
      "Epoch 27/100\n",
      "Avg loss: 0.0642 -- Train acc: 0.9645 -- Val acc: 0.9393 -- Test acc: 0.9380 -- Gen gap 0.0265\n",
      "Epoch 28/100\n",
      "Avg loss: 0.0633 -- Train acc: 0.9656 -- Val acc: 0.9390 -- Test acc: 0.9365 -- Gen gap 0.0291\n",
      "Epoch 29/100\n",
      "Avg loss: 0.0622 -- Train acc: 0.9652 -- Val acc: 0.9383 -- Test acc: 0.9361 -- Gen gap 0.0291\n",
      "Epoch 30/100\n",
      "Avg loss: 0.0591 -- Train acc: 0.9656 -- Val acc: 0.9387 -- Test acc: 0.9378 -- Gen gap 0.0278\n",
      "Epoch 31/100\n",
      "Avg loss: 0.0578 -- Train acc: 0.9656 -- Val acc: 0.9390 -- Test acc: 0.9389 -- Gen gap 0.0267\n",
      "Epoch 32/100\n",
      "Avg loss: 0.0565 -- Train acc: 0.9660 -- Val acc: 0.9385 -- Test acc: 0.9384 -- Gen gap 0.0276\n",
      "Epoch 33/100\n",
      "Avg loss: 0.0549 -- Train acc: 0.9668 -- Val acc: 0.9390 -- Test acc: 0.9370 -- Gen gap 0.0298\n",
      "Epoch 34/100\n",
      "Avg loss: 0.0535 -- Train acc: 0.9664 -- Val acc: 0.9386 -- Test acc: 0.9372 -- Gen gap 0.0292\n",
      "Epoch 35/100\n",
      "Avg loss: 0.0517 -- Train acc: 0.9688 -- Val acc: 0.9391 -- Test acc: 0.9373 -- Gen gap 0.0314\n",
      "Epoch 36/100\n",
      "Avg loss: 0.0513 -- Train acc: 0.9672 -- Val acc: 0.9388 -- Test acc: 0.9386 -- Gen gap 0.0286\n",
      "Epoch 37/100\n",
      "Avg loss: 0.0498 -- Train acc: 0.9684 -- Val acc: 0.9385 -- Test acc: 0.9373 -- Gen gap 0.0311\n",
      "Epoch 38/100\n",
      "Avg loss: 0.0487 -- Train acc: 0.9688 -- Val acc: 0.9392 -- Test acc: 0.9371 -- Gen gap 0.0316\n",
      "Epoch 39/100\n",
      "Avg loss: 0.0480 -- Train acc: 0.9695 -- Val acc: 0.9398 -- Test acc: 0.9380 -- Gen gap 0.0315\n",
      "Epoch 40/100\n",
      "Avg loss: 0.0471 -- Train acc: 0.9688 -- Val acc: 0.9390 -- Test acc: 0.9364 -- Gen gap 0.0323\n",
      "Epoch 41/100\n",
      "Avg loss: 0.0459 -- Train acc: 0.9699 -- Val acc: 0.9394 -- Test acc: 0.9376 -- Gen gap 0.0323\n",
      "Epoch 42/100\n",
      "Avg loss: 0.0446 -- Train acc: 0.9707 -- Val acc: 0.9383 -- Test acc: 0.9374 -- Gen gap 0.0333\n",
      "Epoch 43/100\n",
      "Avg loss: 0.0448 -- Train acc: 0.9691 -- Val acc: 0.9391 -- Test acc: 0.9358 -- Gen gap 0.0333\n",
      "Epoch 44/100\n",
      "Avg loss: 0.0459 -- Train acc: 0.9691 -- Val acc: 0.9386 -- Test acc: 0.9367 -- Gen gap 0.0324\n",
      "Epoch 45/100\n",
      "Avg loss: 0.0456 -- Train acc: 0.9703 -- Val acc: 0.9380 -- Test acc: 0.9369 -- Gen gap 0.0334\n",
      "Epoch 46/100\n",
      "Avg loss: 0.0428 -- Train acc: 0.9707 -- Val acc: 0.9397 -- Test acc: 0.9384 -- Gen gap 0.0323\n",
      "Epoch 47/100\n",
      "Avg loss: 0.0415 -- Train acc: 0.9723 -- Val acc: 0.9400 -- Test acc: 0.9371 -- Gen gap 0.0352\n",
      "Epoch 48/100\n",
      "Avg loss: 0.0393 -- Train acc: 0.9723 -- Val acc: 0.9396 -- Test acc: 0.9378 -- Gen gap 0.0345\n",
      "Epoch 49/100\n",
      "Avg loss: 0.0390 -- Train acc: 0.9730 -- Val acc: 0.9392 -- Test acc: 0.9371 -- Gen gap 0.0359\n",
      "Epoch 50/100\n",
      "Avg loss: 0.0380 -- Train acc: 0.9727 -- Val acc: 0.9396 -- Test acc: 0.9388 -- Gen gap 0.0339\n",
      "Epoch 51/100\n",
      "Avg loss: 0.0371 -- Train acc: 0.9734 -- Val acc: 0.9392 -- Test acc: 0.9385 -- Gen gap 0.0349\n",
      "Epoch 52/100\n",
      "Avg loss: 0.0374 -- Train acc: 0.9727 -- Val acc: 0.9394 -- Test acc: 0.9383 -- Gen gap 0.0344\n",
      "Epoch 53/100\n",
      "Avg loss: 0.0396 -- Train acc: 0.9715 -- Val acc: 0.9376 -- Test acc: 0.9342 -- Gen gap 0.0373\n",
      "Epoch 54/100\n",
      "Avg loss: 0.0368 -- Train acc: 0.9734 -- Val acc: 0.9393 -- Test acc: 0.9383 -- Gen gap 0.0351\n",
      "Epoch 55/100\n",
      "Avg loss: 0.0343 -- Train acc: 0.9738 -- Val acc: 0.9400 -- Test acc: 0.9384 -- Gen gap 0.0354\n",
      "Epoch 56/100\n",
      "Avg loss: 0.0380 -- Train acc: 0.9742 -- Val acc: 0.9390 -- Test acc: 0.9369 -- Gen gap 0.0373\n",
      "Epoch 57/100\n",
      "Avg loss: 0.0338 -- Train acc: 0.9742 -- Val acc: 0.9393 -- Test acc: 0.9376 -- Gen gap 0.0366\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.0327 -- Train acc: 0.9738 -- Val acc: 0.9398 -- Test acc: 0.9375 -- Gen gap 0.0363\n",
      "Epoch 59/100\n",
      "Avg loss: 0.0318 -- Train acc: 0.9742 -- Val acc: 0.9397 -- Test acc: 0.9371 -- Gen gap 0.0371\n",
      "Epoch 60/100\n",
      "Avg loss: 0.0317 -- Train acc: 0.9742 -- Val acc: 0.9397 -- Test acc: 0.9379 -- Gen gap 0.0363\n",
      "Epoch 61/100\n",
      "Avg loss: 0.0307 -- Train acc: 0.9742 -- Val acc: 0.9400 -- Test acc: 0.9379 -- Gen gap 0.0363\n",
      "Epoch 62/100\n",
      "Avg loss: 0.0310 -- Train acc: 0.9742 -- Val acc: 0.9393 -- Test acc: 0.9360 -- Gen gap 0.0382\n",
      "Epoch 63/100\n",
      "Avg loss: 0.0298 -- Train acc: 0.9742 -- Val acc: 0.9400 -- Test acc: 0.9374 -- Gen gap 0.0368\n",
      "Epoch 64/100\n",
      "Avg loss: 0.0299 -- Train acc: 0.9742 -- Val acc: 0.9397 -- Test acc: 0.9367 -- Gen gap 0.0375\n",
      "Epoch 65/100\n",
      "Avg loss: 0.0294 -- Train acc: 0.9746 -- Val acc: 0.9398 -- Test acc: 0.9376 -- Gen gap 0.0370\n",
      "Epoch 66/100\n",
      "Avg loss: 0.0295 -- Train acc: 0.9750 -- Val acc: 0.9397 -- Test acc: 0.9375 -- Gen gap 0.0375\n",
      "Epoch 67/100\n",
      "Avg loss: 0.0285 -- Train acc: 0.9746 -- Val acc: 0.9396 -- Test acc: 0.9367 -- Gen gap 0.0379\n",
      "Epoch 68/100\n",
      "Avg loss: 0.0279 -- Train acc: 0.9750 -- Val acc: 0.9404 -- Test acc: 0.9371 -- Gen gap 0.0379\n",
      "Epoch 69/100\n",
      "Avg loss: 0.0274 -- Train acc: 0.9746 -- Val acc: 0.9392 -- Test acc: 0.9363 -- Gen gap 0.0383\n",
      "Epoch 70/100\n",
      "Avg loss: 0.0295 -- Train acc: 0.9680 -- Val acc: 0.9339 -- Test acc: 0.9352 -- Gen gap 0.0328\n",
      "Epoch 71/100\n",
      "Avg loss: 0.0298 -- Train acc: 0.9746 -- Val acc: 0.9401 -- Test acc: 0.9365 -- Gen gap 0.0381\n",
      "Epoch 72/100\n",
      "Avg loss: 0.0265 -- Train acc: 0.9746 -- Val acc: 0.9397 -- Test acc: 0.9370 -- Gen gap 0.0376\n",
      "Epoch 73/100\n",
      "Avg loss: 0.0255 -- Train acc: 0.9750 -- Val acc: 0.9397 -- Test acc: 0.9378 -- Gen gap 0.0372\n",
      "Epoch 74/100\n",
      "Avg loss: 0.0251 -- Train acc: 0.9750 -- Val acc: 0.9400 -- Test acc: 0.9370 -- Gen gap 0.0380\n",
      "Epoch 75/100\n",
      "Avg loss: 0.0260 -- Train acc: 0.9746 -- Val acc: 0.9396 -- Test acc: 0.9357 -- Gen gap 0.0389\n",
      "Epoch 76/100\n",
      "Avg loss: 0.0250 -- Train acc: 0.9750 -- Val acc: 0.9407 -- Test acc: 0.9373 -- Gen gap 0.0377\n",
      "Epoch 77/100\n",
      "Avg loss: 0.0243 -- Train acc: 0.9754 -- Val acc: 0.9396 -- Test acc: 0.9373 -- Gen gap 0.0381\n",
      "Epoch 78/100\n",
      "Avg loss: 0.0238 -- Train acc: 0.9754 -- Val acc: 0.9397 -- Test acc: 0.9375 -- Gen gap 0.0379\n",
      "Epoch 79/100\n",
      "Avg loss: 0.0231 -- Train acc: 0.9750 -- Val acc: 0.9397 -- Test acc: 0.9377 -- Gen gap 0.0373\n",
      "Epoch 80/100\n",
      "Avg loss: 0.0229 -- Train acc: 0.9754 -- Val acc: 0.9401 -- Test acc: 0.9374 -- Gen gap 0.0380\n",
      "Epoch 81/100\n",
      "Avg loss: 0.0227 -- Train acc: 0.9754 -- Val acc: 0.9400 -- Test acc: 0.9377 -- Gen gap 0.0377\n",
      "Epoch 82/100\n",
      "Avg loss: 0.0233 -- Train acc: 0.9750 -- Val acc: 0.9396 -- Test acc: 0.9376 -- Gen gap 0.0374\n",
      "Epoch 83/100\n",
      "Avg loss: 0.0224 -- Train acc: 0.9758 -- Val acc: 0.9400 -- Test acc: 0.9374 -- Gen gap 0.0384\n",
      "Epoch 84/100\n",
      "Avg loss: 0.0221 -- Train acc: 0.9758 -- Val acc: 0.9399 -- Test acc: 0.9379 -- Gen gap 0.0379\n",
      "Epoch 85/100\n",
      "Avg loss: 0.0227 -- Train acc: 0.9758 -- Val acc: 0.9398 -- Test acc: 0.9369 -- Gen gap 0.0389\n",
      "Epoch 86/100\n",
      "Avg loss: 0.0226 -- Train acc: 0.9746 -- Val acc: 0.9395 -- Test acc: 0.9363 -- Gen gap 0.0383\n",
      "Epoch 87/100\n",
      "Avg loss: 0.0214 -- Train acc: 0.9758 -- Val acc: 0.9404 -- Test acc: 0.9370 -- Gen gap 0.0388\n",
      "Epoch 88/100\n",
      "Avg loss: 0.0207 -- Train acc: 0.9758 -- Val acc: 0.9403 -- Test acc: 0.9373 -- Gen gap 0.0385\n",
      "Epoch 89/100\n",
      "Avg loss: 0.0206 -- Train acc: 0.9758 -- Val acc: 0.9401 -- Test acc: 0.9377 -- Gen gap 0.0381\n",
      "Epoch 90/100\n",
      "Avg loss: 0.0223 -- Train acc: 0.9758 -- Val acc: 0.9403 -- Test acc: 0.9362 -- Gen gap 0.0396\n",
      "Epoch 91/100\n",
      "Avg loss: 0.0201 -- Train acc: 0.9762 -- Val acc: 0.9403 -- Test acc: 0.9371 -- Gen gap 0.0391\n",
      "Epoch 92/100\n",
      "Avg loss: 0.0196 -- Train acc: 0.9758 -- Val acc: 0.9403 -- Test acc: 0.9371 -- Gen gap 0.0387\n",
      "Epoch 93/100\n",
      "Avg loss: 0.0200 -- Train acc: 0.9758 -- Val acc: 0.9402 -- Test acc: 0.9380 -- Gen gap 0.0378\n",
      "Epoch 94/100\n",
      "Avg loss: 0.0192 -- Train acc: 0.9766 -- Val acc: 0.9401 -- Test acc: 0.9372 -- Gen gap 0.0394\n",
      "Epoch 95/100\n",
      "Avg loss: 0.0195 -- Train acc: 0.9762 -- Val acc: 0.9404 -- Test acc: 0.9378 -- Gen gap 0.0384\n",
      "Epoch 96/100\n",
      "Avg loss: 0.0187 -- Train acc: 0.9766 -- Val acc: 0.9405 -- Test acc: 0.9379 -- Gen gap 0.0387\n",
      "Epoch 97/100\n",
      "Avg loss: 0.0186 -- Train acc: 0.9766 -- Val acc: 0.9405 -- Test acc: 0.9375 -- Gen gap 0.0391\n",
      "Epoch 98/100\n",
      "Avg loss: 0.0185 -- Train acc: 0.9762 -- Val acc: 0.9404 -- Test acc: 0.9381 -- Gen gap 0.0381\n",
      "Epoch 99/100\n",
      "Avg loss: 0.0184 -- Train acc: 0.9766 -- Val acc: 0.9408 -- Test acc: 0.9379 -- Gen gap 0.0387\n",
      "Epoch 100/100\n",
      "Avg loss: 0.0187 -- Train acc: 0.9766 -- Val acc: 0.9398 -- Test acc: 0.9379 -- Gen gap 0.0387\n",
      "Training done! Elapsed time: 0:00:23\n",
      "\n",
      "Iter 3\n",
      "Epoch 1/100\n",
      "Avg loss: 0.2015 -- Train acc: 0.9168 -- Val acc: 0.9359 -- Test acc: 0.9331 -- Gen gap -0.0163\n",
      "Epoch 2/100\n",
      "Avg loss: 0.1816 -- Train acc: 0.9359 -- Val acc: 0.9429 -- Test acc: 0.9409 -- Gen gap -0.0049\n",
      "Epoch 3/100\n",
      "Avg loss: 0.1653 -- Train acc: 0.9391 -- Val acc: 0.9429 -- Test acc: 0.9426 -- Gen gap -0.0035\n",
      "Epoch 4/100\n",
      "Avg loss: 0.1627 -- Train acc: 0.9242 -- Val acc: 0.9369 -- Test acc: 0.9323 -- Gen gap -0.0081\n",
      "Epoch 5/100\n",
      "Avg loss: 0.1473 -- Train acc: 0.9445 -- Val acc: 0.9440 -- Test acc: 0.9435 -- Gen gap 0.0011\n",
      "Epoch 6/100\n",
      "Avg loss: 0.1362 -- Train acc: 0.9434 -- Val acc: 0.9440 -- Test acc: 0.9432 -- Gen gap 0.0002\n",
      "Epoch 7/100\n",
      "Avg loss: 0.1280 -- Train acc: 0.9469 -- Val acc: 0.9449 -- Test acc: 0.9439 -- Gen gap 0.0030\n",
      "Epoch 8/100\n",
      "Avg loss: 0.1202 -- Train acc: 0.9477 -- Val acc: 0.9435 -- Test acc: 0.9431 -- Gen gap 0.0046\n",
      "Epoch 9/100\n",
      "Avg loss: 0.1154 -- Train acc: 0.9469 -- Val acc: 0.9446 -- Test acc: 0.9448 -- Gen gap 0.0021\n",
      "Epoch 10/100\n",
      "Avg loss: 0.1142 -- Train acc: 0.9398 -- Val acc: 0.9387 -- Test acc: 0.9378 -- Gen gap 0.0020\n",
      "Epoch 11/100\n",
      "Avg loss: 0.1085 -- Train acc: 0.9523 -- Val acc: 0.9437 -- Test acc: 0.9427 -- Gen gap 0.0097\n",
      "Epoch 12/100\n",
      "Avg loss: 0.1036 -- Train acc: 0.9523 -- Val acc: 0.9426 -- Test acc: 0.9417 -- Gen gap 0.0107\n",
      "Epoch 13/100\n",
      "Avg loss: 0.0986 -- Train acc: 0.9559 -- Val acc: 0.9441 -- Test acc: 0.9446 -- Gen gap 0.0113\n",
      "Epoch 14/100\n",
      "Avg loss: 0.0949 -- Train acc: 0.9555 -- Val acc: 0.9437 -- Test acc: 0.9444 -- Gen gap 0.0111\n",
      "Epoch 15/100\n",
      "Avg loss: 0.0911 -- Train acc: 0.9527 -- Val acc: 0.9423 -- Test acc: 0.9430 -- Gen gap 0.0098\n",
      "Epoch 16/100\n",
      "Avg loss: 0.0893 -- Train acc: 0.9590 -- Val acc: 0.9445 -- Test acc: 0.9444 -- Gen gap 0.0146\n",
      "Epoch 17/100\n",
      "Avg loss: 0.0862 -- Train acc: 0.9570 -- Val acc: 0.9453 -- Test acc: 0.9438 -- Gen gap 0.0133\n",
      "Epoch 18/100\n",
      "Avg loss: 0.0837 -- Train acc: 0.9594 -- Val acc: 0.9443 -- Test acc: 0.9448 -- Gen gap 0.0146\n",
      "Epoch 19/100\n",
      "Avg loss: 0.1024 -- Train acc: 0.9348 -- Val acc: 0.9278 -- Test acc: 0.9298 -- Gen gap 0.0049\n",
      "Epoch 20/100\n",
      "Avg loss: 0.0881 -- Train acc: 0.9609 -- Val acc: 0.9452 -- Test acc: 0.9442 -- Gen gap 0.0168\n",
      "Epoch 21/100\n",
      "Avg loss: 0.0827 -- Train acc: 0.9359 -- Val acc: 0.9266 -- Test acc: 0.9226 -- Gen gap 0.0134\n",
      "Epoch 22/100\n",
      "Avg loss: 0.0824 -- Train acc: 0.9590 -- Val acc: 0.9398 -- Test acc: 0.9372 -- Gen gap 0.0218\n",
      "Epoch 23/100\n",
      "Avg loss: 0.0741 -- Train acc: 0.9648 -- Val acc: 0.9459 -- Test acc: 0.9451 -- Gen gap 0.0198\n",
      "Epoch 24/100\n",
      "Avg loss: 0.0687 -- Train acc: 0.9656 -- Val acc: 0.9456 -- Test acc: 0.9444 -- Gen gap 0.0213\n",
      "Epoch 25/100\n",
      "Avg loss: 0.0669 -- Train acc: 0.9684 -- Val acc: 0.9441 -- Test acc: 0.9443 -- Gen gap 0.0241\n",
      "Epoch 26/100\n",
      "Avg loss: 0.0686 -- Train acc: 0.9625 -- Val acc: 0.9437 -- Test acc: 0.9424 -- Gen gap 0.0201\n",
      "Epoch 27/100\n",
      "Avg loss: 0.0656 -- Train acc: 0.9664 -- Val acc: 0.9448 -- Test acc: 0.9430 -- Gen gap 0.0234\n",
      "Epoch 28/100\n",
      "Avg loss: 0.0613 -- Train acc: 0.9688 -- Val acc: 0.9429 -- Test acc: 0.9439 -- Gen gap 0.0249\n",
      "Epoch 29/100\n",
      "Avg loss: 0.0599 -- Train acc: 0.9684 -- Val acc: 0.9443 -- Test acc: 0.9446 -- Gen gap 0.0238\n",
      "Epoch 30/100\n",
      "Avg loss: 0.0607 -- Train acc: 0.9598 -- Val acc: 0.9402 -- Test acc: 0.9378 -- Gen gap 0.0220\n",
      "Epoch 31/100\n",
      "Avg loss: 0.0685 -- Train acc: 0.9434 -- Val acc: 0.9262 -- Test acc: 0.9219 -- Gen gap 0.0215\n",
      "Epoch 32/100\n",
      "Avg loss: 0.0662 -- Train acc: 0.9688 -- Val acc: 0.9444 -- Test acc: 0.9442 -- Gen gap 0.0246\n",
      "Epoch 33/100\n",
      "Avg loss: 0.0556 -- Train acc: 0.9699 -- Val acc: 0.9457 -- Test acc: 0.9448 -- Gen gap 0.0252\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.0542 -- Train acc: 0.9695 -- Val acc: 0.9439 -- Test acc: 0.9431 -- Gen gap 0.0265\n",
      "Epoch 35/100\n",
      "Avg loss: 0.0516 -- Train acc: 0.9691 -- Val acc: 0.9464 -- Test acc: 0.9429 -- Gen gap 0.0263\n",
      "Epoch 36/100\n",
      "Avg loss: 0.0506 -- Train acc: 0.9703 -- Val acc: 0.9457 -- Test acc: 0.9449 -- Gen gap 0.0254\n",
      "Epoch 37/100\n",
      "Avg loss: 0.0489 -- Train acc: 0.9711 -- Val acc: 0.9458 -- Test acc: 0.9438 -- Gen gap 0.0273\n",
      "Epoch 38/100\n",
      "Avg loss: 0.0484 -- Train acc: 0.9676 -- Val acc: 0.9438 -- Test acc: 0.9414 -- Gen gap 0.0262\n",
      "Epoch 39/100\n",
      "Avg loss: 0.0471 -- Train acc: 0.9715 -- Val acc: 0.9457 -- Test acc: 0.9437 -- Gen gap 0.0278\n",
      "Epoch 40/100\n",
      "Avg loss: 0.0468 -- Train acc: 0.9703 -- Val acc: 0.9464 -- Test acc: 0.9448 -- Gen gap 0.0255\n",
      "Epoch 41/100\n",
      "Avg loss: 0.0450 -- Train acc: 0.9715 -- Val acc: 0.9464 -- Test acc: 0.9442 -- Gen gap 0.0273\n",
      "Epoch 42/100\n",
      "Avg loss: 0.0458 -- Train acc: 0.9684 -- Val acc: 0.9435 -- Test acc: 0.9390 -- Gen gap 0.0294\n",
      "Epoch 43/100\n",
      "Avg loss: 0.0448 -- Train acc: 0.9719 -- Val acc: 0.9459 -- Test acc: 0.9438 -- Gen gap 0.0281\n",
      "Epoch 44/100\n",
      "Avg loss: 0.0437 -- Train acc: 0.9719 -- Val acc: 0.9445 -- Test acc: 0.9437 -- Gen gap 0.0282\n",
      "Epoch 45/100\n",
      "Avg loss: 0.0411 -- Train acc: 0.9719 -- Val acc: 0.9457 -- Test acc: 0.9444 -- Gen gap 0.0275\n",
      "Epoch 46/100\n",
      "Avg loss: 0.0400 -- Train acc: 0.9727 -- Val acc: 0.9447 -- Test acc: 0.9440 -- Gen gap 0.0287\n",
      "Epoch 47/100\n",
      "Avg loss: 0.0397 -- Train acc: 0.9719 -- Val acc: 0.9457 -- Test acc: 0.9444 -- Gen gap 0.0275\n",
      "Epoch 48/100\n",
      "Avg loss: 0.0397 -- Train acc: 0.9723 -- Val acc: 0.9432 -- Test acc: 0.9425 -- Gen gap 0.0298\n",
      "Epoch 49/100\n",
      "Avg loss: 0.0389 -- Train acc: 0.9727 -- Val acc: 0.9444 -- Test acc: 0.9446 -- Gen gap 0.0281\n",
      "Epoch 50/100\n",
      "Avg loss: 0.0370 -- Train acc: 0.9730 -- Val acc: 0.9461 -- Test acc: 0.9448 -- Gen gap 0.0283\n",
      "Epoch 51/100\n",
      "Avg loss: 0.0364 -- Train acc: 0.9730 -- Val acc: 0.9457 -- Test acc: 0.9438 -- Gen gap 0.0293\n",
      "Epoch 52/100\n",
      "Avg loss: 0.0376 -- Train acc: 0.9699 -- Val acc: 0.9433 -- Test acc: 0.9398 -- Gen gap 0.0301\n",
      "Epoch 53/100\n",
      "Avg loss: 0.0363 -- Train acc: 0.9730 -- Val acc: 0.9451 -- Test acc: 0.9448 -- Gen gap 0.0283\n",
      "Epoch 54/100\n",
      "Avg loss: 0.0363 -- Train acc: 0.9727 -- Val acc: 0.9439 -- Test acc: 0.9442 -- Gen gap 0.0285\n",
      "Epoch 55/100\n",
      "Avg loss: 0.0340 -- Train acc: 0.9730 -- Val acc: 0.9460 -- Test acc: 0.9453 -- Gen gap 0.0278\n",
      "Epoch 56/100\n",
      "Avg loss: 0.0327 -- Train acc: 0.9730 -- Val acc: 0.9458 -- Test acc: 0.9436 -- Gen gap 0.0295\n",
      "Epoch 57/100\n",
      "Avg loss: 0.0336 -- Train acc: 0.9719 -- Val acc: 0.9443 -- Test acc: 0.9416 -- Gen gap 0.0303\n",
      "Epoch 58/100\n",
      "Avg loss: 0.0327 -- Train acc: 0.9734 -- Val acc: 0.9461 -- Test acc: 0.9445 -- Gen gap 0.0290\n",
      "Epoch 59/100\n",
      "Avg loss: 0.0314 -- Train acc: 0.9738 -- Val acc: 0.9454 -- Test acc: 0.9450 -- Gen gap 0.0289\n",
      "Epoch 60/100\n",
      "Avg loss: 0.0305 -- Train acc: 0.9738 -- Val acc: 0.9454 -- Test acc: 0.9445 -- Gen gap 0.0294\n",
      "Epoch 61/100\n",
      "Avg loss: 0.0303 -- Train acc: 0.9742 -- Val acc: 0.9453 -- Test acc: 0.9444 -- Gen gap 0.0299\n",
      "Epoch 62/100\n",
      "Avg loss: 0.0296 -- Train acc: 0.9738 -- Val acc: 0.9461 -- Test acc: 0.9445 -- Gen gap 0.0294\n",
      "Epoch 63/100\n",
      "Avg loss: 0.0296 -- Train acc: 0.9734 -- Val acc: 0.9455 -- Test acc: 0.9436 -- Gen gap 0.0299\n",
      "Epoch 64/100\n",
      "Avg loss: 0.0303 -- Train acc: 0.9734 -- Val acc: 0.9431 -- Test acc: 0.9432 -- Gen gap 0.0303\n",
      "Epoch 65/100\n",
      "Avg loss: 0.0289 -- Train acc: 0.9746 -- Val acc: 0.9460 -- Test acc: 0.9450 -- Gen gap 0.0296\n",
      "Epoch 66/100\n",
      "Avg loss: 0.0278 -- Train acc: 0.9746 -- Val acc: 0.9455 -- Test acc: 0.9448 -- Gen gap 0.0298\n",
      "Epoch 67/100\n",
      "Avg loss: 0.0272 -- Train acc: 0.9746 -- Val acc: 0.9466 -- Test acc: 0.9449 -- Gen gap 0.0297\n",
      "Epoch 68/100\n",
      "Avg loss: 0.0267 -- Train acc: 0.9746 -- Val acc: 0.9462 -- Test acc: 0.9449 -- Gen gap 0.0297\n",
      "Epoch 69/100\n",
      "Avg loss: 0.0262 -- Train acc: 0.9754 -- Val acc: 0.9460 -- Test acc: 0.9448 -- Gen gap 0.0306\n",
      "Epoch 70/100\n",
      "Avg loss: 0.0266 -- Train acc: 0.9754 -- Val acc: 0.9455 -- Test acc: 0.9446 -- Gen gap 0.0308\n",
      "Epoch 71/100\n",
      "Avg loss: 0.0256 -- Train acc: 0.9758 -- Val acc: 0.9466 -- Test acc: 0.9448 -- Gen gap 0.0310\n",
      "Epoch 72/100\n",
      "Avg loss: 0.0258 -- Train acc: 0.9762 -- Val acc: 0.9449 -- Test acc: 0.9439 -- Gen gap 0.0323\n",
      "Epoch 73/100\n",
      "Avg loss: 0.0251 -- Train acc: 0.9762 -- Val acc: 0.9462 -- Test acc: 0.9438 -- Gen gap 0.0324\n",
      "Epoch 74/100\n",
      "Avg loss: 0.0249 -- Train acc: 0.9758 -- Val acc: 0.9468 -- Test acc: 0.9447 -- Gen gap 0.0311\n",
      "Epoch 75/100\n",
      "Avg loss: 0.0240 -- Train acc: 0.9758 -- Val acc: 0.9466 -- Test acc: 0.9452 -- Gen gap 0.0306\n",
      "Epoch 76/100\n",
      "Avg loss: 0.0236 -- Train acc: 0.9758 -- Val acc: 0.9466 -- Test acc: 0.9450 -- Gen gap 0.0308\n",
      "Epoch 77/100\n",
      "Avg loss: 0.0232 -- Train acc: 0.9762 -- Val acc: 0.9468 -- Test acc: 0.9445 -- Gen gap 0.0317\n",
      "Epoch 78/100\n",
      "Avg loss: 0.0235 -- Train acc: 0.9762 -- Val acc: 0.9458 -- Test acc: 0.9444 -- Gen gap 0.0318\n",
      "Epoch 79/100\n",
      "Avg loss: 0.0226 -- Train acc: 0.9762 -- Val acc: 0.9462 -- Test acc: 0.9444 -- Gen gap 0.0318\n",
      "Epoch 80/100\n",
      "Avg loss: 0.0228 -- Train acc: 0.9762 -- Val acc: 0.9464 -- Test acc: 0.9452 -- Gen gap 0.0310\n",
      "Epoch 81/100\n",
      "Avg loss: 0.0221 -- Train acc: 0.9762 -- Val acc: 0.9461 -- Test acc: 0.9443 -- Gen gap 0.0319\n",
      "Epoch 82/100\n",
      "Avg loss: 0.0217 -- Train acc: 0.9762 -- Val acc: 0.9462 -- Test acc: 0.9451 -- Gen gap 0.0311\n",
      "Epoch 83/100\n",
      "Avg loss: 0.0219 -- Train acc: 0.9762 -- Val acc: 0.9459 -- Test acc: 0.9442 -- Gen gap 0.0320\n",
      "Epoch 84/100\n",
      "Avg loss: 0.0252 -- Train acc: 0.9703 -- Val acc: 0.9390 -- Test acc: 0.9378 -- Gen gap 0.0325\n",
      "Epoch 85/100\n",
      "Avg loss: 0.0239 -- Train acc: 0.9766 -- Val acc: 0.9456 -- Test acc: 0.9440 -- Gen gap 0.0326\n",
      "Epoch 86/100\n",
      "Avg loss: 0.0231 -- Train acc: 0.9754 -- Val acc: 0.9430 -- Test acc: 0.9416 -- Gen gap 0.0338\n",
      "Epoch 87/100\n",
      "Avg loss: 0.0214 -- Train acc: 0.9766 -- Val acc: 0.9464 -- Test acc: 0.9446 -- Gen gap 0.0320\n",
      "Epoch 88/100\n",
      "Avg loss: 0.0206 -- Train acc: 0.9766 -- Val acc: 0.9463 -- Test acc: 0.9441 -- Gen gap 0.0325\n",
      "Epoch 89/100\n",
      "Avg loss: 0.0202 -- Train acc: 0.9766 -- Val acc: 0.9460 -- Test acc: 0.9447 -- Gen gap 0.0319\n",
      "Epoch 90/100\n",
      "Avg loss: 0.0199 -- Train acc: 0.9766 -- Val acc: 0.9458 -- Test acc: 0.9445 -- Gen gap 0.0321\n",
      "Epoch 91/100\n",
      "Avg loss: 0.0194 -- Train acc: 0.9766 -- Val acc: 0.9461 -- Test acc: 0.9444 -- Gen gap 0.0322\n",
      "Epoch 92/100\n",
      "Avg loss: 0.0191 -- Train acc: 0.9766 -- Val acc: 0.9460 -- Test acc: 0.9445 -- Gen gap 0.0321\n",
      "Epoch 93/100\n",
      "Avg loss: 0.0187 -- Train acc: 0.9766 -- Val acc: 0.9460 -- Test acc: 0.9447 -- Gen gap 0.0319\n",
      "Epoch 94/100\n",
      "Avg loss: 0.0184 -- Train acc: 0.9766 -- Val acc: 0.9461 -- Test acc: 0.9445 -- Gen gap 0.0321\n",
      "Epoch 95/100\n",
      "Avg loss: 0.0183 -- Train acc: 0.9766 -- Val acc: 0.9459 -- Test acc: 0.9444 -- Gen gap 0.0322\n",
      "Epoch 96/100\n",
      "Avg loss: 0.0181 -- Train acc: 0.9766 -- Val acc: 0.9463 -- Test acc: 0.9443 -- Gen gap 0.0323\n",
      "Epoch 97/100\n",
      "Avg loss: 0.0192 -- Train acc: 0.9766 -- Val acc: 0.9461 -- Test acc: 0.9446 -- Gen gap 0.0320\n",
      "Epoch 98/100\n",
      "Avg loss: 0.0183 -- Train acc: 0.9766 -- Val acc: 0.9468 -- Test acc: 0.9445 -- Gen gap 0.0321\n",
      "Epoch 99/100\n",
      "Avg loss: 0.0180 -- Train acc: 0.9766 -- Val acc: 0.9463 -- Test acc: 0.9447 -- Gen gap 0.0319\n",
      "Epoch 100/100\n",
      "Avg loss: 0.0181 -- Train acc: 0.9766 -- Val acc: 0.9466 -- Test acc: 0.9446 -- Gen gap 0.0320\n",
      "Training done! Elapsed time: 0:00:23\n",
      "\n",
      "==============================\n",
      "a = 0.10, Na = 5000\n",
      "------------------------------\n",
      "Iter 1\n",
      "Epoch 1/100\n",
      "Avg loss: 0.1620 -- Train acc: 0.9462 -- Val acc: 0.9468 -- Test acc: 0.9443 -- Gen gap 0.0019\n",
      "Epoch 2/100\n",
      "Avg loss: 0.1444 -- Train acc: 0.9472 -- Val acc: 0.9445 -- Test acc: 0.9423 -- Gen gap 0.0049\n",
      "Epoch 3/100\n",
      "Avg loss: 0.1292 -- Train acc: 0.9547 -- Val acc: 0.9473 -- Test acc: 0.9452 -- Gen gap 0.0095\n",
      "Epoch 4/100\n",
      "Avg loss: 0.1176 -- Train acc: 0.9581 -- Val acc: 0.9511 -- Test acc: 0.9488 -- Gen gap 0.0092\n",
      "Epoch 5/100\n",
      "Avg loss: 0.1095 -- Train acc: 0.9634 -- Val acc: 0.9506 -- Test acc: 0.9482 -- Gen gap 0.0152\n",
      "Epoch 6/100\n",
      "Avg loss: 0.1033 -- Train acc: 0.9636 -- Val acc: 0.9492 -- Test acc: 0.9479 -- Gen gap 0.0157\n",
      "Epoch 7/100\n",
      "Avg loss: 0.0969 -- Train acc: 0.9636 -- Val acc: 0.9492 -- Test acc: 0.9466 -- Gen gap 0.0171\n",
      "Epoch 8/100\n",
      "Avg loss: 0.0918 -- Train acc: 0.9660 -- Val acc: 0.9514 -- Test acc: 0.9486 -- Gen gap 0.0173\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.0877 -- Train acc: 0.9660 -- Val acc: 0.9505 -- Test acc: 0.9495 -- Gen gap 0.0164\n",
      "Epoch 10/100\n",
      "Avg loss: 0.0907 -- Train acc: 0.9680 -- Val acc: 0.9484 -- Test acc: 0.9473 -- Gen gap 0.0207\n",
      "Epoch 11/100\n",
      "Avg loss: 0.0802 -- Train acc: 0.9705 -- Val acc: 0.9509 -- Test acc: 0.9481 -- Gen gap 0.0224\n",
      "Epoch 12/100\n",
      "Avg loss: 0.0766 -- Train acc: 0.9701 -- Val acc: 0.9504 -- Test acc: 0.9495 -- Gen gap 0.0206\n",
      "Epoch 13/100\n",
      "Avg loss: 0.0743 -- Train acc: 0.9717 -- Val acc: 0.9486 -- Test acc: 0.9479 -- Gen gap 0.0239\n",
      "Epoch 14/100\n",
      "Avg loss: 0.0703 -- Train acc: 0.9715 -- Val acc: 0.9502 -- Test acc: 0.9506 -- Gen gap 0.0209\n",
      "Epoch 15/100\n",
      "Avg loss: 0.0673 -- Train acc: 0.9747 -- Val acc: 0.9514 -- Test acc: 0.9504 -- Gen gap 0.0242\n",
      "Epoch 16/100\n",
      "Avg loss: 0.0649 -- Train acc: 0.9747 -- Val acc: 0.9504 -- Test acc: 0.9515 -- Gen gap 0.0232\n",
      "Epoch 17/100\n",
      "Avg loss: 0.0637 -- Train acc: 0.9757 -- Val acc: 0.9504 -- Test acc: 0.9511 -- Gen gap 0.0245\n",
      "Epoch 18/100\n",
      "Avg loss: 0.0615 -- Train acc: 0.9769 -- Val acc: 0.9509 -- Test acc: 0.9519 -- Gen gap 0.0249\n",
      "Epoch 19/100\n",
      "Avg loss: 0.0587 -- Train acc: 0.9775 -- Val acc: 0.9515 -- Test acc: 0.9499 -- Gen gap 0.0275\n",
      "Epoch 20/100\n",
      "Avg loss: 0.0583 -- Train acc: 0.9751 -- Val acc: 0.9503 -- Test acc: 0.9499 -- Gen gap 0.0251\n",
      "Epoch 21/100\n",
      "Avg loss: 0.0548 -- Train acc: 0.9784 -- Val acc: 0.9515 -- Test acc: 0.9507 -- Gen gap 0.0277\n",
      "Epoch 22/100\n",
      "Avg loss: 0.0528 -- Train acc: 0.9790 -- Val acc: 0.9504 -- Test acc: 0.9502 -- Gen gap 0.0288\n",
      "Epoch 23/100\n",
      "Avg loss: 0.0522 -- Train acc: 0.9771 -- Val acc: 0.9513 -- Test acc: 0.9513 -- Gen gap 0.0257\n",
      "Epoch 24/100\n",
      "Avg loss: 0.0504 -- Train acc: 0.9804 -- Val acc: 0.9518 -- Test acc: 0.9517 -- Gen gap 0.0287\n",
      "Epoch 25/100\n",
      "Avg loss: 0.0483 -- Train acc: 0.9800 -- Val acc: 0.9519 -- Test acc: 0.9505 -- Gen gap 0.0295\n",
      "Epoch 26/100\n",
      "Avg loss: 0.0468 -- Train acc: 0.9806 -- Val acc: 0.9520 -- Test acc: 0.9511 -- Gen gap 0.0295\n",
      "Epoch 27/100\n",
      "Avg loss: 0.0493 -- Train acc: 0.9802 -- Val acc: 0.9514 -- Test acc: 0.9506 -- Gen gap 0.0296\n",
      "Epoch 28/100\n",
      "Avg loss: 0.0461 -- Train acc: 0.9804 -- Val acc: 0.9500 -- Test acc: 0.9499 -- Gen gap 0.0305\n",
      "Epoch 29/100\n",
      "Avg loss: 0.0429 -- Train acc: 0.9816 -- Val acc: 0.9516 -- Test acc: 0.9502 -- Gen gap 0.0314\n",
      "Epoch 30/100\n",
      "Avg loss: 0.0488 -- Train acc: 0.9745 -- Val acc: 0.9478 -- Test acc: 0.9469 -- Gen gap 0.0276\n",
      "Epoch 31/100\n",
      "Avg loss: 0.0482 -- Train acc: 0.9806 -- Val acc: 0.9523 -- Test acc: 0.9515 -- Gen gap 0.0291\n",
      "Epoch 32/100\n",
      "Avg loss: 0.0397 -- Train acc: 0.9826 -- Val acc: 0.9524 -- Test acc: 0.9512 -- Gen gap 0.0314\n",
      "Epoch 33/100\n",
      "Avg loss: 0.0389 -- Train acc: 0.9826 -- Val acc: 0.9517 -- Test acc: 0.9513 -- Gen gap 0.0313\n",
      "Epoch 34/100\n",
      "Avg loss: 0.0373 -- Train acc: 0.9832 -- Val acc: 0.9521 -- Test acc: 0.9512 -- Gen gap 0.0320\n",
      "Epoch 35/100\n",
      "Avg loss: 0.0375 -- Train acc: 0.9828 -- Val acc: 0.9519 -- Test acc: 0.9510 -- Gen gap 0.0318\n",
      "Epoch 36/100\n",
      "Avg loss: 0.0354 -- Train acc: 0.9840 -- Val acc: 0.9519 -- Test acc: 0.9516 -- Gen gap 0.0323\n",
      "Epoch 37/100\n",
      "Avg loss: 0.0351 -- Train acc: 0.9830 -- Val acc: 0.9524 -- Test acc: 0.9500 -- Gen gap 0.0330\n",
      "Epoch 38/100\n",
      "Avg loss: 0.0340 -- Train acc: 0.9838 -- Val acc: 0.9526 -- Test acc: 0.9515 -- Gen gap 0.0322\n",
      "Epoch 39/100\n",
      "Avg loss: 0.0328 -- Train acc: 0.9848 -- Val acc: 0.9533 -- Test acc: 0.9520 -- Gen gap 0.0327\n",
      "Epoch 40/100\n",
      "Avg loss: 0.0318 -- Train acc: 0.9848 -- Val acc: 0.9524 -- Test acc: 0.9508 -- Gen gap 0.0339\n",
      "Epoch 41/100\n",
      "Avg loss: 0.0315 -- Train acc: 0.9844 -- Val acc: 0.9527 -- Test acc: 0.9531 -- Gen gap 0.0312\n",
      "Epoch 42/100\n",
      "Avg loss: 0.0303 -- Train acc: 0.9850 -- Val acc: 0.9519 -- Test acc: 0.9515 -- Gen gap 0.0334\n",
      "Epoch 43/100\n",
      "Avg loss: 0.0304 -- Train acc: 0.9850 -- Val acc: 0.9535 -- Test acc: 0.9527 -- Gen gap 0.0322\n",
      "Epoch 44/100\n",
      "Avg loss: 0.0295 -- Train acc: 0.9852 -- Val acc: 0.9531 -- Test acc: 0.9511 -- Gen gap 0.0340\n",
      "Epoch 45/100\n",
      "Avg loss: 0.0286 -- Train acc: 0.9858 -- Val acc: 0.9529 -- Test acc: 0.9512 -- Gen gap 0.0345\n",
      "Epoch 46/100\n",
      "Avg loss: 0.0281 -- Train acc: 0.9860 -- Val acc: 0.9533 -- Test acc: 0.9517 -- Gen gap 0.0342\n",
      "Epoch 47/100\n",
      "Avg loss: 0.0274 -- Train acc: 0.9860 -- Val acc: 0.9531 -- Test acc: 0.9521 -- Gen gap 0.0338\n",
      "Epoch 48/100\n",
      "Avg loss: 0.0273 -- Train acc: 0.9858 -- Val acc: 0.9534 -- Test acc: 0.9520 -- Gen gap 0.0337\n",
      "Epoch 49/100\n",
      "Avg loss: 0.0262 -- Train acc: 0.9862 -- Val acc: 0.9533 -- Test acc: 0.9515 -- Gen gap 0.0346\n",
      "Epoch 50/100\n",
      "Avg loss: 0.0260 -- Train acc: 0.9864 -- Val acc: 0.9534 -- Test acc: 0.9525 -- Gen gap 0.0338\n",
      "Epoch 51/100\n",
      "Avg loss: 0.0252 -- Train acc: 0.9864 -- Val acc: 0.9532 -- Test acc: 0.9522 -- Gen gap 0.0341\n",
      "Epoch 52/100\n",
      "Avg loss: 0.0246 -- Train acc: 0.9869 -- Val acc: 0.9530 -- Test acc: 0.9512 -- Gen gap 0.0357\n",
      "Epoch 53/100\n",
      "Avg loss: 0.0241 -- Train acc: 0.9866 -- Val acc: 0.9532 -- Test acc: 0.9522 -- Gen gap 0.0343\n",
      "Epoch 54/100\n",
      "Avg loss: 0.0237 -- Train acc: 0.9864 -- Val acc: 0.9529 -- Test acc: 0.9520 -- Gen gap 0.0343\n",
      "Epoch 55/100\n",
      "Avg loss: 0.0233 -- Train acc: 0.9871 -- Val acc: 0.9535 -- Test acc: 0.9525 -- Gen gap 0.0346\n",
      "Epoch 56/100\n",
      "Avg loss: 0.0227 -- Train acc: 0.9871 -- Val acc: 0.9527 -- Test acc: 0.9523 -- Gen gap 0.0348\n",
      "Epoch 57/100\n",
      "Avg loss: 0.0226 -- Train acc: 0.9871 -- Val acc: 0.9534 -- Test acc: 0.9524 -- Gen gap 0.0347\n",
      "Epoch 58/100\n",
      "Avg loss: 0.0219 -- Train acc: 0.9871 -- Val acc: 0.9534 -- Test acc: 0.9527 -- Gen gap 0.0344\n",
      "Epoch 59/100\n",
      "Avg loss: 0.0215 -- Train acc: 0.9875 -- Val acc: 0.9538 -- Test acc: 0.9521 -- Gen gap 0.0354\n",
      "Epoch 60/100\n",
      "Avg loss: 0.0211 -- Train acc: 0.9871 -- Val acc: 0.9532 -- Test acc: 0.9523 -- Gen gap 0.0348\n",
      "Epoch 61/100\n",
      "Avg loss: 0.0217 -- Train acc: 0.9875 -- Val acc: 0.9535 -- Test acc: 0.9521 -- Gen gap 0.0354\n",
      "Epoch 62/100\n",
      "Avg loss: 0.0204 -- Train acc: 0.9879 -- Val acc: 0.9537 -- Test acc: 0.9522 -- Gen gap 0.0357\n",
      "Epoch 63/100\n",
      "Avg loss: 0.0201 -- Train acc: 0.9877 -- Val acc: 0.9539 -- Test acc: 0.9516 -- Gen gap 0.0361\n",
      "Epoch 64/100\n",
      "Avg loss: 0.0196 -- Train acc: 0.9877 -- Val acc: 0.9534 -- Test acc: 0.9522 -- Gen gap 0.0355\n",
      "Epoch 65/100\n",
      "Avg loss: 0.0193 -- Train acc: 0.9879 -- Val acc: 0.9538 -- Test acc: 0.9518 -- Gen gap 0.0361\n",
      "Epoch 66/100\n",
      "Avg loss: 0.0193 -- Train acc: 0.9879 -- Val acc: 0.9533 -- Test acc: 0.9522 -- Gen gap 0.0357\n",
      "Epoch 67/100\n",
      "Avg loss: 0.0186 -- Train acc: 0.9881 -- Val acc: 0.9536 -- Test acc: 0.9523 -- Gen gap 0.0358\n",
      "Epoch 68/100\n",
      "Avg loss: 0.0185 -- Train acc: 0.9885 -- Val acc: 0.9538 -- Test acc: 0.9524 -- Gen gap 0.0361\n",
      "Epoch 69/100\n",
      "Avg loss: 0.0185 -- Train acc: 0.9883 -- Val acc: 0.9537 -- Test acc: 0.9526 -- Gen gap 0.0357\n",
      "Epoch 70/100\n",
      "Avg loss: 0.0179 -- Train acc: 0.9885 -- Val acc: 0.9536 -- Test acc: 0.9520 -- Gen gap 0.0365\n",
      "Epoch 71/100\n",
      "Avg loss: 0.0178 -- Train acc: 0.9885 -- Val acc: 0.9536 -- Test acc: 0.9516 -- Gen gap 0.0369\n",
      "Epoch 72/100\n",
      "Avg loss: 0.0175 -- Train acc: 0.9885 -- Val acc: 0.9540 -- Test acc: 0.9525 -- Gen gap 0.0360\n",
      "Epoch 73/100\n",
      "Avg loss: 0.0172 -- Train acc: 0.9883 -- Val acc: 0.9535 -- Test acc: 0.9527 -- Gen gap 0.0356\n",
      "Epoch 74/100\n",
      "Avg loss: 0.0169 -- Train acc: 0.9887 -- Val acc: 0.9541 -- Test acc: 0.9523 -- Gen gap 0.0364\n",
      "Epoch 75/100\n",
      "Avg loss: 0.0164 -- Train acc: 0.9885 -- Val acc: 0.9539 -- Test acc: 0.9523 -- Gen gap 0.0362\n",
      "Epoch 76/100\n",
      "Avg loss: 0.0163 -- Train acc: 0.9887 -- Val acc: 0.9542 -- Test acc: 0.9521 -- Gen gap 0.0366\n",
      "Epoch 77/100\n",
      "Avg loss: 0.0164 -- Train acc: 0.9887 -- Val acc: 0.9539 -- Test acc: 0.9521 -- Gen gap 0.0366\n",
      "Epoch 78/100\n",
      "Avg loss: 0.0158 -- Train acc: 0.9887 -- Val acc: 0.9535 -- Test acc: 0.9525 -- Gen gap 0.0362\n",
      "Epoch 79/100\n",
      "Avg loss: 0.0160 -- Train acc: 0.9887 -- Val acc: 0.9523 -- Test acc: 0.9506 -- Gen gap 0.0381\n",
      "Epoch 80/100\n",
      "Avg loss: 0.0155 -- Train acc: 0.9889 -- Val acc: 0.9540 -- Test acc: 0.9520 -- Gen gap 0.0369\n",
      "Epoch 81/100\n",
      "Avg loss: 0.0152 -- Train acc: 0.9889 -- Val acc: 0.9537 -- Test acc: 0.9535 -- Gen gap 0.0354\n",
      "Epoch 82/100\n",
      "Avg loss: 0.0149 -- Train acc: 0.9887 -- Val acc: 0.9536 -- Test acc: 0.9529 -- Gen gap 0.0358\n",
      "Epoch 83/100\n",
      "Avg loss: 0.0147 -- Train acc: 0.9889 -- Val acc: 0.9538 -- Test acc: 0.9530 -- Gen gap 0.0359\n",
      "Epoch 84/100\n",
      "Avg loss: 0.0146 -- Train acc: 0.9889 -- Val acc: 0.9536 -- Test acc: 0.9519 -- Gen gap 0.0370\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.0143 -- Train acc: 0.9889 -- Val acc: 0.9538 -- Test acc: 0.9527 -- Gen gap 0.0362\n",
      "Epoch 86/100\n",
      "Avg loss: 0.0141 -- Train acc: 0.9889 -- Val acc: 0.9536 -- Test acc: 0.9530 -- Gen gap 0.0359\n",
      "Epoch 87/100\n",
      "Avg loss: 0.0139 -- Train acc: 0.9889 -- Val acc: 0.9540 -- Test acc: 0.9518 -- Gen gap 0.0371\n",
      "Epoch 88/100\n",
      "Avg loss: 0.0139 -- Train acc: 0.9887 -- Val acc: 0.9536 -- Test acc: 0.9519 -- Gen gap 0.0368\n",
      "Epoch 89/100\n",
      "Avg loss: 0.0136 -- Train acc: 0.9889 -- Val acc: 0.9540 -- Test acc: 0.9529 -- Gen gap 0.0360\n",
      "Epoch 90/100\n",
      "Avg loss: 0.0134 -- Train acc: 0.9889 -- Val acc: 0.9536 -- Test acc: 0.9526 -- Gen gap 0.0363\n",
      "Epoch 91/100\n",
      "Avg loss: 0.0132 -- Train acc: 0.9889 -- Val acc: 0.9537 -- Test acc: 0.9531 -- Gen gap 0.0358\n",
      "Epoch 92/100\n",
      "Avg loss: 0.0134 -- Train acc: 0.9889 -- Val acc: 0.9539 -- Test acc: 0.9533 -- Gen gap 0.0356\n",
      "Epoch 93/100\n",
      "Avg loss: 0.0129 -- Train acc: 0.9889 -- Val acc: 0.9541 -- Test acc: 0.9529 -- Gen gap 0.0360\n",
      "Epoch 94/100\n",
      "Avg loss: 0.0127 -- Train acc: 0.9889 -- Val acc: 0.9539 -- Test acc: 0.9527 -- Gen gap 0.0362\n",
      "Epoch 95/100\n",
      "Avg loss: 0.0129 -- Train acc: 0.9889 -- Val acc: 0.9538 -- Test acc: 0.9519 -- Gen gap 0.0370\n",
      "Epoch 96/100\n",
      "Avg loss: 0.0126 -- Train acc: 0.9889 -- Val acc: 0.9539 -- Test acc: 0.9525 -- Gen gap 0.0364\n",
      "Epoch 97/100\n",
      "Avg loss: 0.0123 -- Train acc: 0.9889 -- Val acc: 0.9540 -- Test acc: 0.9527 -- Gen gap 0.0362\n",
      "Epoch 98/100\n",
      "Avg loss: 0.0123 -- Train acc: 0.9889 -- Val acc: 0.9541 -- Test acc: 0.9537 -- Gen gap 0.0352\n",
      "Epoch 99/100\n",
      "Avg loss: 0.0121 -- Train acc: 0.9889 -- Val acc: 0.9540 -- Test acc: 0.9528 -- Gen gap 0.0361\n",
      "Epoch 100/100\n",
      "Avg loss: 0.0120 -- Train acc: 0.9889 -- Val acc: 0.9542 -- Test acc: 0.9524 -- Gen gap 0.0365\n",
      "Training done! Elapsed time: 0:00:33\n",
      "\n",
      "Iter 2\n",
      "Epoch 1/100\n",
      "Avg loss: 0.1530 -- Train acc: 0.9527 -- Val acc: 0.9551 -- Test acc: 0.9544 -- Gen gap -0.0017\n",
      "Epoch 2/100\n",
      "Avg loss: 0.1344 -- Train acc: 0.9571 -- Val acc: 0.9557 -- Test acc: 0.9545 -- Gen gap 0.0026\n",
      "Epoch 3/100\n",
      "Avg loss: 0.1234 -- Train acc: 0.9598 -- Val acc: 0.9567 -- Test acc: 0.9555 -- Gen gap 0.0043\n",
      "Epoch 4/100\n",
      "Avg loss: 0.1133 -- Train acc: 0.9634 -- Val acc: 0.9573 -- Test acc: 0.9565 -- Gen gap 0.0069\n",
      "Epoch 5/100\n",
      "Avg loss: 0.1047 -- Train acc: 0.9646 -- Val acc: 0.9578 -- Test acc: 0.9566 -- Gen gap 0.0080\n",
      "Epoch 6/100\n",
      "Avg loss: 0.0985 -- Train acc: 0.9654 -- Val acc: 0.9575 -- Test acc: 0.9564 -- Gen gap 0.0090\n",
      "Epoch 7/100\n",
      "Avg loss: 0.0977 -- Train acc: 0.9670 -- Val acc: 0.9566 -- Test acc: 0.9565 -- Gen gap 0.0105\n",
      "Epoch 8/100\n",
      "Avg loss: 0.0875 -- Train acc: 0.9686 -- Val acc: 0.9576 -- Test acc: 0.9567 -- Gen gap 0.0118\n",
      "Epoch 9/100\n",
      "Avg loss: 0.0855 -- Train acc: 0.9470 -- Val acc: 0.9405 -- Test acc: 0.9397 -- Gen gap 0.0073\n",
      "Epoch 10/100\n",
      "Avg loss: 0.0817 -- Train acc: 0.9709 -- Val acc: 0.9580 -- Test acc: 0.9568 -- Gen gap 0.0141\n",
      "Epoch 11/100\n",
      "Avg loss: 0.0757 -- Train acc: 0.9703 -- Val acc: 0.9574 -- Test acc: 0.9571 -- Gen gap 0.0132\n",
      "Epoch 12/100\n",
      "Avg loss: 0.0716 -- Train acc: 0.9733 -- Val acc: 0.9587 -- Test acc: 0.9582 -- Gen gap 0.0151\n",
      "Epoch 13/100\n",
      "Avg loss: 0.0684 -- Train acc: 0.9737 -- Val acc: 0.9576 -- Test acc: 0.9575 -- Gen gap 0.0162\n",
      "Epoch 14/100\n",
      "Avg loss: 0.0652 -- Train acc: 0.9751 -- Val acc: 0.9578 -- Test acc: 0.9582 -- Gen gap 0.0169\n",
      "Epoch 15/100\n",
      "Avg loss: 0.0642 -- Train acc: 0.9743 -- Val acc: 0.9568 -- Test acc: 0.9570 -- Gen gap 0.0173\n",
      "Epoch 16/100\n",
      "Avg loss: 0.0602 -- Train acc: 0.9765 -- Val acc: 0.9584 -- Test acc: 0.9574 -- Gen gap 0.0191\n",
      "Epoch 17/100\n",
      "Avg loss: 0.0576 -- Train acc: 0.9777 -- Val acc: 0.9578 -- Test acc: 0.9570 -- Gen gap 0.0206\n",
      "Epoch 18/100\n",
      "Avg loss: 0.0552 -- Train acc: 0.9782 -- Val acc: 0.9583 -- Test acc: 0.9563 -- Gen gap 0.0219\n",
      "Epoch 19/100\n",
      "Avg loss: 0.0534 -- Train acc: 0.9788 -- Val acc: 0.9574 -- Test acc: 0.9582 -- Gen gap 0.0206\n",
      "Epoch 20/100\n",
      "Avg loss: 0.0528 -- Train acc: 0.9788 -- Val acc: 0.9570 -- Test acc: 0.9565 -- Gen gap 0.0223\n",
      "Epoch 21/100\n",
      "Avg loss: 0.0511 -- Train acc: 0.9796 -- Val acc: 0.9584 -- Test acc: 0.9581 -- Gen gap 0.0215\n",
      "Epoch 22/100\n",
      "Avg loss: 0.0483 -- Train acc: 0.9810 -- Val acc: 0.9586 -- Test acc: 0.9578 -- Gen gap 0.0232\n",
      "Epoch 23/100\n",
      "Avg loss: 0.0468 -- Train acc: 0.9812 -- Val acc: 0.9586 -- Test acc: 0.9578 -- Gen gap 0.0234\n",
      "Epoch 24/100\n",
      "Avg loss: 0.0450 -- Train acc: 0.9820 -- Val acc: 0.9576 -- Test acc: 0.9572 -- Gen gap 0.0248\n",
      "Epoch 25/100\n",
      "Avg loss: 0.0436 -- Train acc: 0.9820 -- Val acc: 0.9588 -- Test acc: 0.9577 -- Gen gap 0.0243\n",
      "Epoch 26/100\n",
      "Avg loss: 0.0422 -- Train acc: 0.9830 -- Val acc: 0.9585 -- Test acc: 0.9575 -- Gen gap 0.0255\n",
      "Epoch 27/100\n",
      "Avg loss: 0.0408 -- Train acc: 0.9838 -- Val acc: 0.9582 -- Test acc: 0.9585 -- Gen gap 0.0253\n",
      "Epoch 28/100\n",
      "Avg loss: 0.0396 -- Train acc: 0.9836 -- Val acc: 0.9585 -- Test acc: 0.9571 -- Gen gap 0.0265\n",
      "Epoch 29/100\n",
      "Avg loss: 0.0384 -- Train acc: 0.9850 -- Val acc: 0.9580 -- Test acc: 0.9580 -- Gen gap 0.0270\n",
      "Epoch 30/100\n",
      "Avg loss: 0.0376 -- Train acc: 0.9850 -- Val acc: 0.9576 -- Test acc: 0.9574 -- Gen gap 0.0276\n",
      "Epoch 31/100\n",
      "Avg loss: 0.0365 -- Train acc: 0.9846 -- Val acc: 0.9584 -- Test acc: 0.9572 -- Gen gap 0.0274\n",
      "Epoch 32/100\n",
      "Avg loss: 0.0355 -- Train acc: 0.9850 -- Val acc: 0.9585 -- Test acc: 0.9568 -- Gen gap 0.0282\n",
      "Epoch 33/100\n",
      "Avg loss: 0.0342 -- Train acc: 0.9854 -- Val acc: 0.9587 -- Test acc: 0.9571 -- Gen gap 0.0283\n",
      "Epoch 34/100\n",
      "Avg loss: 0.0344 -- Train acc: 0.9856 -- Val acc: 0.9587 -- Test acc: 0.9589 -- Gen gap 0.0267\n",
      "Epoch 35/100\n",
      "Avg loss: 0.0325 -- Train acc: 0.9852 -- Val acc: 0.9578 -- Test acc: 0.9577 -- Gen gap 0.0275\n",
      "Epoch 36/100\n",
      "Avg loss: 0.0323 -- Train acc: 0.9850 -- Val acc: 0.9588 -- Test acc: 0.9574 -- Gen gap 0.0276\n",
      "Epoch 37/100\n",
      "Avg loss: 0.0313 -- Train acc: 0.9864 -- Val acc: 0.9583 -- Test acc: 0.9574 -- Gen gap 0.0289\n",
      "Epoch 38/100\n",
      "Avg loss: 0.0312 -- Train acc: 0.9862 -- Val acc: 0.9585 -- Test acc: 0.9568 -- Gen gap 0.0293\n",
      "Epoch 39/100\n",
      "Avg loss: 0.0297 -- Train acc: 0.9867 -- Val acc: 0.9581 -- Test acc: 0.9568 -- Gen gap 0.0299\n",
      "Epoch 40/100\n",
      "Avg loss: 0.0288 -- Train acc: 0.9866 -- Val acc: 0.9590 -- Test acc: 0.9572 -- Gen gap 0.0293\n",
      "Epoch 41/100\n",
      "Avg loss: 0.0282 -- Train acc: 0.9864 -- Val acc: 0.9581 -- Test acc: 0.9566 -- Gen gap 0.0297\n",
      "Epoch 42/100\n",
      "Avg loss: 0.0275 -- Train acc: 0.9869 -- Val acc: 0.9586 -- Test acc: 0.9577 -- Gen gap 0.0292\n",
      "Epoch 43/100\n",
      "Avg loss: 0.0267 -- Train acc: 0.9871 -- Val acc: 0.9587 -- Test acc: 0.9574 -- Gen gap 0.0297\n",
      "Epoch 44/100\n",
      "Avg loss: 0.0263 -- Train acc: 0.9867 -- Val acc: 0.9583 -- Test acc: 0.9577 -- Gen gap 0.0290\n",
      "Epoch 45/100\n",
      "Avg loss: 0.0261 -- Train acc: 0.9873 -- Val acc: 0.9590 -- Test acc: 0.9579 -- Gen gap 0.0294\n",
      "Epoch 46/100\n",
      "Avg loss: 0.0251 -- Train acc: 0.9875 -- Val acc: 0.9585 -- Test acc: 0.9572 -- Gen gap 0.0303\n",
      "Epoch 47/100\n",
      "Avg loss: 0.0245 -- Train acc: 0.9875 -- Val acc: 0.9585 -- Test acc: 0.9572 -- Gen gap 0.0303\n",
      "Epoch 48/100\n",
      "Avg loss: 0.0240 -- Train acc: 0.9875 -- Val acc: 0.9586 -- Test acc: 0.9577 -- Gen gap 0.0298\n",
      "Epoch 49/100\n",
      "Avg loss: 0.0252 -- Train acc: 0.9848 -- Val acc: 0.9566 -- Test acc: 0.9540 -- Gen gap 0.0307\n",
      "Epoch 50/100\n",
      "Avg loss: 0.0235 -- Train acc: 0.9875 -- Val acc: 0.9586 -- Test acc: 0.9575 -- Gen gap 0.0300\n",
      "Epoch 51/100\n",
      "Avg loss: 0.0224 -- Train acc: 0.9875 -- Val acc: 0.9585 -- Test acc: 0.9576 -- Gen gap 0.0299\n",
      "Epoch 52/100\n",
      "Avg loss: 0.0222 -- Train acc: 0.9875 -- Val acc: 0.9583 -- Test acc: 0.9576 -- Gen gap 0.0299\n",
      "Epoch 53/100\n",
      "Avg loss: 0.0220 -- Train acc: 0.9877 -- Val acc: 0.9588 -- Test acc: 0.9574 -- Gen gap 0.0303\n",
      "Epoch 54/100\n",
      "Avg loss: 0.0214 -- Train acc: 0.9879 -- Val acc: 0.9584 -- Test acc: 0.9574 -- Gen gap 0.0305\n",
      "Epoch 55/100\n",
      "Avg loss: 0.0209 -- Train acc: 0.9881 -- Val acc: 0.9583 -- Test acc: 0.9572 -- Gen gap 0.0309\n",
      "Epoch 56/100\n",
      "Avg loss: 0.0206 -- Train acc: 0.9881 -- Val acc: 0.9592 -- Test acc: 0.9573 -- Gen gap 0.0308\n",
      "Epoch 57/100\n",
      "Avg loss: 0.0200 -- Train acc: 0.9881 -- Val acc: 0.9588 -- Test acc: 0.9571 -- Gen gap 0.0310\n",
      "Epoch 58/100\n",
      "Avg loss: 0.0197 -- Train acc: 0.9881 -- Val acc: 0.9586 -- Test acc: 0.9575 -- Gen gap 0.0306\n",
      "Epoch 59/100\n",
      "Avg loss: 0.0199 -- Train acc: 0.9881 -- Val acc: 0.9586 -- Test acc: 0.9567 -- Gen gap 0.0314\n",
      "Epoch 60/100\n",
      "Avg loss: 0.0191 -- Train acc: 0.9881 -- Val acc: 0.9589 -- Test acc: 0.9575 -- Gen gap 0.0306\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.0188 -- Train acc: 0.9883 -- Val acc: 0.9587 -- Test acc: 0.9575 -- Gen gap 0.0308\n",
      "Epoch 62/100\n",
      "Avg loss: 0.0184 -- Train acc: 0.9883 -- Val acc: 0.9584 -- Test acc: 0.9570 -- Gen gap 0.0313\n",
      "Epoch 63/100\n",
      "Avg loss: 0.0186 -- Train acc: 0.9881 -- Val acc: 0.9590 -- Test acc: 0.9566 -- Gen gap 0.0315\n",
      "Epoch 64/100\n",
      "Avg loss: 0.0180 -- Train acc: 0.9883 -- Val acc: 0.9579 -- Test acc: 0.9576 -- Gen gap 0.0307\n",
      "Epoch 65/100\n",
      "Avg loss: 0.0175 -- Train acc: 0.9885 -- Val acc: 0.9585 -- Test acc: 0.9572 -- Gen gap 0.0313\n",
      "Epoch 66/100\n",
      "Avg loss: 0.0174 -- Train acc: 0.9885 -- Val acc: 0.9587 -- Test acc: 0.9573 -- Gen gap 0.0312\n",
      "Epoch 67/100\n",
      "Avg loss: 0.0168 -- Train acc: 0.9885 -- Val acc: 0.9586 -- Test acc: 0.9571 -- Gen gap 0.0314\n",
      "Epoch 68/100\n",
      "Avg loss: 0.0168 -- Train acc: 0.9885 -- Val acc: 0.9589 -- Test acc: 0.9575 -- Gen gap 0.0310\n",
      "Epoch 69/100\n",
      "Avg loss: 0.0165 -- Train acc: 0.9885 -- Val acc: 0.9581 -- Test acc: 0.9572 -- Gen gap 0.0313\n",
      "Epoch 70/100\n",
      "Avg loss: 0.0163 -- Train acc: 0.9885 -- Val acc: 0.9579 -- Test acc: 0.9571 -- Gen gap 0.0314\n",
      "Epoch 71/100\n",
      "Avg loss: 0.0158 -- Train acc: 0.9885 -- Val acc: 0.9589 -- Test acc: 0.9577 -- Gen gap 0.0308\n",
      "Epoch 72/100\n",
      "Avg loss: 0.0162 -- Train acc: 0.9885 -- Val acc: 0.9574 -- Test acc: 0.9559 -- Gen gap 0.0326\n",
      "Epoch 73/100\n",
      "Avg loss: 0.0155 -- Train acc: 0.9885 -- Val acc: 0.9581 -- Test acc: 0.9577 -- Gen gap 0.0308\n",
      "Epoch 74/100\n",
      "Avg loss: 0.0154 -- Train acc: 0.9885 -- Val acc: 0.9584 -- Test acc: 0.9581 -- Gen gap 0.0304\n",
      "Epoch 75/100\n",
      "Avg loss: 0.0149 -- Train acc: 0.9885 -- Val acc: 0.9580 -- Test acc: 0.9575 -- Gen gap 0.0310\n",
      "Epoch 76/100\n",
      "Avg loss: 0.0148 -- Train acc: 0.9885 -- Val acc: 0.9587 -- Test acc: 0.9578 -- Gen gap 0.0307\n",
      "Epoch 77/100\n",
      "Avg loss: 0.0147 -- Train acc: 0.9885 -- Val acc: 0.9583 -- Test acc: 0.9574 -- Gen gap 0.0311\n",
      "Epoch 78/100\n",
      "Avg loss: 0.0144 -- Train acc: 0.9885 -- Val acc: 0.9585 -- Test acc: 0.9575 -- Gen gap 0.0310\n",
      "Epoch 79/100\n",
      "Avg loss: 0.0144 -- Train acc: 0.9885 -- Val acc: 0.9580 -- Test acc: 0.9578 -- Gen gap 0.0307\n",
      "Epoch 80/100\n",
      "Avg loss: 0.0140 -- Train acc: 0.9885 -- Val acc: 0.9583 -- Test acc: 0.9571 -- Gen gap 0.0314\n",
      "Epoch 81/100\n",
      "Avg loss: 0.0139 -- Train acc: 0.9885 -- Val acc: 0.9583 -- Test acc: 0.9576 -- Gen gap 0.0309\n",
      "Epoch 82/100\n",
      "Avg loss: 0.0136 -- Train acc: 0.9885 -- Val acc: 0.9586 -- Test acc: 0.9577 -- Gen gap 0.0308\n",
      "Epoch 83/100\n",
      "Avg loss: 0.0137 -- Train acc: 0.9885 -- Val acc: 0.9584 -- Test acc: 0.9574 -- Gen gap 0.0311\n",
      "Epoch 84/100\n",
      "Avg loss: 0.0133 -- Train acc: 0.9885 -- Val acc: 0.9585 -- Test acc: 0.9573 -- Gen gap 0.0312\n",
      "Epoch 85/100\n",
      "Avg loss: 0.0131 -- Train acc: 0.9885 -- Val acc: 0.9580 -- Test acc: 0.9578 -- Gen gap 0.0307\n",
      "Epoch 86/100\n",
      "Avg loss: 0.0130 -- Train acc: 0.9885 -- Val acc: 0.9584 -- Test acc: 0.9577 -- Gen gap 0.0308\n",
      "Epoch 87/100\n",
      "Avg loss: 0.0129 -- Train acc: 0.9885 -- Val acc: 0.9589 -- Test acc: 0.9573 -- Gen gap 0.0312\n",
      "Epoch 88/100\n",
      "Avg loss: 0.0127 -- Train acc: 0.9885 -- Val acc: 0.9578 -- Test acc: 0.9563 -- Gen gap 0.0322\n",
      "Epoch 89/100\n",
      "Avg loss: 0.0126 -- Train acc: 0.9885 -- Val acc: 0.9581 -- Test acc: 0.9571 -- Gen gap 0.0314\n",
      "Epoch 90/100\n",
      "Avg loss: 0.0138 -- Train acc: 0.9883 -- Val acc: 0.9572 -- Test acc: 0.9559 -- Gen gap 0.0324\n",
      "Epoch 91/100\n",
      "Avg loss: 0.0130 -- Train acc: 0.9887 -- Val acc: 0.9580 -- Test acc: 0.9568 -- Gen gap 0.0319\n",
      "Epoch 92/100\n",
      "Avg loss: 0.0121 -- Train acc: 0.9887 -- Val acc: 0.9582 -- Test acc: 0.9573 -- Gen gap 0.0314\n",
      "Epoch 93/100\n",
      "Avg loss: 0.0118 -- Train acc: 0.9887 -- Val acc: 0.9583 -- Test acc: 0.9576 -- Gen gap 0.0311\n",
      "Epoch 94/100\n",
      "Avg loss: 0.0119 -- Train acc: 0.9887 -- Val acc: 0.9582 -- Test acc: 0.9571 -- Gen gap 0.0316\n",
      "Epoch 95/100\n",
      "Avg loss: 0.0115 -- Train acc: 0.9887 -- Val acc: 0.9581 -- Test acc: 0.9579 -- Gen gap 0.0308\n",
      "Epoch 96/100\n",
      "Avg loss: 0.0113 -- Train acc: 0.9887 -- Val acc: 0.9583 -- Test acc: 0.9576 -- Gen gap 0.0311\n",
      "Epoch 97/100\n",
      "Avg loss: 0.0112 -- Train acc: 0.9887 -- Val acc: 0.9581 -- Test acc: 0.9573 -- Gen gap 0.0314\n",
      "Epoch 98/100\n",
      "Avg loss: 0.0111 -- Train acc: 0.9887 -- Val acc: 0.9583 -- Test acc: 0.9575 -- Gen gap 0.0312\n",
      "Epoch 99/100\n",
      "Avg loss: 0.0109 -- Train acc: 0.9887 -- Val acc: 0.9582 -- Test acc: 0.9573 -- Gen gap 0.0314\n",
      "Epoch 100/100\n",
      "Avg loss: 0.0108 -- Train acc: 0.9887 -- Val acc: 0.9582 -- Test acc: 0.9575 -- Gen gap 0.0312\n",
      "Training done! Elapsed time: 0:00:33\n",
      "\n",
      "Iter 3\n",
      "Epoch 1/100\n",
      "Avg loss: 0.0996 -- Train acc: 0.9640 -- Val acc: 0.9597 -- Test acc: 0.9578 -- Gen gap 0.0062\n",
      "Epoch 2/100\n",
      "Avg loss: 0.0861 -- Train acc: 0.9662 -- Val acc: 0.9585 -- Test acc: 0.9583 -- Gen gap 0.0079\n",
      "Epoch 3/100\n",
      "Avg loss: 0.0775 -- Train acc: 0.9676 -- Val acc: 0.9590 -- Test acc: 0.9587 -- Gen gap 0.0089\n",
      "Epoch 4/100\n",
      "Avg loss: 0.0696 -- Train acc: 0.9721 -- Val acc: 0.9585 -- Test acc: 0.9577 -- Gen gap 0.0144\n",
      "Epoch 5/100\n",
      "Avg loss: 0.0636 -- Train acc: 0.9727 -- Val acc: 0.9600 -- Test acc: 0.9597 -- Gen gap 0.0130\n",
      "Epoch 6/100\n",
      "Avg loss: 0.0581 -- Train acc: 0.9721 -- Val acc: 0.9570 -- Test acc: 0.9577 -- Gen gap 0.0144\n",
      "Epoch 7/100\n",
      "Avg loss: 0.0543 -- Train acc: 0.9761 -- Val acc: 0.9591 -- Test acc: 0.9601 -- Gen gap 0.0160\n",
      "Epoch 8/100\n",
      "Avg loss: 0.0499 -- Train acc: 0.9777 -- Val acc: 0.9599 -- Test acc: 0.9601 -- Gen gap 0.0176\n",
      "Epoch 9/100\n",
      "Avg loss: 0.0525 -- Train acc: 0.9733 -- Val acc: 0.9554 -- Test acc: 0.9549 -- Gen gap 0.0184\n",
      "Epoch 10/100\n",
      "Avg loss: 0.0454 -- Train acc: 0.9790 -- Val acc: 0.9589 -- Test acc: 0.9597 -- Gen gap 0.0193\n",
      "Epoch 11/100\n",
      "Avg loss: 0.0412 -- Train acc: 0.9804 -- Val acc: 0.9597 -- Test acc: 0.9591 -- Gen gap 0.0213\n",
      "Epoch 12/100\n",
      "Avg loss: 0.0387 -- Train acc: 0.9818 -- Val acc: 0.9594 -- Test acc: 0.9601 -- Gen gap 0.0217\n",
      "Epoch 13/100\n",
      "Avg loss: 0.0368 -- Train acc: 0.9818 -- Val acc: 0.9596 -- Test acc: 0.9600 -- Gen gap 0.0218\n",
      "Epoch 14/100\n",
      "Avg loss: 0.0352 -- Train acc: 0.9818 -- Val acc: 0.9602 -- Test acc: 0.9603 -- Gen gap 0.0215\n",
      "Epoch 15/100\n",
      "Avg loss: 0.0331 -- Train acc: 0.9836 -- Val acc: 0.9598 -- Test acc: 0.9598 -- Gen gap 0.0238\n",
      "Epoch 16/100\n",
      "Avg loss: 0.0317 -- Train acc: 0.9830 -- Val acc: 0.9607 -- Test acc: 0.9608 -- Gen gap 0.0222\n",
      "Epoch 17/100\n",
      "Avg loss: 0.0300 -- Train acc: 0.9842 -- Val acc: 0.9598 -- Test acc: 0.9600 -- Gen gap 0.0242\n",
      "Epoch 18/100\n",
      "Avg loss: 0.0291 -- Train acc: 0.9844 -- Val acc: 0.9595 -- Test acc: 0.9604 -- Gen gap 0.0240\n",
      "Epoch 19/100\n",
      "Avg loss: 0.0280 -- Train acc: 0.9856 -- Val acc: 0.9591 -- Test acc: 0.9594 -- Gen gap 0.0262\n",
      "Epoch 20/100\n",
      "Avg loss: 0.0266 -- Train acc: 0.9862 -- Val acc: 0.9592 -- Test acc: 0.9607 -- Gen gap 0.0255\n",
      "Epoch 21/100\n",
      "Avg loss: 0.0261 -- Train acc: 0.9862 -- Val acc: 0.9586 -- Test acc: 0.9601 -- Gen gap 0.0261\n",
      "Epoch 22/100\n",
      "Avg loss: 0.0248 -- Train acc: 0.9866 -- Val acc: 0.9597 -- Test acc: 0.9605 -- Gen gap 0.0261\n",
      "Epoch 23/100\n",
      "Avg loss: 0.0238 -- Train acc: 0.9869 -- Val acc: 0.9603 -- Test acc: 0.9608 -- Gen gap 0.0262\n",
      "Epoch 24/100\n",
      "Avg loss: 0.0231 -- Train acc: 0.9875 -- Val acc: 0.9599 -- Test acc: 0.9605 -- Gen gap 0.0270\n",
      "Epoch 25/100\n",
      "Avg loss: 0.0223 -- Train acc: 0.9873 -- Val acc: 0.9596 -- Test acc: 0.9603 -- Gen gap 0.0271\n",
      "Epoch 26/100\n",
      "Avg loss: 0.0215 -- Train acc: 0.9877 -- Val acc: 0.9598 -- Test acc: 0.9604 -- Gen gap 0.0273\n",
      "Epoch 27/100\n",
      "Avg loss: 0.0209 -- Train acc: 0.9875 -- Val acc: 0.9598 -- Test acc: 0.9610 -- Gen gap 0.0266\n",
      "Epoch 28/100\n",
      "Avg loss: 0.0202 -- Train acc: 0.9879 -- Val acc: 0.9600 -- Test acc: 0.9610 -- Gen gap 0.0269\n",
      "Epoch 29/100\n",
      "Avg loss: 0.0200 -- Train acc: 0.9879 -- Val acc: 0.9594 -- Test acc: 0.9604 -- Gen gap 0.0275\n",
      "Epoch 30/100\n",
      "Avg loss: 0.0192 -- Train acc: 0.9879 -- Val acc: 0.9596 -- Test acc: 0.9610 -- Gen gap 0.0269\n",
      "Epoch 31/100\n",
      "Avg loss: 0.0186 -- Train acc: 0.9881 -- Val acc: 0.9601 -- Test acc: 0.9612 -- Gen gap 0.0269\n",
      "Epoch 32/100\n",
      "Avg loss: 0.0185 -- Train acc: 0.9879 -- Val acc: 0.9589 -- Test acc: 0.9603 -- Gen gap 0.0276\n",
      "Epoch 33/100\n",
      "Avg loss: 0.0176 -- Train acc: 0.9881 -- Val acc: 0.9603 -- Test acc: 0.9607 -- Gen gap 0.0274\n",
      "Epoch 34/100\n",
      "Avg loss: 0.0172 -- Train acc: 0.9881 -- Val acc: 0.9601 -- Test acc: 0.9605 -- Gen gap 0.0276\n",
      "Epoch 35/100\n",
      "Avg loss: 0.0167 -- Train acc: 0.9881 -- Val acc: 0.9596 -- Test acc: 0.9611 -- Gen gap 0.0270\n",
      "Epoch 36/100\n",
      "Avg loss: 0.0163 -- Train acc: 0.9883 -- Val acc: 0.9596 -- Test acc: 0.9611 -- Gen gap 0.0272\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.0158 -- Train acc: 0.9881 -- Val acc: 0.9605 -- Test acc: 0.9610 -- Gen gap 0.0271\n",
      "Epoch 38/100\n",
      "Avg loss: 0.0158 -- Train acc: 0.9883 -- Val acc: 0.9604 -- Test acc: 0.9612 -- Gen gap 0.0271\n",
      "Epoch 39/100\n",
      "Avg loss: 0.0154 -- Train acc: 0.9883 -- Val acc: 0.9606 -- Test acc: 0.9612 -- Gen gap 0.0271\n",
      "Epoch 40/100\n",
      "Avg loss: 0.0150 -- Train acc: 0.9883 -- Val acc: 0.9597 -- Test acc: 0.9610 -- Gen gap 0.0273\n",
      "Epoch 41/100\n",
      "Avg loss: 0.0145 -- Train acc: 0.9883 -- Val acc: 0.9595 -- Test acc: 0.9609 -- Gen gap 0.0274\n",
      "Epoch 42/100\n",
      "Avg loss: 0.0142 -- Train acc: 0.9883 -- Val acc: 0.9604 -- Test acc: 0.9611 -- Gen gap 0.0272\n",
      "Epoch 43/100\n",
      "Avg loss: 0.0140 -- Train acc: 0.9883 -- Val acc: 0.9600 -- Test acc: 0.9616 -- Gen gap 0.0267\n",
      "Epoch 44/100\n",
      "Avg loss: 0.0137 -- Train acc: 0.9883 -- Val acc: 0.9601 -- Test acc: 0.9611 -- Gen gap 0.0272\n",
      "Epoch 45/100\n",
      "Avg loss: 0.0138 -- Train acc: 0.9879 -- Val acc: 0.9589 -- Test acc: 0.9605 -- Gen gap 0.0274\n",
      "Epoch 46/100\n",
      "Avg loss: 0.0133 -- Train acc: 0.9883 -- Val acc: 0.9596 -- Test acc: 0.9608 -- Gen gap 0.0275\n",
      "Epoch 47/100\n",
      "Avg loss: 0.0127 -- Train acc: 0.9885 -- Val acc: 0.9601 -- Test acc: 0.9612 -- Gen gap 0.0273\n",
      "Epoch 48/100\n",
      "Avg loss: 0.0126 -- Train acc: 0.9883 -- Val acc: 0.9605 -- Test acc: 0.9609 -- Gen gap 0.0274\n",
      "Epoch 49/100\n",
      "Avg loss: 0.0123 -- Train acc: 0.9885 -- Val acc: 0.9604 -- Test acc: 0.9610 -- Gen gap 0.0275\n",
      "Epoch 50/100\n",
      "Avg loss: 0.0122 -- Train acc: 0.9885 -- Val acc: 0.9602 -- Test acc: 0.9609 -- Gen gap 0.0276\n",
      "Epoch 51/100\n",
      "Avg loss: 0.0120 -- Train acc: 0.9887 -- Val acc: 0.9601 -- Test acc: 0.9609 -- Gen gap 0.0278\n",
      "Epoch 52/100\n",
      "Avg loss: 0.0116 -- Train acc: 0.9887 -- Val acc: 0.9596 -- Test acc: 0.9613 -- Gen gap 0.0274\n",
      "Epoch 53/100\n",
      "Avg loss: 0.0116 -- Train acc: 0.9887 -- Val acc: 0.9600 -- Test acc: 0.9615 -- Gen gap 0.0272\n",
      "Epoch 54/100\n",
      "Avg loss: 0.0115 -- Train acc: 0.9887 -- Val acc: 0.9593 -- Test acc: 0.9608 -- Gen gap 0.0279\n",
      "Epoch 55/100\n",
      "Avg loss: 0.0111 -- Train acc: 0.9887 -- Val acc: 0.9596 -- Test acc: 0.9615 -- Gen gap 0.0272\n",
      "Epoch 56/100\n",
      "Avg loss: 0.0108 -- Train acc: 0.9887 -- Val acc: 0.9589 -- Test acc: 0.9623 -- Gen gap 0.0264\n",
      "Epoch 57/100\n",
      "Avg loss: 0.0106 -- Train acc: 0.9889 -- Val acc: 0.9600 -- Test acc: 0.9614 -- Gen gap 0.0275\n",
      "Epoch 58/100\n",
      "Avg loss: 0.0106 -- Train acc: 0.9889 -- Val acc: 0.9591 -- Test acc: 0.9617 -- Gen gap 0.0272\n",
      "Epoch 59/100\n",
      "Avg loss: 0.0104 -- Train acc: 0.9887 -- Val acc: 0.9606 -- Test acc: 0.9619 -- Gen gap 0.0268\n",
      "Epoch 60/100\n",
      "Avg loss: 0.0103 -- Train acc: 0.9889 -- Val acc: 0.9599 -- Test acc: 0.9612 -- Gen gap 0.0277\n",
      "Epoch 61/100\n",
      "Avg loss: 0.0104 -- Train acc: 0.9887 -- Val acc: 0.9599 -- Test acc: 0.9612 -- Gen gap 0.0275\n",
      "Epoch 62/100\n",
      "Avg loss: 0.0102 -- Train acc: 0.9889 -- Val acc: 0.9596 -- Test acc: 0.9614 -- Gen gap 0.0275\n",
      "Epoch 63/100\n",
      "Avg loss: 0.0098 -- Train acc: 0.9889 -- Val acc: 0.9597 -- Test acc: 0.9617 -- Gen gap 0.0272\n",
      "Epoch 64/100\n",
      "Avg loss: 0.0097 -- Train acc: 0.9889 -- Val acc: 0.9598 -- Test acc: 0.9616 -- Gen gap 0.0273\n",
      "Epoch 65/100\n",
      "Avg loss: 0.0096 -- Train acc: 0.9889 -- Val acc: 0.9604 -- Test acc: 0.9614 -- Gen gap 0.0275\n",
      "Epoch 66/100\n",
      "Avg loss: 0.0097 -- Train acc: 0.9889 -- Val acc: 0.9598 -- Test acc: 0.9611 -- Gen gap 0.0278\n",
      "Epoch 67/100\n",
      "Avg loss: 0.0097 -- Train acc: 0.9889 -- Val acc: 0.9604 -- Test acc: 0.9614 -- Gen gap 0.0275\n",
      "Epoch 68/100\n",
      "Avg loss: 0.0092 -- Train acc: 0.9889 -- Val acc: 0.9603 -- Test acc: 0.9617 -- Gen gap 0.0272\n",
      "Epoch 69/100\n",
      "Avg loss: 0.0089 -- Train acc: 0.9889 -- Val acc: 0.9603 -- Test acc: 0.9620 -- Gen gap 0.0269\n",
      "Epoch 70/100\n",
      "Avg loss: 0.0091 -- Train acc: 0.9889 -- Val acc: 0.9590 -- Test acc: 0.9616 -- Gen gap 0.0273\n",
      "Epoch 71/100\n",
      "Avg loss: 0.0091 -- Train acc: 0.9889 -- Val acc: 0.9599 -- Test acc: 0.9614 -- Gen gap 0.0275\n",
      "Epoch 72/100\n",
      "Avg loss: 0.0088 -- Train acc: 0.9889 -- Val acc: 0.9597 -- Test acc: 0.9614 -- Gen gap 0.0275\n",
      "Epoch 73/100\n",
      "Avg loss: 0.0085 -- Train acc: 0.9889 -- Val acc: 0.9604 -- Test acc: 0.9618 -- Gen gap 0.0271\n",
      "Epoch 74/100\n",
      "Avg loss: 0.0087 -- Train acc: 0.9889 -- Val acc: 0.9602 -- Test acc: 0.9621 -- Gen gap 0.0268\n",
      "Epoch 75/100\n",
      "Avg loss: 0.0084 -- Train acc: 0.9889 -- Val acc: 0.9601 -- Test acc: 0.9612 -- Gen gap 0.0277\n",
      "Epoch 76/100\n",
      "Avg loss: 0.0083 -- Train acc: 0.9889 -- Val acc: 0.9605 -- Test acc: 0.9618 -- Gen gap 0.0271\n",
      "Epoch 77/100\n",
      "Avg loss: 0.0081 -- Train acc: 0.9889 -- Val acc: 0.9604 -- Test acc: 0.9618 -- Gen gap 0.0271\n",
      "Epoch 78/100\n",
      "Avg loss: 0.0080 -- Train acc: 0.9889 -- Val acc: 0.9603 -- Test acc: 0.9623 -- Gen gap 0.0266\n",
      "Epoch 79/100\n",
      "Avg loss: 0.0080 -- Train acc: 0.9889 -- Val acc: 0.9599 -- Test acc: 0.9613 -- Gen gap 0.0276\n",
      "Epoch 80/100\n",
      "Avg loss: 0.0079 -- Train acc: 0.9889 -- Val acc: 0.9600 -- Test acc: 0.9617 -- Gen gap 0.0272\n",
      "Epoch 81/100\n",
      "Avg loss: 0.0079 -- Train acc: 0.9889 -- Val acc: 0.9603 -- Test acc: 0.9619 -- Gen gap 0.0270\n",
      "Epoch 82/100\n",
      "Avg loss: 0.0076 -- Train acc: 0.9889 -- Val acc: 0.9602 -- Test acc: 0.9623 -- Gen gap 0.0266\n",
      "Epoch 83/100\n",
      "Avg loss: 0.0076 -- Train acc: 0.9889 -- Val acc: 0.9603 -- Test acc: 0.9623 -- Gen gap 0.0266\n",
      "Epoch 84/100\n",
      "Avg loss: 0.0074 -- Train acc: 0.9889 -- Val acc: 0.9603 -- Test acc: 0.9620 -- Gen gap 0.0269\n",
      "Epoch 85/100\n",
      "Avg loss: 0.0074 -- Train acc: 0.9889 -- Val acc: 0.9600 -- Test acc: 0.9623 -- Gen gap 0.0266\n",
      "Epoch 86/100\n",
      "Avg loss: 0.0073 -- Train acc: 0.9889 -- Val acc: 0.9603 -- Test acc: 0.9622 -- Gen gap 0.0267\n",
      "Epoch 87/100\n",
      "Avg loss: 0.0072 -- Train acc: 0.9889 -- Val acc: 0.9603 -- Test acc: 0.9619 -- Gen gap 0.0270\n",
      "Epoch 88/100\n",
      "Avg loss: 0.0071 -- Train acc: 0.9889 -- Val acc: 0.9604 -- Test acc: 0.9624 -- Gen gap 0.0265\n",
      "Epoch 89/100\n",
      "Avg loss: 0.0071 -- Train acc: 0.9889 -- Val acc: 0.9601 -- Test acc: 0.9621 -- Gen gap 0.0268\n",
      "Epoch 90/100\n",
      "Avg loss: 0.0070 -- Train acc: 0.9889 -- Val acc: 0.9601 -- Test acc: 0.9624 -- Gen gap 0.0265\n",
      "Epoch 91/100\n",
      "Avg loss: 0.0069 -- Train acc: 0.9889 -- Val acc: 0.9601 -- Test acc: 0.9624 -- Gen gap 0.0265\n",
      "Epoch 92/100\n",
      "Avg loss: 0.0069 -- Train acc: 0.9889 -- Val acc: 0.9607 -- Test acc: 0.9618 -- Gen gap 0.0271\n",
      "Epoch 93/100\n",
      "Avg loss: 0.0068 -- Train acc: 0.9889 -- Val acc: 0.9602 -- Test acc: 0.9624 -- Gen gap 0.0265\n",
      "Epoch 94/100\n",
      "Avg loss: 0.0067 -- Train acc: 0.9889 -- Val acc: 0.9602 -- Test acc: 0.9622 -- Gen gap 0.0267\n",
      "Epoch 95/100\n",
      "Avg loss: 0.0067 -- Train acc: 0.9889 -- Val acc: 0.9605 -- Test acc: 0.9623 -- Gen gap 0.0266\n",
      "Epoch 96/100\n",
      "Avg loss: 0.0066 -- Train acc: 0.9889 -- Val acc: 0.9601 -- Test acc: 0.9623 -- Gen gap 0.0266\n",
      "Epoch 97/100\n",
      "Avg loss: 0.0066 -- Train acc: 0.9889 -- Val acc: 0.9601 -- Test acc: 0.9622 -- Gen gap 0.0267\n",
      "Epoch 98/100\n",
      "Avg loss: 0.0065 -- Train acc: 0.9889 -- Val acc: 0.9601 -- Test acc: 0.9617 -- Gen gap 0.0272\n",
      "Epoch 99/100\n",
      "Avg loss: 0.0066 -- Train acc: 0.9889 -- Val acc: 0.9604 -- Test acc: 0.9621 -- Gen gap 0.0268\n",
      "Epoch 100/100\n",
      "Avg loss: 0.0064 -- Train acc: 0.9889 -- Val acc: 0.9602 -- Test acc: 0.9622 -- Gen gap 0.0267\n",
      "Training done! Elapsed time: 0:00:34\n",
      "\n",
      "==============================\n",
      "a = 1.00, Na = 50000\n",
      "------------------------------\n",
      "Iter 1\n",
      "Epoch 1/100\n",
      "Avg loss: 0.0938 -- Train acc: 0.9768 -- Val acc: 0.9650 -- Test acc: 0.9642 -- Gen gap 0.0127\n",
      "Epoch 2/100\n",
      "Avg loss: 0.0780 -- Train acc: 0.9788 -- Val acc: 0.9656 -- Test acc: 0.9656 -- Gen gap 0.0132\n",
      "Epoch 3/100\n",
      "Avg loss: 0.0692 -- Train acc: 0.9812 -- Val acc: 0.9663 -- Test acc: 0.9661 -- Gen gap 0.0151\n",
      "Epoch 4/100\n",
      "Avg loss: 0.0640 -- Train acc: 0.9822 -- Val acc: 0.9682 -- Test acc: 0.9668 -- Gen gap 0.0154\n",
      "Epoch 5/100\n",
      "Avg loss: 0.0590 -- Train acc: 0.9844 -- Val acc: 0.9696 -- Test acc: 0.9678 -- Gen gap 0.0166\n",
      "Epoch 6/100\n",
      "Avg loss: 0.0553 -- Train acc: 0.9854 -- Val acc: 0.9694 -- Test acc: 0.9681 -- Gen gap 0.0174\n",
      "Epoch 7/100\n",
      "Avg loss: 0.0524 -- Train acc: 0.9857 -- Val acc: 0.9701 -- Test acc: 0.9687 -- Gen gap 0.0171\n",
      "Epoch 8/100\n",
      "Avg loss: 0.0496 -- Train acc: 0.9865 -- Val acc: 0.9691 -- Test acc: 0.9684 -- Gen gap 0.0181\n",
      "Epoch 9/100\n",
      "Avg loss: 0.0470 -- Train acc: 0.9873 -- Val acc: 0.9694 -- Test acc: 0.9685 -- Gen gap 0.0189\n",
      "Epoch 10/100\n",
      "Avg loss: 0.0447 -- Train acc: 0.9886 -- Val acc: 0.9711 -- Test acc: 0.9691 -- Gen gap 0.0194\n",
      "Epoch 11/100\n",
      "Avg loss: 0.0428 -- Train acc: 0.9890 -- Val acc: 0.9709 -- Test acc: 0.9696 -- Gen gap 0.0193\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.0407 -- Train acc: 0.9891 -- Val acc: 0.9709 -- Test acc: 0.9693 -- Gen gap 0.0198\n",
      "Epoch 13/100\n",
      "Avg loss: 0.0390 -- Train acc: 0.9900 -- Val acc: 0.9719 -- Test acc: 0.9694 -- Gen gap 0.0206\n",
      "Epoch 14/100\n",
      "Avg loss: 0.0375 -- Train acc: 0.9908 -- Val acc: 0.9718 -- Test acc: 0.9697 -- Gen gap 0.0210\n",
      "Epoch 15/100\n",
      "Avg loss: 0.0358 -- Train acc: 0.9915 -- Val acc: 0.9723 -- Test acc: 0.9705 -- Gen gap 0.0209\n",
      "Epoch 16/100\n",
      "Avg loss: 0.0345 -- Train acc: 0.9918 -- Val acc: 0.9725 -- Test acc: 0.9701 -- Gen gap 0.0217\n",
      "Epoch 17/100\n",
      "Avg loss: 0.0332 -- Train acc: 0.9925 -- Val acc: 0.9724 -- Test acc: 0.9702 -- Gen gap 0.0222\n",
      "Epoch 18/100\n",
      "Avg loss: 0.0319 -- Train acc: 0.9919 -- Val acc: 0.9711 -- Test acc: 0.9707 -- Gen gap 0.0212\n",
      "Epoch 19/100\n",
      "Avg loss: 0.0306 -- Train acc: 0.9930 -- Val acc: 0.9719 -- Test acc: 0.9708 -- Gen gap 0.0222\n",
      "Epoch 20/100\n",
      "Avg loss: 0.0295 -- Train acc: 0.9938 -- Val acc: 0.9722 -- Test acc: 0.9710 -- Gen gap 0.0228\n",
      "Epoch 21/100\n",
      "Avg loss: 0.0286 -- Train acc: 0.9935 -- Val acc: 0.9736 -- Test acc: 0.9706 -- Gen gap 0.0229\n",
      "Epoch 22/100\n",
      "Avg loss: 0.0276 -- Train acc: 0.9937 -- Val acc: 0.9728 -- Test acc: 0.9705 -- Gen gap 0.0232\n",
      "Epoch 23/100\n",
      "Avg loss: 0.0266 -- Train acc: 0.9948 -- Val acc: 0.9735 -- Test acc: 0.9706 -- Gen gap 0.0241\n",
      "Epoch 24/100\n",
      "Avg loss: 0.0254 -- Train acc: 0.9948 -- Val acc: 0.9728 -- Test acc: 0.9705 -- Gen gap 0.0243\n",
      "Epoch 25/100\n",
      "Avg loss: 0.0247 -- Train acc: 0.9950 -- Val acc: 0.9730 -- Test acc: 0.9722 -- Gen gap 0.0228\n",
      "Epoch 26/100\n",
      "Avg loss: 0.0236 -- Train acc: 0.9952 -- Val acc: 0.9735 -- Test acc: 0.9704 -- Gen gap 0.0247\n",
      "Epoch 27/100\n",
      "Avg loss: 0.0228 -- Train acc: 0.9957 -- Val acc: 0.9732 -- Test acc: 0.9707 -- Gen gap 0.0249\n",
      "Epoch 28/100\n",
      "Avg loss: 0.0222 -- Train acc: 0.9954 -- Val acc: 0.9731 -- Test acc: 0.9729 -- Gen gap 0.0225\n",
      "Epoch 29/100\n",
      "Avg loss: 0.0214 -- Train acc: 0.9958 -- Val acc: 0.9739 -- Test acc: 0.9716 -- Gen gap 0.0242\n",
      "Epoch 30/100\n",
      "Avg loss: 0.0205 -- Train acc: 0.9961 -- Val acc: 0.9735 -- Test acc: 0.9709 -- Gen gap 0.0251\n",
      "Epoch 31/100\n",
      "Avg loss: 0.0201 -- Train acc: 0.9964 -- Val acc: 0.9743 -- Test acc: 0.9722 -- Gen gap 0.0242\n",
      "Epoch 32/100\n",
      "Avg loss: 0.0193 -- Train acc: 0.9965 -- Val acc: 0.9736 -- Test acc: 0.9713 -- Gen gap 0.0252\n",
      "Epoch 33/100\n",
      "Avg loss: 0.0188 -- Train acc: 0.9968 -- Val acc: 0.9740 -- Test acc: 0.9717 -- Gen gap 0.0251\n",
      "Epoch 34/100\n",
      "Avg loss: 0.0180 -- Train acc: 0.9967 -- Val acc: 0.9743 -- Test acc: 0.9718 -- Gen gap 0.0249\n",
      "Epoch 35/100\n",
      "Avg loss: 0.0176 -- Train acc: 0.9970 -- Val acc: 0.9744 -- Test acc: 0.9726 -- Gen gap 0.0243\n",
      "Epoch 36/100\n",
      "Avg loss: 0.0170 -- Train acc: 0.9972 -- Val acc: 0.9736 -- Test acc: 0.9719 -- Gen gap 0.0252\n",
      "Epoch 37/100\n",
      "Avg loss: 0.0165 -- Train acc: 0.9966 -- Val acc: 0.9743 -- Test acc: 0.9726 -- Gen gap 0.0240\n",
      "Epoch 38/100\n",
      "Avg loss: 0.0160 -- Train acc: 0.9972 -- Val acc: 0.9737 -- Test acc: 0.9722 -- Gen gap 0.0250\n",
      "Epoch 39/100\n",
      "Avg loss: 0.0155 -- Train acc: 0.9973 -- Val acc: 0.9750 -- Test acc: 0.9728 -- Gen gap 0.0245\n",
      "Epoch 40/100\n",
      "Avg loss: 0.0150 -- Train acc: 0.9971 -- Val acc: 0.9740 -- Test acc: 0.9728 -- Gen gap 0.0243\n",
      "Epoch 41/100\n",
      "Avg loss: 0.0145 -- Train acc: 0.9974 -- Val acc: 0.9747 -- Test acc: 0.9733 -- Gen gap 0.0241\n",
      "Epoch 42/100\n",
      "Avg loss: 0.0141 -- Train acc: 0.9977 -- Val acc: 0.9746 -- Test acc: 0.9726 -- Gen gap 0.0251\n",
      "Epoch 43/100\n",
      "Avg loss: 0.0138 -- Train acc: 0.9976 -- Val acc: 0.9747 -- Test acc: 0.9724 -- Gen gap 0.0252\n",
      "Epoch 44/100\n",
      "Avg loss: 0.0133 -- Train acc: 0.9977 -- Val acc: 0.9749 -- Test acc: 0.9734 -- Gen gap 0.0243\n",
      "Epoch 45/100\n",
      "Avg loss: 0.0129 -- Train acc: 0.9977 -- Val acc: 0.9748 -- Test acc: 0.9730 -- Gen gap 0.0247\n",
      "Epoch 46/100\n",
      "Avg loss: 0.0125 -- Train acc: 0.9979 -- Val acc: 0.9749 -- Test acc: 0.9731 -- Gen gap 0.0248\n",
      "Epoch 47/100\n",
      "Avg loss: 0.0121 -- Train acc: 0.9979 -- Val acc: 0.9747 -- Test acc: 0.9735 -- Gen gap 0.0243\n",
      "Epoch 48/100\n",
      "Avg loss: 0.0118 -- Train acc: 0.9979 -- Val acc: 0.9748 -- Test acc: 0.9735 -- Gen gap 0.0244\n",
      "Epoch 49/100\n",
      "Avg loss: 0.0116 -- Train acc: 0.9981 -- Val acc: 0.9746 -- Test acc: 0.9729 -- Gen gap 0.0252\n",
      "Epoch 50/100\n",
      "Avg loss: 0.0113 -- Train acc: 0.9980 -- Val acc: 0.9743 -- Test acc: 0.9738 -- Gen gap 0.0242\n",
      "Epoch 51/100\n",
      "Avg loss: 0.0110 -- Train acc: 0.9982 -- Val acc: 0.9756 -- Test acc: 0.9731 -- Gen gap 0.0251\n",
      "Epoch 52/100\n",
      "Avg loss: 0.0106 -- Train acc: 0.9983 -- Val acc: 0.9748 -- Test acc: 0.9733 -- Gen gap 0.0250\n",
      "Epoch 53/100\n",
      "Avg loss: 0.0104 -- Train acc: 0.9984 -- Val acc: 0.9749 -- Test acc: 0.9736 -- Gen gap 0.0247\n",
      "Epoch 54/100\n",
      "Avg loss: 0.0101 -- Train acc: 0.9983 -- Val acc: 0.9739 -- Test acc: 0.9729 -- Gen gap 0.0254\n",
      "Epoch 55/100\n",
      "Avg loss: 0.0098 -- Train acc: 0.9984 -- Val acc: 0.9749 -- Test acc: 0.9733 -- Gen gap 0.0250\n",
      "Epoch 56/100\n",
      "Avg loss: 0.0096 -- Train acc: 0.9985 -- Val acc: 0.9748 -- Test acc: 0.9740 -- Gen gap 0.0244\n",
      "Epoch 57/100\n",
      "Avg loss: 0.0093 -- Train acc: 0.9984 -- Val acc: 0.9747 -- Test acc: 0.9740 -- Gen gap 0.0244\n",
      "Epoch 58/100\n",
      "Avg loss: 0.0090 -- Train acc: 0.9984 -- Val acc: 0.9748 -- Test acc: 0.9736 -- Gen gap 0.0248\n",
      "Epoch 59/100\n",
      "Avg loss: 0.0088 -- Train acc: 0.9985 -- Val acc: 0.9749 -- Test acc: 0.9733 -- Gen gap 0.0252\n",
      "Epoch 60/100\n",
      "Avg loss: 0.0086 -- Train acc: 0.9987 -- Val acc: 0.9746 -- Test acc: 0.9734 -- Gen gap 0.0253\n",
      "Epoch 61/100\n",
      "Avg loss: 0.0084 -- Train acc: 0.9986 -- Val acc: 0.9749 -- Test acc: 0.9728 -- Gen gap 0.0258\n",
      "Epoch 62/100\n",
      "Avg loss: 0.0082 -- Train acc: 0.9986 -- Val acc: 0.9745 -- Test acc: 0.9742 -- Gen gap 0.0244\n",
      "Epoch 63/100\n",
      "Avg loss: 0.0080 -- Train acc: 0.9986 -- Val acc: 0.9749 -- Test acc: 0.9742 -- Gen gap 0.0244\n",
      "Epoch 64/100\n",
      "Avg loss: 0.0078 -- Train acc: 0.9986 -- Val acc: 0.9750 -- Test acc: 0.9729 -- Gen gap 0.0257\n",
      "Epoch 65/100\n",
      "Avg loss: 0.0077 -- Train acc: 0.9987 -- Val acc: 0.9753 -- Test acc: 0.9731 -- Gen gap 0.0256\n",
      "Epoch 66/100\n",
      "Avg loss: 0.0074 -- Train acc: 0.9986 -- Val acc: 0.9749 -- Test acc: 0.9741 -- Gen gap 0.0245\n",
      "Epoch 67/100\n",
      "Avg loss: 0.0073 -- Train acc: 0.9987 -- Val acc: 0.9747 -- Test acc: 0.9735 -- Gen gap 0.0252\n",
      "Epoch 68/100\n",
      "Avg loss: 0.0071 -- Train acc: 0.9988 -- Val acc: 0.9754 -- Test acc: 0.9736 -- Gen gap 0.0251\n",
      "Epoch 69/100\n",
      "Avg loss: 0.0070 -- Train acc: 0.9988 -- Val acc: 0.9748 -- Test acc: 0.9732 -- Gen gap 0.0256\n",
      "Epoch 70/100\n",
      "Avg loss: 0.0068 -- Train acc: 0.9988 -- Val acc: 0.9746 -- Test acc: 0.9742 -- Gen gap 0.0245\n",
      "Epoch 71/100\n",
      "Avg loss: 0.0066 -- Train acc: 0.9988 -- Val acc: 0.9751 -- Test acc: 0.9737 -- Gen gap 0.0251\n",
      "Epoch 72/100\n",
      "Avg loss: 0.0065 -- Train acc: 0.9988 -- Val acc: 0.9751 -- Test acc: 0.9742 -- Gen gap 0.0245\n",
      "Epoch 73/100\n",
      "Avg loss: 0.0063 -- Train acc: 0.9988 -- Val acc: 0.9755 -- Test acc: 0.9737 -- Gen gap 0.0251\n",
      "Epoch 74/100\n",
      "Avg loss: 0.0062 -- Train acc: 0.9988 -- Val acc: 0.9752 -- Test acc: 0.9741 -- Gen gap 0.0247\n",
      "Epoch 75/100\n",
      "Avg loss: 0.0061 -- Train acc: 0.9989 -- Val acc: 0.9754 -- Test acc: 0.9740 -- Gen gap 0.0248\n",
      "Epoch 76/100\n",
      "Avg loss: 0.0059 -- Train acc: 0.9989 -- Val acc: 0.9746 -- Test acc: 0.9741 -- Gen gap 0.0248\n",
      "Epoch 77/100\n",
      "Avg loss: 0.0058 -- Train acc: 0.9989 -- Val acc: 0.9752 -- Test acc: 0.9733 -- Gen gap 0.0256\n",
      "Epoch 78/100\n",
      "Avg loss: 0.0057 -- Train acc: 0.9989 -- Val acc: 0.9753 -- Test acc: 0.9742 -- Gen gap 0.0247\n",
      "Epoch 79/100\n",
      "Avg loss: 0.0056 -- Train acc: 0.9988 -- Val acc: 0.9749 -- Test acc: 0.9743 -- Gen gap 0.0245\n",
      "Epoch 80/100\n",
      "Avg loss: 0.0055 -- Train acc: 0.9989 -- Val acc: 0.9749 -- Test acc: 0.9741 -- Gen gap 0.0248\n",
      "Epoch 81/100\n",
      "Avg loss: 0.0054 -- Train acc: 0.9989 -- Val acc: 0.9758 -- Test acc: 0.9741 -- Gen gap 0.0248\n",
      "Epoch 82/100\n",
      "Avg loss: 0.0053 -- Train acc: 0.9990 -- Val acc: 0.9758 -- Test acc: 0.9742 -- Gen gap 0.0247\n",
      "Epoch 83/100\n",
      "Avg loss: 0.0052 -- Train acc: 0.9989 -- Val acc: 0.9753 -- Test acc: 0.9737 -- Gen gap 0.0252\n",
      "Epoch 84/100\n",
      "Avg loss: 0.0051 -- Train acc: 0.9989 -- Val acc: 0.9752 -- Test acc: 0.9743 -- Gen gap 0.0246\n",
      "Epoch 85/100\n",
      "Avg loss: 0.0050 -- Train acc: 0.9990 -- Val acc: 0.9748 -- Test acc: 0.9743 -- Gen gap 0.0246\n",
      "Epoch 86/100\n",
      "Avg loss: 0.0049 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9741 -- Gen gap 0.0248\n",
      "Epoch 87/100\n",
      "Avg loss: 0.0048 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9745 -- Gen gap 0.0244\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.0047 -- Train acc: 0.9990 -- Val acc: 0.9750 -- Test acc: 0.9748 -- Gen gap 0.0241\n",
      "Epoch 89/100\n",
      "Avg loss: 0.0046 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9742 -- Gen gap 0.0248\n",
      "Epoch 90/100\n",
      "Avg loss: 0.0045 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9743 -- Gen gap 0.0247\n",
      "Epoch 91/100\n",
      "Avg loss: 0.0045 -- Train acc: 0.9990 -- Val acc: 0.9750 -- Test acc: 0.9742 -- Gen gap 0.0248\n",
      "Epoch 92/100\n",
      "Avg loss: 0.0044 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9740 -- Gen gap 0.0250\n",
      "Epoch 93/100\n",
      "Avg loss: 0.0043 -- Train acc: 0.9990 -- Val acc: 0.9749 -- Test acc: 0.9744 -- Gen gap 0.0246\n",
      "Epoch 94/100\n",
      "Avg loss: 0.0042 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9738 -- Gen gap 0.0252\n",
      "Epoch 95/100\n",
      "Avg loss: 0.0042 -- Train acc: 0.9990 -- Val acc: 0.9748 -- Test acc: 0.9743 -- Gen gap 0.0247\n",
      "Epoch 96/100\n",
      "Avg loss: 0.0041 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9740 -- Gen gap 0.0250\n",
      "Epoch 97/100\n",
      "Avg loss: 0.0040 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9744 -- Gen gap 0.0246\n",
      "Epoch 98/100\n",
      "Avg loss: 0.0040 -- Train acc: 0.9990 -- Val acc: 0.9750 -- Test acc: 0.9746 -- Gen gap 0.0244\n",
      "Epoch 99/100\n",
      "Avg loss: 0.0039 -- Train acc: 0.9990 -- Val acc: 0.9748 -- Test acc: 0.9740 -- Gen gap 0.0250\n",
      "Epoch 100/100\n",
      "Avg loss: 0.0039 -- Train acc: 0.9990 -- Val acc: 0.9748 -- Test acc: 0.9742 -- Gen gap 0.0248\n",
      "Training done! Elapsed time: 0:03:28\n",
      "\n",
      "Iter 2\n",
      "Epoch 1/100\n",
      "Avg loss: 0.0038 -- Train acc: 0.9990 -- Val acc: 0.9759 -- Test acc: 0.9745 -- Gen gap 0.0245\n",
      "Epoch 2/100\n",
      "Avg loss: 0.0037 -- Train acc: 0.9990 -- Val acc: 0.9750 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 3/100\n",
      "Avg loss: 0.0037 -- Train acc: 0.9990 -- Val acc: 0.9748 -- Test acc: 0.9741 -- Gen gap 0.0249\n",
      "Epoch 4/100\n",
      "Avg loss: 0.0036 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9742 -- Gen gap 0.0248\n",
      "Epoch 5/100\n",
      "Avg loss: 0.0036 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9745 -- Gen gap 0.0245\n",
      "Epoch 6/100\n",
      "Avg loss: 0.0035 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9747 -- Gen gap 0.0243\n",
      "Epoch 7/100\n",
      "Avg loss: 0.0035 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9743 -- Gen gap 0.0247\n",
      "Epoch 8/100\n",
      "Avg loss: 0.0034 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9745 -- Gen gap 0.0245\n",
      "Epoch 9/100\n",
      "Avg loss: 0.0034 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9743 -- Gen gap 0.0247\n",
      "Epoch 10/100\n",
      "Avg loss: 0.0033 -- Train acc: 0.9990 -- Val acc: 0.9756 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 11/100\n",
      "Avg loss: 0.0033 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9746 -- Gen gap 0.0244\n",
      "Epoch 12/100\n",
      "Avg loss: 0.0032 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9745 -- Gen gap 0.0245\n",
      "Epoch 13/100\n",
      "Avg loss: 0.0032 -- Train acc: 0.9990 -- Val acc: 0.9750 -- Test acc: 0.9744 -- Gen gap 0.0246\n",
      "Epoch 14/100\n",
      "Avg loss: 0.0031 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9745 -- Gen gap 0.0245\n",
      "Epoch 15/100\n",
      "Avg loss: 0.0031 -- Train acc: 0.9990 -- Val acc: 0.9756 -- Test acc: 0.9747 -- Gen gap 0.0243\n",
      "Epoch 16/100\n",
      "Avg loss: 0.0031 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 17/100\n",
      "Avg loss: 0.0030 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9746 -- Gen gap 0.0244\n",
      "Epoch 18/100\n",
      "Avg loss: 0.0030 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 19/100\n",
      "Avg loss: 0.0029 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9742 -- Gen gap 0.0248\n",
      "Epoch 20/100\n",
      "Avg loss: 0.0029 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9747 -- Gen gap 0.0243\n",
      "Epoch 21/100\n",
      "Avg loss: 0.0029 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 22/100\n",
      "Avg loss: 0.0028 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9745 -- Gen gap 0.0245\n",
      "Epoch 23/100\n",
      "Avg loss: 0.0028 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9747 -- Gen gap 0.0243\n",
      "Epoch 24/100\n",
      "Avg loss: 0.0028 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9745 -- Gen gap 0.0245\n",
      "Epoch 25/100\n",
      "Avg loss: 0.0027 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9744 -- Gen gap 0.0246\n",
      "Epoch 26/100\n",
      "Avg loss: 0.0027 -- Train acc: 0.9990 -- Val acc: 0.9749 -- Test acc: 0.9745 -- Gen gap 0.0245\n",
      "Epoch 27/100\n",
      "Avg loss: 0.0027 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9745 -- Gen gap 0.0245\n",
      "Epoch 28/100\n",
      "Avg loss: 0.0026 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9745 -- Gen gap 0.0245\n",
      "Epoch 29/100\n",
      "Avg loss: 0.0026 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9745 -- Gen gap 0.0245\n",
      "Epoch 30/100\n",
      "Avg loss: 0.0026 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 31/100\n",
      "Avg loss: 0.0025 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9746 -- Gen gap 0.0244\n",
      "Epoch 32/100\n",
      "Avg loss: 0.0025 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9744 -- Gen gap 0.0246\n",
      "Epoch 33/100\n",
      "Avg loss: 0.0025 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 34/100\n",
      "Avg loss: 0.0025 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 35/100\n",
      "Avg loss: 0.0024 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 36/100\n",
      "Avg loss: 0.0024 -- Train acc: 0.9990 -- Val acc: 0.9757 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 37/100\n",
      "Avg loss: 0.0024 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9747 -- Gen gap 0.0243\n",
      "Epoch 38/100\n",
      "Avg loss: 0.0024 -- Train acc: 0.9990 -- Val acc: 0.9749 -- Test acc: 0.9745 -- Gen gap 0.0245\n",
      "Epoch 39/100\n",
      "Avg loss: 0.0023 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 40/100\n",
      "Avg loss: 0.0023 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9745 -- Gen gap 0.0245\n",
      "Epoch 41/100\n",
      "Avg loss: 0.0023 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 42/100\n",
      "Avg loss: 0.0022 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 43/100\n",
      "Avg loss: 0.0022 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 44/100\n",
      "Avg loss: 0.0022 -- Train acc: 0.9990 -- Val acc: 0.9758 -- Test acc: 0.9745 -- Gen gap 0.0245\n",
      "Epoch 45/100\n",
      "Avg loss: 0.0022 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9747 -- Gen gap 0.0243\n",
      "Epoch 46/100\n",
      "Avg loss: 0.0022 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9747 -- Gen gap 0.0243\n",
      "Epoch 47/100\n",
      "Avg loss: 0.0021 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9747 -- Gen gap 0.0243\n",
      "Epoch 48/100\n",
      "Avg loss: 0.0021 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 49/100\n",
      "Avg loss: 0.0021 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9747 -- Gen gap 0.0243\n",
      "Epoch 50/100\n",
      "Avg loss: 0.0021 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 51/100\n",
      "Avg loss: 0.0020 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9747 -- Gen gap 0.0243\n",
      "Epoch 52/100\n",
      "Avg loss: 0.0020 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9746 -- Gen gap 0.0244\n",
      "Epoch 53/100\n",
      "Avg loss: 0.0020 -- Train acc: 0.9990 -- Val acc: 0.9750 -- Test acc: 0.9746 -- Gen gap 0.0244\n",
      "Epoch 54/100\n",
      "Avg loss: 0.0020 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 55/100\n",
      "Avg loss: 0.0020 -- Train acc: 0.9990 -- Val acc: 0.9756 -- Test acc: 0.9754 -- Gen gap 0.0236\n",
      "Epoch 56/100\n",
      "Avg loss: 0.0020 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 57/100\n",
      "Avg loss: 0.0019 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 58/100\n",
      "Avg loss: 0.0019 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 59/100\n",
      "Avg loss: 0.0019 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 60/100\n",
      "Avg loss: 0.0019 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 61/100\n",
      "Avg loss: 0.0019 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 62/100\n",
      "Avg loss: 0.0018 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 63/100\n",
      "Avg loss: 0.0018 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.0018 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 65/100\n",
      "Avg loss: 0.0018 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 66/100\n",
      "Avg loss: 0.0018 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9746 -- Gen gap 0.0244\n",
      "Epoch 67/100\n",
      "Avg loss: 0.0018 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 68/100\n",
      "Avg loss: 0.0017 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 69/100\n",
      "Avg loss: 0.0017 -- Train acc: 0.9990 -- Val acc: 0.9757 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 70/100\n",
      "Avg loss: 0.0017 -- Train acc: 0.9990 -- Val acc: 0.9756 -- Test acc: 0.9747 -- Gen gap 0.0243\n",
      "Epoch 71/100\n",
      "Avg loss: 0.0017 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 72/100\n",
      "Avg loss: 0.0017 -- Train acc: 0.9990 -- Val acc: 0.9759 -- Test acc: 0.9747 -- Gen gap 0.0243\n",
      "Epoch 73/100\n",
      "Avg loss: 0.0017 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 74/100\n",
      "Avg loss: 0.0017 -- Train acc: 0.9990 -- Val acc: 0.9750 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 75/100\n",
      "Avg loss: 0.0016 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 76/100\n",
      "Avg loss: 0.0016 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 77/100\n",
      "Avg loss: 0.0016 -- Train acc: 0.9990 -- Val acc: 0.9750 -- Test acc: 0.9747 -- Gen gap 0.0243\n",
      "Epoch 78/100\n",
      "Avg loss: 0.0016 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 79/100\n",
      "Avg loss: 0.0016 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 80/100\n",
      "Avg loss: 0.0016 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 81/100\n",
      "Avg loss: 0.0016 -- Train acc: 0.9990 -- Val acc: 0.9749 -- Test acc: 0.9747 -- Gen gap 0.0243\n",
      "Epoch 82/100\n",
      "Avg loss: 0.0016 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 83/100\n",
      "Avg loss: 0.0015 -- Train acc: 0.9990 -- Val acc: 0.9758 -- Test acc: 0.9748 -- Gen gap 0.0242\n",
      "Epoch 84/100\n",
      "Avg loss: 0.0015 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 85/100\n",
      "Avg loss: 0.0015 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 86/100\n",
      "Avg loss: 0.0015 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 87/100\n",
      "Avg loss: 0.0015 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 88/100\n",
      "Avg loss: 0.0015 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 89/100\n",
      "Avg loss: 0.0015 -- Train acc: 0.9990 -- Val acc: 0.9756 -- Test acc: 0.9754 -- Gen gap 0.0236\n",
      "Epoch 90/100\n",
      "Avg loss: 0.0015 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 91/100\n",
      "Avg loss: 0.0014 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 92/100\n",
      "Avg loss: 0.0014 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 93/100\n",
      "Avg loss: 0.0014 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 94/100\n",
      "Avg loss: 0.0014 -- Train acc: 0.9990 -- Val acc: 0.9757 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 95/100\n",
      "Avg loss: 0.0014 -- Train acc: 0.9990 -- Val acc: 0.9757 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 96/100\n",
      "Avg loss: 0.0014 -- Train acc: 0.9990 -- Val acc: 0.9757 -- Test acc: 0.9747 -- Gen gap 0.0243\n",
      "Epoch 97/100\n",
      "Avg loss: 0.0014 -- Train acc: 0.9990 -- Val acc: 0.9750 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 98/100\n",
      "Avg loss: 0.0014 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 99/100\n",
      "Avg loss: 0.0014 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 100/100\n",
      "Avg loss: 0.0014 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Training done! Elapsed time: 0:03:27\n",
      "\n",
      "Iter 3\n",
      "Epoch 1/100\n",
      "Avg loss: 0.0013 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 2/100\n",
      "Avg loss: 0.0013 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 3/100\n",
      "Avg loss: 0.0013 -- Train acc: 0.9990 -- Val acc: 0.9758 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 4/100\n",
      "Avg loss: 0.0013 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 5/100\n",
      "Avg loss: 0.0013 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 6/100\n",
      "Avg loss: 0.0013 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 7/100\n",
      "Avg loss: 0.0013 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 8/100\n",
      "Avg loss: 0.0013 -- Train acc: 0.9990 -- Val acc: 0.9758 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 9/100\n",
      "Avg loss: 0.0013 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9755 -- Gen gap 0.0235\n",
      "Epoch 10/100\n",
      "Avg loss: 0.0013 -- Train acc: 0.9990 -- Val acc: 0.9749 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 11/100\n",
      "Avg loss: 0.0013 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 12/100\n",
      "Avg loss: 0.0012 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 13/100\n",
      "Avg loss: 0.0012 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9755 -- Gen gap 0.0235\n",
      "Epoch 14/100\n",
      "Avg loss: 0.0012 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 15/100\n",
      "Avg loss: 0.0012 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 16/100\n",
      "Avg loss: 0.0012 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 17/100\n",
      "Avg loss: 0.0012 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 18/100\n",
      "Avg loss: 0.0012 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 19/100\n",
      "Avg loss: 0.0012 -- Train acc: 0.9990 -- Val acc: 0.9758 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 20/100\n",
      "Avg loss: 0.0012 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 21/100\n",
      "Avg loss: 0.0012 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 22/100\n",
      "Avg loss: 0.0012 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 23/100\n",
      "Avg loss: 0.0012 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 24/100\n",
      "Avg loss: 0.0012 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 25/100\n",
      "Avg loss: 0.0011 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 26/100\n",
      "Avg loss: 0.0011 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 27/100\n",
      "Avg loss: 0.0011 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 28/100\n",
      "Avg loss: 0.0011 -- Train acc: 0.9990 -- Val acc: 0.9756 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 29/100\n",
      "Avg loss: 0.0011 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 30/100\n",
      "Avg loss: 0.0011 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 31/100\n",
      "Avg loss: 0.0011 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 32/100\n",
      "Avg loss: 0.0011 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 33/100\n",
      "Avg loss: 0.0011 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 34/100\n",
      "Avg loss: 0.0011 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 35/100\n",
      "Avg loss: 0.0011 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 36/100\n",
      "Avg loss: 0.0011 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 37/100\n",
      "Avg loss: 0.0011 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9749 -- Gen gap 0.0241\n",
      "Epoch 38/100\n",
      "Avg loss: 0.0011 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 39/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9751 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 41/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 42/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 43/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 44/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 45/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 46/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 47/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 48/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 49/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 50/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 51/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 52/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9750 -- Gen gap 0.0240\n",
      "Epoch 53/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 54/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 55/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 56/100\n",
      "Avg loss: 0.0010 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 57/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 58/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 59/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 60/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9756 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 61/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 62/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 63/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 64/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 65/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9752 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 66/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9754 -- Gen gap 0.0236\n",
      "Epoch 67/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 68/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 69/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 70/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 71/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 72/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9757 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 73/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9754 -- Gen gap 0.0236\n",
      "Epoch 74/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 75/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9754 -- Gen gap 0.0236\n",
      "Epoch 76/100\n",
      "Avg loss: 0.0009 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9754 -- Gen gap 0.0236\n",
      "Epoch 77/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 78/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 79/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9754 -- Gen gap 0.0236\n",
      "Epoch 80/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 81/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9755 -- Gen gap 0.0235\n",
      "Epoch 82/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9756 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 83/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 84/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9754 -- Gen gap 0.0236\n",
      "Epoch 85/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 86/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9756 -- Test acc: 0.9754 -- Gen gap 0.0236\n",
      "Epoch 87/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 88/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9754 -- Gen gap 0.0236\n",
      "Epoch 89/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9754 -- Gen gap 0.0236\n",
      "Epoch 90/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 91/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 92/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 93/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 94/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 95/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 96/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9755 -- Gen gap 0.0235\n",
      "Epoch 97/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9755 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Epoch 98/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9753 -- Gen gap 0.0237\n",
      "Epoch 99/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9753 -- Test acc: 0.9752 -- Gen gap 0.0238\n",
      "Epoch 100/100\n",
      "Avg loss: 0.0008 -- Train acc: 0.9990 -- Val acc: 0.9754 -- Test acc: 0.9751 -- Gen gap 0.0239\n",
      "Training done! Elapsed time: 0:03:29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize best model so far\n",
    "mlp = MNIST(layers, learning_rate, \"glorot\")\n",
    "ratios = [0.01, 0.02, 0.05, 0.1, 1.0]\n",
    "nb_epochs = 100\n",
    "nb_trials = 3\n",
    "\n",
    "# Generalization gaps\n",
    "Ga = np.zeros(len(ratios), nb_trials)\n",
    "             \n",
    "for i, a in enumerate(ratios):\n",
    "    length = int(a * len(train_loader.dataset))\n",
    "    print(\"%s\\na = %.2f, Na = %d\\n%s\" % (\"=\"*30, a, length, \"-\"*30))\n",
    "    \n",
    "    for j in range(nb_trials):\n",
    "        print(\"Iter {:d}\".format(j + 1))\n",
    "        # Subsample from training set\n",
    "        Na, sub_train_loader = subsample_train(a, train_loader, batch_size)\n",
    "    \n",
    "        # Train\n",
    "        train_loss, train_acc, valid_acc, test_acc = \\\n",
    "            mlp.train(nb_epochs, sub_train_loader, valid_loader, test_loader, Na, gen_gap=True)\n",
    "            \n",
    "        # Get best validation epoch\n",
    "        best_valid = max(valid_acc)\n",
    "        max_valid_idx = valid_acc.index(best_valid)\n",
    "        \n",
    "        # Save generalization gap\n",
    "        Ga[i,j] = train_acc[max_valid_idx] - test_acc[max_valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f091c251850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "means, stds = Ga.mean(1), Ga.std(1)\n",
    "labels = [\"0.01\",\"0.02\",\"0.05\",\"0.1\",\"1.\"]\n",
    "plot_error_bars(labels, means, stds, \"Ratios\", \"Avg generalization gap\",\n",
    "    \"Average generalization gap for different training subsets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that as expected, the average generalization gap decreases as we increase the size of the training set. This is in accordance with the fact that when there is less data, our neural network overfits it, hence having a larger generalization gap. When there is more training data, this data better represents the true distribution, and hence the model that we fit is a very good one (doesn't overfit), as shown by the small generalization gap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
