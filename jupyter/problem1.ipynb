{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for this multilayer perceptron can be found in `mnist.py`. The module `utils.py` contains helper functions to load the dataset, display progress bar, plot graphs, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from mnist import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build an MLP and choose the values of $h^1$ and $h^2$ such that the total number of parameters (including biases) falls within the range of $I = [0.5M, 1.0M]$. This can be achieved by choosing $h^1 = h^2 = 512$. Since MNIST samples are $28 \\times 28 = 784$ pixels, the total number of parameters is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params = (28*28)*512 + 512*512 + 512*10\n",
    "print(num_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is within range. We thus build the MLP with the parameters below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "h0, h1, h2, h3 = 784, 512, 512, 10\n",
    "learning_rate = 1e-2\n",
    "batch_size = 64\n",
    "data_filename = \"../data/mnist/mnist.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load the tensors via Torch data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets from pickled file\n",
    "train_data, valid_data, test_data = unpickle_mnist(data_filename)\n",
    "\n",
    "# Build data loaders for all three datasets\n",
    "# Training set\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                    train_data, \n",
    "                    batch_size=batch_size, \n",
    "                    shuffle=True)\n",
    "\n",
    "# Validation set\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "                    valid_data,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True)\n",
    "\n",
    "# Test set\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                    test_data,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hardcoded parameters used for all three initilization schemes are:\n",
    "* **Activation functions:** Rectified linear unit (ReLU)\n",
    "* **Loss function:** Cross entropy\n",
    "* **Optimizer:** Stochastic gradient descent (SGD) with learning rate `learning_rate`\n",
    "\n",
    "For each initialization scheme, we compile the model and train by keeping track of the average loss. After training, we plot the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and train model\n",
    "# Length of the training set is passed for the progress bar\n",
    "# Only training data is passed for this part\n",
    "model_z, loss_fn, optimizer = build_model(h0, h1, h2, h3, init=\"zeros\")\n",
    "zero_losses = train(model_z, loss_fn, optimizer, 3, len(train_data), train_loader, [], [])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot avg loss / epoch\n",
    "%matplotlib inline\n",
    "plot_per_epoch(zero_losses, \"Avg loss\", \"Training with zeros initialization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_n, loss_fn, optimizer = build_model(h0, h1, h2, h3, init=\"normal\")\n",
    "normal_losses = train(model_n, loss_fn, optimizer, 10, len(train_data), train_loader, [], [])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plot_per_epoch(normal_losses, \"Avg loss\", \"Training with Normal(0,1) initialization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glorot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_g, loss_fn, optimizer = build_model(h0, h1, h2, h3, init=\"glorot\")\n",
    "glorot_losses = train(model_g, loss_fn, optimizer, 3, len(train_data), train_loader, valid_loader, [])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plot_per_epoch(glorot_losses, \"Avg loss\", \"Training with Glorot initialization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Avg loss: 0.8836 -- Train acc: 0.8841 -- Val acc: 0.8915\n",
      "Epoch 2/10\n",
      "Avg loss: 0.3720 -- Train acc: 0.9079 -- Val acc: 0.9109\n",
      "Epoch 3/10\n",
      "Avg loss: 0.3085 -- Train acc: 0.9182 -- Val acc: 0.9204\n",
      "Epoch 4/10\n",
      "Avg loss: 0.2739 -- Train acc: 0.9265 -- Val acc: 0.9271\n",
      "Epoch 5/10\n",
      "Avg loss: 0.2490 -- Train acc: 0.9284 -- Val acc: 0.9291\n",
      "Epoch 6/10\n",
      "Avg loss: 0.2286 -- Train acc: 0.9379 -- Val acc: 0.9379\n",
      "Epoch 7/10\n",
      "Avg loss: 0.2120 -- Train acc: 0.9423 -- Val acc: 0.9423\n",
      "Epoch 8/10\n",
      "Avg loss: 0.1972 -- Train acc: 0.9456 -- Val acc: 0.9448\n",
      "Epoch 9/10\n",
      "Avg loss: 0.1845 -- Train acc: 0.9487 -- Val acc: 0.9469\n",
      "Epoch 10/10\n",
      "Avg loss: 0.1735 -- Train acc: 0.9531 -- Val acc: 0.9515\n",
      "Training done! Elapsed time: 0:01:04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, loss_fn, optimizer = build_model(h0, h1, h2, h3, init=\"glorot\")\n",
    "_, train_acc, valid_acc, _ = train(model, loss_fn, optimizer, 10, len(train_data), train_loader, valid_loader, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109b0c438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots_per_epoch([train_acc, valid_acc], [\"Train\", \"Test\"], \"Avg Loss\", \"Training the model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train by doubling the model capacity. This is done by doubling the number of neurons at each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params = (28*28)*2*512 + 2*512*512 + 512*10\n",
    "print(num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2, loss_fn, optimizer = build_model(h0, 2*h1, 2*h2, h3, init=\"glorot\")\n",
    "train_acc_2, _, valid_acc_2, _ = train(model_g, loss_fn, optimizer, 10, len(train_data), train_loader, valid_loader, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training Set Size, Generalization Gap, and Standard Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each ratio $a \\in \\{0.01, 0.02, 0.05, 0.1, 1.0\\}$, we reduce the training set to $N_a = aN$ samples, where $N= 50\\,000$. We then train using this new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize best model so far\n",
    "model, loss_fn, optimizer = build_model(h0, h1, h2, h3, init=\"glorot\")\n",
    "ratios = [0.01, 0.02, 0.05, 0.1, 1.0]\n",
    "nb_epochs = 100\n",
    "nb_trials = 3\n",
    "\n",
    "# Generalization gaps\n",
    "Ga = np.zeros((len(ratios), nb_trials, nb_epochs))\n",
    "             \n",
    "for i, a in enumerate(ratios):\n",
    "    print(\"%s\\na = %.2f, Na = %d\\n%s\" % (\"=\"*30, a, int(a * len(train_data)), \"-\"*30))\n",
    "    \n",
    "    for j in range(nb_trials):\n",
    "        print(\"Iter %s\" % str(j + 1))\n",
    "        # Subsample from training set\n",
    "        Na, sub_train_loader = subsample_train(model, loss_fn, optimizer, a, train_loader)\n",
    "    \n",
    "        # Train\n",
    "        train_loss, train_acc, valid_acc, test_acc = \\\n",
    "            train(model, loss_fn, optimizer, nb_epochs, Na, sub_train_loader, valid_loader, test_loader, gen_gap=True)\n",
    "        \n",
    "        # Save generalization gap\n",
    "        Ga[i,j,:] = [r_train - r_test for r_train, r_test in zip(train_acc, test_acc)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
