{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for this single-layer perceptron can be found in `newsgroups.py`. The module `utils.py` contains helper functions to load the dataset, display progress bar, plot graphs, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from newsgroups_v2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the parameters of the single-layer MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "batch_size = 64\n",
    "layers = [61188, 100, 20]\n",
    "learning_rate = 1e-4\n",
    "momentum = 0.9\n",
    "eps = 1e-5\n",
    "train_filename = \"../data/newsgroups/matlab/train\"\n",
    "test_filename = \"../data/newsgroups/matlab/test\"\n",
    "saved = \"../data/newsgroups/saved/\"\n",
    "train_size = 11269\n",
    "test_size = 7505"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a learning rate grid search for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_search = [1e-2, 1e-3, 1e-4, 1e-5]\n",
    "nb_epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load different datasets for each preprocessing methods. Since loading all three datasets at once requires a huge amount of memory, we load them sequentially by clearing out the memory inbetween each procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load dataset without any preprocessing (count vector)\n",
    "train_data, test_data = load_newsgroups(train_filename, test_filename, \n",
    "                                layers[0], train_size, test_size, \"count\")\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Learning rate = 0.1000\n",
      "------------------------------\n",
      "Epoch 1/20\n",
      "Avg loss: 10.6031 -- Train acc: 0.0429 -- Test acc: 0.0440\n",
      "Epoch 2/20\n",
      "Avg loss: 49.2482 -- Train acc: 0.0432 -- Test acc: 0.0438\n",
      "Epoch 3/20\n",
      "Avg loss: 14.5802 -- Train acc: 0.0438 -- Test acc: 0.0436\n",
      "Epoch 4/20\n",
      "Avg loss: 28.4527 -- Train acc: 0.0433 -- Test acc: 0.0429\n",
      "Epoch 5/20\n",
      "Avg loss: 35.4696 -- Train acc: 0.0453 -- Test acc: 0.0442\n",
      "Epoch 6/20\n",
      "Avg loss: 4.5944 -- Train acc: 0.0448 -- Test acc: 0.0438\n",
      "Epoch 7/20\n",
      "Avg loss: 4.5434 -- Train acc: 0.0472 -- Test acc: 0.0454\n",
      "Epoch 8/20\n",
      "Avg loss: 4.5240 -- Train acc: 0.0598 -- Test acc: 0.0580\n",
      "Epoch 9/20\n",
      "Avg loss: 4.5122 -- Train acc: 0.0453 -- Test acc: 0.0440\n",
      "Epoch 10/20\n",
      "Avg loss: 4.5002 -- Train acc: 0.0621 -- Test acc: 0.0593\n",
      "Epoch 11/20\n",
      "Avg loss: 4.4584 -- Train acc: 0.0635 -- Test acc: 0.0596\n",
      "Epoch 12/20\n",
      "Avg loss: 4.4764 -- Train acc: 0.0553 -- Test acc: 0.0514\n",
      "Epoch 13/20\n",
      "Avg loss: 4.4854 -- Train acc: 0.0653 -- Test acc: 0.0612\n",
      "Epoch 14/20\n",
      "Avg loss: 40.7465 -- Train acc: 0.0707 -- Test acc: 0.0648\n",
      "Epoch 15/20\n",
      "Avg loss: 4.4557 -- Train acc: 0.0724 -- Test acc: 0.0675\n",
      "Epoch 16/20\n",
      "Avg loss: 4.4371 -- Train acc: 0.0713 -- Test acc: 0.0657\n",
      "Epoch 17/20\n",
      "Avg loss: 4.4675 -- Train acc: 0.0697 -- Test acc: 0.0632\n",
      "Epoch 18/20\n",
      "Avg loss: 4.4186 -- Train acc: 0.0737 -- Test acc: 0.0685\n",
      "Epoch 19/20\n",
      "Avg loss: 4.4184 -- Train acc: 0.0748 -- Test acc: 0.0698\n",
      "Epoch 20/20\n",
      "Avg loss: 4.4136 -- Train acc: 0.0743 -- Test acc: 0.0698\n",
      "Training done! Elapsed time: 0:00:45\n",
      "\n",
      "==============================\n",
      "Learning rate = 0.0100\n",
      "------------------------------\n",
      "Epoch 1/20\n",
      "Avg loss: 3.5582 -- Train acc: 0.0538 -- Test acc: 0.0539\n",
      "Epoch 2/20\n",
      "Avg loss: 3.3918 -- Train acc: 0.0575 -- Test acc: 0.0565\n",
      "Epoch 3/20\n",
      "Avg loss: 3.4262 -- Train acc: 0.0541 -- Test acc: 0.0540\n",
      "Epoch 4/20\n",
      "Avg loss: 3.3924 -- Train acc: 0.0597 -- Test acc: 0.0576\n",
      "Epoch 5/20\n",
      "Avg loss: 3.2341 -- Train acc: 0.0584 -- Test acc: 0.0572\n",
      "Epoch 6/20\n",
      "Avg loss: 3.4488 -- Train acc: 0.0560 -- Test acc: 0.0547\n",
      "Epoch 7/20\n",
      "Avg loss: 3.2193 -- Train acc: 0.0576 -- Test acc: 0.0559\n",
      "Epoch 8/20\n",
      "Avg loss: 3.2801 -- Train acc: 0.0604 -- Test acc: 0.0569\n",
      "Epoch 9/20\n",
      "Avg loss: 3.2463 -- Train acc: 0.0663 -- Test acc: 0.0609\n",
      "Epoch 10/20\n",
      "Avg loss: 3.2699 -- Train acc: 0.0652 -- Test acc: 0.0609\n",
      "Epoch 11/20\n",
      "Avg loss: 3.2242 -- Train acc: 0.0838 -- Test acc: 0.0767\n",
      "Epoch 12/20\n",
      "Avg loss: 3.2370 -- Train acc: 0.0584 -- Test acc: 0.0568\n",
      "Epoch 13/20\n",
      "Avg loss: 3.4812 -- Train acc: 0.0885 -- Test acc: 0.0869\n",
      "Epoch 14/20\n",
      "Avg loss: 3.2014 -- Train acc: 0.0907 -- Test acc: 0.0814\n",
      "Epoch 15/20\n",
      "Avg loss: 3.1723 -- Train acc: 0.0957 -- Test acc: 0.0859\n",
      "Epoch 16/20\n",
      "Avg loss: 3.2154 -- Train acc: 0.0936 -- Test acc: 0.0850\n",
      "Epoch 17/20\n",
      "Avg loss: 3.4257 -- Train acc: 0.0889 -- Test acc: 0.0828\n",
      "Epoch 18/20\n",
      "Avg loss: 3.3155 -- Train acc: 0.0922 -- Test acc: 0.0796\n",
      "Epoch 19/20\n",
      "Avg loss: 3.2235 -- Train acc: 0.0703 -- Test acc: 0.0626\n",
      "Epoch 20/20\n",
      "Avg loss: 3.2318 -- Train acc: 0.0672 -- Test acc: 0.0614\n",
      "Training done! Elapsed time: 0:00:46\n",
      "\n",
      "==============================\n",
      "Learning rate = 0.0010\n",
      "------------------------------\n",
      "Epoch 1/20\n",
      "Avg loss: 3.1467 -- Train acc: 0.0545 -- Test acc: 0.0544\n",
      "Epoch 2/20\n",
      "Avg loss: 3.0209 -- Train acc: 0.0721 -- Test acc: 0.0646\n",
      "Epoch 3/20\n",
      "Avg loss: 3.0187 -- Train acc: 0.0740 -- Test acc: 0.0670\n",
      "Epoch 4/20\n",
      "Avg loss: 3.0163 -- Train acc: 0.0873 -- Test acc: 0.0794\n",
      "Epoch 5/20\n",
      "Avg loss: 3.0593 -- Train acc: 0.0860 -- Test acc: 0.0802\n",
      "Epoch 6/20\n",
      "Avg loss: 3.0171 -- Train acc: 0.0947 -- Test acc: 0.0865\n",
      "Epoch 7/20\n",
      "Avg loss: 3.0263 -- Train acc: 0.1003 -- Test acc: 0.0898\n",
      "Epoch 8/20\n",
      "Avg loss: 3.0089 -- Train acc: 0.0930 -- Test acc: 0.0854\n",
      "Epoch 9/20\n",
      "Avg loss: 3.0146 -- Train acc: 0.1023 -- Test acc: 0.0960\n",
      "Epoch 10/20\n",
      "Avg loss: 3.0203 -- Train acc: 0.1061 -- Test acc: 0.0967\n",
      "Epoch 11/20\n",
      "Avg loss: 2.9893 -- Train acc: 0.1090 -- Test acc: 0.1018\n",
      "Epoch 12/20\n",
      "Avg loss: 2.9847 -- Train acc: 0.1111 -- Test acc: 0.1046\n",
      "Epoch 13/20\n",
      "Avg loss: 2.9785 -- Train acc: 0.1207 -- Test acc: 0.1164\n",
      "Epoch 14/20\n",
      "Avg loss: 2.9744 -- Train acc: 0.1171 -- Test acc: 0.1115\n",
      "Epoch 15/20\n",
      "Avg loss: 2.9682 -- Train acc: 0.1347 -- Test acc: 0.1261\n",
      "Epoch 16/20\n",
      "Avg loss: 3.0077 -- Train acc: 0.1270 -- Test acc: 0.1194\n",
      "Epoch 17/20\n",
      "Avg loss: 2.9458 -- Train acc: 0.1295 -- Test acc: 0.1226\n",
      "Epoch 18/20\n",
      "Avg loss: 2.9340 -- Train acc: 0.1276 -- Test acc: 0.1177\n",
      "Epoch 19/20\n",
      "Avg loss: 2.9307 -- Train acc: 0.1434 -- Test acc: 0.1339\n",
      "Epoch 20/20\n",
      "Avg loss: 2.9176 -- Train acc: 0.1362 -- Test acc: 0.1230\n",
      "Training done! Elapsed time: 0:00:46\n",
      "\n",
      "==============================\n",
      "Learning rate = 0.0001\n",
      "------------------------------\n",
      "Epoch 1/20\n",
      "Avg loss: 3.1070 -- Train acc: 0.0755 -- Test acc: 0.0735\n",
      "Epoch 2/20\n",
      "Avg loss: 2.9962 -- Train acc: 0.0875 -- Test acc: 0.0796\n",
      "Epoch 3/20\n",
      "Avg loss: 2.9957 -- Train acc: 0.1012 -- Test acc: 0.0918\n",
      "Epoch 4/20\n",
      "Avg loss: 2.9923 -- Train acc: 0.1187 -- Test acc: 0.1001\n",
      "Epoch 5/20\n",
      "Avg loss: 2.9935 -- Train acc: 0.1306 -- Test acc: 0.1074\n",
      "Epoch 6/20\n",
      "Avg loss: 2.9907 -- Train acc: 0.1476 -- Test acc: 0.1185\n",
      "Epoch 7/20\n",
      "Avg loss: 2.9873 -- Train acc: 0.1459 -- Test acc: 0.1225\n",
      "Epoch 8/20\n",
      "Avg loss: 2.9866 -- Train acc: 0.1744 -- Test acc: 0.1367\n",
      "Epoch 9/20\n",
      "Avg loss: 2.9821 -- Train acc: 0.1764 -- Test acc: 0.1425\n",
      "Epoch 10/20\n",
      "Avg loss: 2.9772 -- Train acc: 0.1859 -- Test acc: 0.1502\n",
      "Epoch 11/20\n",
      "Avg loss: 2.9784 -- Train acc: 0.1889 -- Test acc: 0.1590\n",
      "Epoch 12/20\n",
      "Avg loss: 2.9654 -- Train acc: 0.2033 -- Test acc: 0.1691\n",
      "Epoch 13/20\n",
      "Avg loss: 2.9609 -- Train acc: 0.1890 -- Test acc: 0.1577\n",
      "Epoch 14/20\n",
      "Avg loss: 2.9535 -- Train acc: 0.1721 -- Test acc: 0.1446\n",
      "Epoch 15/20\n",
      "Avg loss: 2.9471 -- Train acc: 0.1883 -- Test acc: 0.1516\n",
      "Epoch 16/20\n",
      "Avg loss: 2.9410 -- Train acc: 0.2025 -- Test acc: 0.1643\n",
      "Epoch 17/20\n",
      "Avg loss: 2.9264 -- Train acc: 0.2141 -- Test acc: 0.1732\n",
      "Epoch 18/20\n",
      "Avg loss: 2.9097 -- Train acc: 0.2311 -- Test acc: 0.1923\n",
      "Epoch 19/20\n",
      "Avg loss: 2.9073 -- Train acc: 0.2400 -- Test acc: 0.1962\n",
      "Epoch 20/20\n",
      "Avg loss: 2.8818 -- Train acc: 0.2602 -- Test acc: 0.2156\n",
      "Training done! Elapsed time: 0:00:46\n",
      "\n",
      "==============================\n",
      "Learning rate = 0.0000\n",
      "------------------------------\n",
      "Epoch 1/20\n",
      "Avg loss: 3.0579 -- Train acc: 0.0599 -- Test acc: 0.0604\n",
      "Epoch 2/20\n",
      "Avg loss: 3.0198 -- Train acc: 0.0639 -- Test acc: 0.0657\n",
      "Epoch 3/20\n",
      "Avg loss: 3.0033 -- Train acc: 0.0685 -- Test acc: 0.0703\n",
      "Epoch 4/20\n",
      "Avg loss: 2.9930 -- Train acc: 0.0743 -- Test acc: 0.0745\n",
      "Epoch 5/20\n",
      "Avg loss: 2.9850 -- Train acc: 0.0791 -- Test acc: 0.0777\n",
      "Epoch 6/20\n",
      "Avg loss: 2.9785 -- Train acc: 0.0840 -- Test acc: 0.0818\n",
      "Epoch 7/20\n",
      "Avg loss: 2.9720 -- Train acc: 0.0901 -- Test acc: 0.0851\n",
      "Epoch 8/20\n",
      "Avg loss: 2.9659 -- Train acc: 0.0950 -- Test acc: 0.0900\n",
      "Epoch 9/20\n",
      "Avg loss: 2.9600 -- Train acc: 0.1005 -- Test acc: 0.0947\n",
      "Epoch 10/20\n",
      "Avg loss: 2.9538 -- Train acc: 0.1064 -- Test acc: 0.0976\n",
      "Epoch 11/20\n",
      "Avg loss: 2.9473 -- Train acc: 0.1128 -- Test acc: 0.0996\n",
      "Epoch 12/20\n",
      "Avg loss: 2.9412 -- Train acc: 0.1194 -- Test acc: 0.1033\n",
      "Epoch 13/20\n",
      "Avg loss: 2.9350 -- Train acc: 0.1256 -- Test acc: 0.1094\n",
      "Epoch 14/20\n",
      "Avg loss: 2.9288 -- Train acc: 0.1318 -- Test acc: 0.1157\n",
      "Epoch 15/20\n",
      "Avg loss: 2.9227 -- Train acc: 0.1385 -- Test acc: 0.1226\n",
      "Epoch 16/20\n",
      "Avg loss: 2.9164 -- Train acc: 0.1449 -- Test acc: 0.1280\n",
      "Epoch 17/20\n",
      "Avg loss: 2.9101 -- Train acc: 0.1528 -- Test acc: 0.1335\n",
      "Epoch 18/20\n",
      "Avg loss: 2.9036 -- Train acc: 0.1577 -- Test acc: 0.1385\n",
      "Epoch 19/20\n",
      "Avg loss: 2.8973 -- Train acc: 0.1641 -- Test acc: 0.1449\n",
      "Epoch 20/20\n",
      "Avg loss: 2.8911 -- Train acc: 0.1717 -- Test acc: 0.1496\n",
      "Training done! Elapsed time: 0:00:46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile and train model\n",
    "train_acc = torch.zeros((len(lr_search), nb_epochs))\n",
    "test_acc = torch.zeros((len(lr_search), nb_epochs))\n",
    "\n",
    "# Learning rate grid search\n",
    "for i, lr in enumerate(lr_search):\n",
    "    print(\"{}\\nLearning rate = {:.5f}\\n{}\".format(\"=\"*30, lr, \"-\"*30))\n",
    "    mlp_n = Newsgroups(layers, lr, momentum)\n",
    "    _, tr_acc, te_acc = mlp_n.train(nb_epochs, train_loader, test_loader)\n",
    "    train_acc[i], test_acc[i] = torch.FloatTensor(tr_acc), torch.FloatTensor(te_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc16c040c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find best learning rate\n",
    "best_lr_idx = test_acc.max(1)[0].max(0)[1][0]\n",
    "best_lr = lr_search[best_lr_idx]\n",
    "\n",
    "# Plot accuracy per epoch for this learning rate\n",
    "plots_per_epoch([train_acc[best_lr_idx], test_acc[best_lr_idx]], \n",
    "    [\"Train\", \"Test\"], \"Accuracy\", \"Count: Best learning rate = {}\".format(best_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset with tf-idf preprocessing (tf-idf vector)\n",
    "train_data, test_data = load_newsgroups(train_filename, test_filename, \n",
    "                                layers[0], train_size, test_size, \"tfidf\")\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Learning rate = 0.10000\n",
      "------------------------------\n",
      "Epoch 1/20\n",
      "Avg loss: 77.7257 -- Train acc: 0.0434 -- Test acc: 0.0430\n",
      "Epoch 2/20\n",
      "Avg loss: 6.2442 -- Train acc: 0.0439 -- Test acc: 0.0425\n",
      "Epoch 3/20\n",
      "Avg loss: 46.0783 -- Train acc: 0.0440 -- Test acc: 0.0429\n",
      "Epoch 4/20\n",
      "Avg loss: 340.2365 -- Train acc: 0.0433 -- Test acc: 0.0425\n",
      "Epoch 5/20\n",
      "Avg loss: 1305.3649 -- Train acc: 0.0476 -- Test acc: 0.0449\n",
      "Epoch 6/20\n",
      "Avg loss: 7452.3127 -- Train acc: 0.0556 -- Test acc: 0.0502\n",
      "Epoch 7/20\n",
      "Avg loss: 4.5735 -- Train acc: 0.0621 -- Test acc: 0.0534\n",
      "Epoch 8/20\n",
      "Avg loss: 4.8432 -- Train acc: 0.0518 -- Test acc: 0.0449\n",
      "Epoch 9/20\n",
      "Avg loss: 8.2525 -- Train acc: 0.0523 -- Test acc: 0.0474\n",
      "Epoch 10/20\n",
      "Avg loss: 4.5802 -- Train acc: 0.0508 -- Test acc: 0.0454\n",
      "Epoch 11/20\n",
      "Avg loss: 4.5033 -- Train acc: 0.0508 -- Test acc: 0.0456\n",
      "Epoch 12/20\n",
      "Avg loss: 4.5034 -- Train acc: 0.0508 -- Test acc: 0.0456\n",
      "Epoch 13/20\n",
      "Avg loss: 4.5037 -- Train acc: 0.0509 -- Test acc: 0.0456\n",
      "Epoch 14/20\n",
      "Avg loss: 4.5324 -- Train acc: 0.0506 -- Test acc: 0.0454\n",
      "Epoch 15/20\n",
      "Avg loss: 4.5206 -- Train acc: 0.0508 -- Test acc: 0.0454\n",
      "Epoch 16/20\n",
      "Avg loss: 4.5034 -- Train acc: 0.0508 -- Test acc: 0.0454\n",
      "Epoch 17/20\n",
      "Avg loss: 4.5027 -- Train acc: 0.0508 -- Test acc: 0.0454\n",
      "Epoch 18/20\n",
      "Avg loss: 4.5027 -- Train acc: 0.0508 -- Test acc: 0.0454\n",
      "Epoch 19/20\n",
      "Avg loss: 4.5024 -- Train acc: 0.0508 -- Test acc: 0.0454\n",
      "Epoch 20/20\n",
      "Avg loss: 4.5058 -- Train acc: 0.0509 -- Test acc: 0.0454\n",
      "Training done! Elapsed time: 0:00:44\n",
      "\n",
      "==============================\n",
      "Learning rate = 0.01000\n",
      "------------------------------\n",
      "Epoch 1/20\n",
      "Avg loss: 4.8971 -- Train acc: 0.0587 -- Test acc: 0.0580\n",
      "Epoch 2/20\n",
      "Avg loss: 3.9904 -- Train acc: 0.0615 -- Test acc: 0.0580\n",
      "Epoch 3/20\n",
      "Avg loss: 3.8721 -- Train acc: 0.1007 -- Test acc: 0.0885\n",
      "Epoch 4/20\n",
      "Avg loss: 4.7229 -- Train acc: 0.1073 -- Test acc: 0.0956\n",
      "Epoch 5/20\n",
      "Avg loss: 3.9887 -- Train acc: 0.1052 -- Test acc: 0.0928\n",
      "Epoch 6/20\n",
      "Avg loss: 3.1538 -- Train acc: 0.1315 -- Test acc: 0.1194\n",
      "Epoch 7/20\n",
      "Avg loss: 3.0716 -- Train acc: 0.1407 -- Test acc: 0.1291\n",
      "Epoch 8/20\n",
      "Avg loss: 3.0246 -- Train acc: 0.1558 -- Test acc: 0.1378\n",
      "Epoch 9/20\n",
      "Avg loss: 4.8835 -- Train acc: 0.1224 -- Test acc: 0.1092\n",
      "Epoch 10/20\n",
      "Avg loss: 7.3522 -- Train acc: 0.1272 -- Test acc: 0.1026\n",
      "Epoch 11/20\n",
      "Avg loss: 4.3519 -- Train acc: 0.1228 -- Test acc: 0.0973\n",
      "Epoch 12/20\n",
      "Avg loss: 3.3797 -- Train acc: 0.1468 -- Test acc: 0.1159\n",
      "Epoch 13/20\n",
      "Avg loss: 3.1077 -- Train acc: 0.1216 -- Test acc: 0.1016\n",
      "Epoch 14/20\n",
      "Avg loss: 3.0535 -- Train acc: 0.1450 -- Test acc: 0.1067\n",
      "Epoch 15/20\n",
      "Avg loss: 2.9830 -- Train acc: 0.1461 -- Test acc: 0.1124\n",
      "Epoch 16/20\n",
      "Avg loss: 3.0427 -- Train acc: 0.1421 -- Test acc: 0.1103\n",
      "Epoch 17/20\n",
      "Avg loss: 2.9230 -- Train acc: 0.1615 -- Test acc: 0.1184\n",
      "Epoch 18/20\n",
      "Avg loss: 3.2795 -- Train acc: 0.1236 -- Test acc: 0.0944\n",
      "Epoch 19/20\n",
      "Avg loss: 2.8950 -- Train acc: 0.1720 -- Test acc: 0.1405\n",
      "Epoch 20/20\n",
      "Avg loss: 2.8536 -- Train acc: 0.1845 -- Test acc: 0.1453\n",
      "Training done! Elapsed time: 0:00:46\n",
      "\n",
      "==============================\n",
      "Learning rate = 0.00100\n",
      "------------------------------\n",
      "Epoch 1/20\n",
      "Avg loss: 3.2371 -- Train acc: 0.0870 -- Test acc: 0.0670\n",
      "Epoch 2/20\n",
      "Avg loss: 3.0056 -- Train acc: 0.1256 -- Test acc: 0.0947\n",
      "Epoch 3/20\n",
      "Avg loss: 3.0454 -- Train acc: 0.1446 -- Test acc: 0.1116\n",
      "Epoch 4/20\n",
      "Avg loss: 2.9781 -- Train acc: 0.1853 -- Test acc: 0.1345\n",
      "Epoch 5/20\n",
      "Avg loss: 3.0334 -- Train acc: 0.2230 -- Test acc: 0.1741\n",
      "Epoch 6/20\n",
      "Avg loss: 2.8308 -- Train acc: 0.2203 -- Test acc: 0.1748\n",
      "Epoch 7/20\n",
      "Avg loss: 2.7548 -- Train acc: 0.2144 -- Test acc: 0.1647\n",
      "Epoch 8/20\n",
      "Avg loss: 2.6576 -- Train acc: 0.2780 -- Test acc: 0.2215\n",
      "Epoch 9/20\n",
      "Avg loss: 2.5456 -- Train acc: 0.3110 -- Test acc: 0.2447\n",
      "Epoch 10/20\n",
      "Avg loss: 2.4150 -- Train acc: 0.3120 -- Test acc: 0.2430\n",
      "Epoch 11/20\n",
      "Avg loss: 2.4370 -- Train acc: 0.3061 -- Test acc: 0.2401\n",
      "Epoch 12/20\n",
      "Avg loss: 2.3006 -- Train acc: 0.3722 -- Test acc: 0.3011\n",
      "Epoch 13/20\n",
      "Avg loss: 2.0791 -- Train acc: 0.4210 -- Test acc: 0.3294\n",
      "Epoch 14/20\n",
      "Avg loss: 1.9242 -- Train acc: 0.4195 -- Test acc: 0.3245\n",
      "Epoch 15/20\n",
      "Avg loss: 2.0039 -- Train acc: 0.4732 -- Test acc: 0.3530\n",
      "Epoch 16/20\n",
      "Avg loss: 1.8002 -- Train acc: 0.4708 -- Test acc: 0.3635\n",
      "Epoch 17/20\n",
      "Avg loss: 1.8443 -- Train acc: 0.5063 -- Test acc: 0.3619\n",
      "Epoch 18/20\n",
      "Avg loss: 1.8079 -- Train acc: 0.5402 -- Test acc: 0.4094\n",
      "Epoch 19/20\n",
      "Avg loss: 1.5448 -- Train acc: 0.5006 -- Test acc: 0.3486\n",
      "Epoch 20/20\n",
      "Avg loss: 1.5023 -- Train acc: 0.5514 -- Test acc: 0.4002\n",
      "Training done! Elapsed time: 0:00:45\n",
      "\n",
      "==============================\n",
      "Learning rate = 0.00010\n",
      "------------------------------\n",
      "Epoch 1/20\n",
      "Avg loss: 3.2650 -- Train acc: 0.1195 -- Test acc: 0.0926\n",
      "Epoch 2/20\n",
      "Avg loss: 2.9563 -- Train acc: 0.1888 -- Test acc: 0.1319\n",
      "Epoch 3/20\n",
      "Avg loss: 2.9073 -- Train acc: 0.2603 -- Test acc: 0.1827\n",
      "Epoch 4/20\n",
      "Avg loss: 2.8214 -- Train acc: 0.2632 -- Test acc: 0.1721\n",
      "Epoch 5/20\n",
      "Avg loss: 2.7025 -- Train acc: 0.2820 -- Test acc: 0.1752\n",
      "Epoch 6/20\n",
      "Avg loss: 2.5254 -- Train acc: 0.3876 -- Test acc: 0.2516\n",
      "Epoch 7/20\n",
      "Avg loss: 2.3349 -- Train acc: 0.5011 -- Test acc: 0.3370\n",
      "Epoch 8/20\n",
      "Avg loss: 2.1389 -- Train acc: 0.5012 -- Test acc: 0.3249\n",
      "Epoch 9/20\n",
      "Avg loss: 1.9909 -- Train acc: 0.6475 -- Test acc: 0.4502\n",
      "Epoch 10/20\n",
      "Avg loss: 1.7553 -- Train acc: 0.7051 -- Test acc: 0.5040\n",
      "Epoch 11/20\n",
      "Avg loss: 1.5905 -- Train acc: 0.7541 -- Test acc: 0.5528\n",
      "Epoch 12/20\n",
      "Avg loss: 1.4384 -- Train acc: 0.7963 -- Test acc: 0.5975\n",
      "Epoch 13/20\n",
      "Avg loss: 1.3015 -- Train acc: 0.8237 -- Test acc: 0.6286\n",
      "Epoch 14/20\n",
      "Avg loss: 1.1887 -- Train acc: 0.8458 -- Test acc: 0.6502\n",
      "Epoch 15/20\n",
      "Avg loss: 1.0865 -- Train acc: 0.8629 -- Test acc: 0.6670\n",
      "Epoch 16/20\n",
      "Avg loss: 1.0139 -- Train acc: 0.8788 -- Test acc: 0.6845\n",
      "Epoch 17/20\n",
      "Avg loss: 0.9458 -- Train acc: 0.8858 -- Test acc: 0.6886\n",
      "Epoch 18/20\n",
      "Avg loss: 0.9030 -- Train acc: 0.9002 -- Test acc: 0.7042\n",
      "Epoch 19/20\n",
      "Avg loss: 0.8459 -- Train acc: 0.9092 -- Test acc: 0.7150\n",
      "Epoch 20/20\n",
      "Avg loss: 0.7954 -- Train acc: 0.9149 -- Test acc: 0.7178\n",
      "Training done! Elapsed time: 0:00:46\n",
      "\n",
      "==============================\n",
      "Learning rate = 0.00001\n",
      "------------------------------\n",
      "Epoch 1/20\n",
      "Avg loss: 3.2663 -- Train acc: 0.0798 -- Test acc: 0.0777\n",
      "Epoch 2/20\n",
      "Avg loss: 3.0400 -- Train acc: 0.1075 -- Test acc: 0.0939\n",
      "Epoch 3/20\n",
      "Avg loss: 2.9501 -- Train acc: 0.1358 -- Test acc: 0.1131\n",
      "Epoch 4/20\n",
      "Avg loss: 2.8911 -- Train acc: 0.1653 -- Test acc: 0.1300\n",
      "Epoch 5/20\n",
      "Avg loss: 2.8399 -- Train acc: 0.1977 -- Test acc: 0.1517\n",
      "Epoch 6/20\n",
      "Avg loss: 2.7906 -- Train acc: 0.2296 -- Test acc: 0.1728\n",
      "Epoch 7/20\n",
      "Avg loss: 2.7415 -- Train acc: 0.2605 -- Test acc: 0.1961\n",
      "Epoch 8/20\n",
      "Avg loss: 2.6908 -- Train acc: 0.2925 -- Test acc: 0.2213\n",
      "Epoch 9/20\n",
      "Avg loss: 2.6400 -- Train acc: 0.3254 -- Test acc: 0.2428\n",
      "Epoch 10/20\n",
      "Avg loss: 2.5881 -- Train acc: 0.3577 -- Test acc: 0.2685\n",
      "Epoch 11/20\n",
      "Avg loss: 2.5344 -- Train acc: 0.3890 -- Test acc: 0.2920\n",
      "Epoch 12/20\n",
      "Avg loss: 2.4789 -- Train acc: 0.4174 -- Test acc: 0.3146\n",
      "Epoch 13/20\n",
      "Avg loss: 2.4219 -- Train acc: 0.4480 -- Test acc: 0.3345\n",
      "Epoch 14/20\n",
      "Avg loss: 2.3659 -- Train acc: 0.4774 -- Test acc: 0.3584\n",
      "Epoch 15/20\n",
      "Avg loss: 2.3086 -- Train acc: 0.5071 -- Test acc: 0.3815\n",
      "Epoch 16/20\n",
      "Avg loss: 2.2523 -- Train acc: 0.5295 -- Test acc: 0.4028\n",
      "Epoch 17/20\n",
      "Avg loss: 2.1972 -- Train acc: 0.5520 -- Test acc: 0.4216\n",
      "Epoch 18/20\n",
      "Avg loss: 2.1433 -- Train acc: 0.5706 -- Test acc: 0.4371\n",
      "Epoch 19/20\n",
      "Avg loss: 2.0907 -- Train acc: 0.5906 -- Test acc: 0.4530\n",
      "Epoch 20/20\n",
      "Avg loss: 2.0402 -- Train acc: 0.6089 -- Test acc: 0.4701\n",
      "Training done! Elapsed time: 0:00:45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile and train model\n",
    "train_acc = torch.zeros((len(lr_search), nb_epochs))\n",
    "test_acc = torch.zeros((len(lr_search), nb_epochs))\n",
    "\n",
    "# Learning rate grid search\n",
    "for i, lr in enumerate(lr_search):\n",
    "    print(\"{}\\nLearning rate = {:.5f}\\n{}\".format(\"=\"*30, lr, \"-\"*30))\n",
    "    mlp_t = Newsgroups(layers, lr, momentum)\n",
    "    _, tr_acc, te_acc = mlp_t.train(nb_epochs, train_loader, test_loader)\n",
    "    train_acc[i], test_acc[i] = torch.FloatTensor(tr_acc), torch.FloatTensor(te_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f56332c7e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find best learning rate\n",
    "best_lr_idx = test_acc.max(1)[0].max(0)[1][0]\n",
    "best_lr = lr_search[best_lr_idx]\n",
    "\n",
    "# Plot accuracy per epoch for this learning rate\n",
    "plots_per_epoch([train_acc[best_lr_idx], test_acc[best_lr_idx]], \n",
    "    [\"Train\", \"Test\"], \"Accuracy\", \"TF-IDF: Best learning rate = {}\".format(best_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset with standardization preprocessing, given epsilon\n",
    "train_data, test_data = load_newsgroups(train_filename, test_filename, \n",
    "                                layers[0], train_size, test_size, \"stand\", 1e-5)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Learning rate = 0.00001\n",
      "------------------------------\n",
      "Epoch 1/20\n",
      "Avg loss: 3.2956 -- Train acc: 0.0624 -- Test acc: 0.0531\n",
      "Epoch 2/20\n",
      "Avg loss: 3.2021 -- Train acc: 0.0734 -- Test acc: 0.0588\n",
      "Epoch 3/20\n",
      "Avg loss: 3.1158 -- Train acc: 0.0865 -- Test acc: 0.0655\n",
      "Epoch 4/20\n",
      "Avg loss: 3.0357 -- Train acc: 0.1036 -- Test acc: 0.0706\n",
      "Epoch 5/20\n",
      "Avg loss: 2.9608 -- Train acc: 0.1218 -- Test acc: 0.0772\n",
      "Epoch 6/20\n",
      "Avg loss: 2.8902 -- Train acc: 0.1406 -- Test acc: 0.0830\n",
      "Epoch 7/20\n",
      "Avg loss: 2.8238 -- Train acc: 0.1629 -- Test acc: 0.0906\n",
      "Epoch 8/20\n",
      "Avg loss: 2.7612 -- Train acc: 0.1828 -- Test acc: 0.0972\n",
      "Epoch 9/20\n",
      "Avg loss: 2.7020 -- Train acc: 0.2044 -- Test acc: 0.1042\n",
      "Epoch 10/20\n",
      "Avg loss: 2.6459 -- Train acc: 0.2270 -- Test acc: 0.1132\n",
      "Epoch 11/20\n",
      "Avg loss: 2.5924 -- Train acc: 0.2493 -- Test acc: 0.1221\n",
      "Epoch 12/20\n",
      "Avg loss: 2.5411 -- Train acc: 0.2742 -- Test acc: 0.1307\n",
      "Epoch 13/20\n",
      "Avg loss: 2.4918 -- Train acc: 0.2973 -- Test acc: 0.1404\n",
      "Epoch 14/20\n",
      "Avg loss: 2.4445 -- Train acc: 0.3205 -- Test acc: 0.1487\n",
      "Epoch 15/20\n",
      "Avg loss: 2.3988 -- Train acc: 0.3438 -- Test acc: 0.1572\n",
      "Epoch 16/20\n",
      "Avg loss: 2.3549 -- Train acc: 0.3665 -- Test acc: 0.1657\n",
      "Epoch 17/20\n",
      "Training [■■■■■■■■■■■■■       ] 67.0% \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2f0299adabd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}\\nLearning rate = {:.5f}\\n{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmlp_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNewsgroups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mtrain_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mte_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nic/Documents/joey/ift6135-a1/src/newsgroups_v2.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, nb_epochs, train_loader, test_loader, nb_max_updates)\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nic/.local/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCudaTransfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nic/.local/lib/python2.7/site-packages/torch/autograd/_functions/tensor.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i, device, async)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nic/.local/lib/python2.7/site-packages/torch/_utils.pyc\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Compile and train model\n",
    "train_acc = torch.zeros((len(lr_search), nb_epochs))\n",
    "test_acc = torch.zeros((len(lr_search), nb_epochs))\n",
    "\n",
    "# Learning rate grid search\n",
    "for i, lr in enumerate(lr_search):\n",
    "    print(\"{}\\nLearning rate = {:.5f}\\n{}\".format(\"=\"*30, lr, \"-\"*30))\n",
    "    mlp_t = Newsgroups(layers, lr, momentum)\n",
    "    _, tr_acc, te_acc = mlp_t.train(nb_epochs, train_loader, test_loader)\n",
    "    train_acc[i], test_acc[i] = torch.FloatTensor(tr_acc), torch.FloatTensor(te_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0dabb27390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find best learning rate\n",
    "best_lr_idx = test_acc.max(1)[0].max(0)[1][0]\n",
    "best_lr = lr_search[best_lr_idx]\n",
    "\n",
    "# Plot accuracy per epoch for this learning rate\n",
    "plots_per_epoch([train_acc[best_lr_idx], test_acc[best_lr_idx]], \n",
    "    [\"Train\", \"Test\"], \"Accuracy\", \"Standardization: Best learning rate = {}\".format(best_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)**\n",
    "\n",
    "**(b)** If $\\epsilon = 0$ then a word in the vocabulary that never appears in any document will cause a division by zero. In PyTorch, this gives `inf` entries in the training set which causes problem when updating the weights. In order to resolve this issue, we can remove all zero-contribution words in the vocab such that $\\sigma_{\\text{train}} \\neq 0$ for all words.\n",
    " \n",
    "**(c)** The tf-idf representation gives more \"weight\" to words that are rare. In some sense, tf-idf disregards words that have low impact (e.g. \"the\", \"a\", \"and\") in the classification because they are common, and identifies rare occurences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Variance in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tfidf dataset\n",
    "train_data, test_data = load_newsgroups(train_filename, test_filename, \n",
    "                                layers[0], train_size, test_size, \"tfidf\")\n",
    "learning_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "Update    0/5000 -- Cur Loss: 1.9969\n",
      "Update  100/5000 -- Cur Loss: 0.0000\n",
      "Update  200/5000 -- Cur Loss: 0.0000\n",
      "Update  300/5000 -- Cur Loss: 0.0000\n",
      "Update  400/5000 -- Cur Loss: 0.0000\n",
      "Update  500/5000 -- Cur Loss: 0.0000\n",
      "Update  600/5000 -- Cur Loss: 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-257a4d9e8599>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmlp_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNewsgroups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/McGill/Graduate/Courses/IFT 6135/Assignments/A1/src/newsgroups_v2.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, nb_epochs, train_loader, test_loader, nb_max_updates)\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0;31m# Zero gradients, perform a backward pass, and update the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     98\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mlp_t = Newsgroups(layers, learning_rate, momentum)\n",
    "train_loss, train_acc, test_acc = mlp_t.train(1, train_loader, test_loader, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-38e1d3a27a7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loss' is not defined"
     ]
    }
   ],
   "source": [
    "print(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Update    0/5000 -- Cur Loss: 5.8199\n",
      "Update  100/5000 -- Cur Loss: 6.6925\n",
      "Epoch 2/100\n",
      "Update  200/5000 -- Cur Loss: 6.3561\n",
      "Epoch 3/100\n",
      "Update  300/5000 -- Cur Loss: 4.9169\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-35d2a593990c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/McGill/Graduate/Courses/IFT 6135/Assignments/A1/src/newsgroups_v2.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, nb_epochs, train_loader, test_loader, nb_max_updates)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0;31m# Zero gradients, perform a backward pass, and update the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss, train_acc, test_acc = mlp_t.train(100, train_loader, test_loader, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_per_epoch(train_loss, \"Loss\", \"Vochier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
